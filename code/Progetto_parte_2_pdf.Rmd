---
documentclass: jss
author:
  - name: Carmela Pia Senatore
    orcid: 0000-0000-0000-0000
    affiliation: 'Università degli studi di Salerno'
    address: |
      | Matricola: 0522501721
    email: \email{c.senatore50@studenti.unisa.it}
title:
  formatted: "Analisi e valutazione del benessere della società: caso studio sugli indici di vita "
  # If you use tex in the formatted title, also supply version without
  plain:     "Analisi e valutazione del benessere della società: caso studio sugli indici di vita"
abstract: >
  The abstract of the article.
keywords:
  # at least one keyword must be supplied
  formatted: [keywords, not capitalized, "\\proglang{Java}"]
  plain:     [keywords, not capitalized, Java]
preamble: |
  \usepackage{amsmath}
output: 
  rticles::jss_article
---































```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(warning=FALSE)

```



```{r echo=FALSE, fig.align='center', include=FALSE}
library(imputeTS)
library(tidyverse)
library(networkD3)
library(reshape2)

library(forecast)

library(readxl)
library(dplyr)
library(ggplot2)
library(stats)

```


Definizione degli obiettivi

Nel corso dell' analisi, si mira, a definire gli obiettivi tramite l'utilizzo del database, con particolare attenzione su tre aspetti principali. 

  * In primo luogo, in questa parte,  verrà condotta un'analisi delle serie storiche basata su osservazioni annuali per comprendere l'evoluzione di specifiche variabili nel tempo. Questo consentirà di acquisire una prospettiva longitudinale e identificare eventuali tendenze o cambiamenti significativi.
  * Successivamente, nella seconda parte,  ci si concentrerà su un anno specifico (il 2017), in cui verrà condotta un'analisi esplorativa e di clustering. Quest'ultima  permetterà di ottenere una visione più dettagliata dei pattern e delle relazioni presenti nei dati di quell'anno in particolare.
  * Infine, verrà scelta una variabile aleatoria sulla quale svolgere inferenza. 

L'obiettivo principale è capire quali elementi hanno un impatto significativo sul livello di benessere e qualità della vita.
  * Successivamente, nella seconda parte,  ci si concentrerà su un anno specifico (il 2017), in cui verrà condotta un'analisi esplorativa e di clustering. Quest'ultima  permetterà di ottenere una visione più dettagliata dei pattern e delle relazioni presenti nei dati di quell'anno in particolare.
  * Infine, verrà scelta una variabile aleatoria sulla quale svolgere inferenza.
L'obiettivo principale è capire quali elementi hanno un impatto significativo sul livello di benessere e qualità della vita.

```{r echo=FALSE, fig.align='center', include=FALSE}
setwd("C:/Users/carme/OneDrive/Desktop/UNIVERSITA 2/STATISTICA E ANALISI DEI DATI/Progetto_statistica_parte_2")
library(readxl)
library(dplyr)
library(ggplot2)
library(corrplot)
library(cluster)
library(tseries)
library(tidyverse)
library(plotly)
library(fpc)
library(ggridges)
library(gridExtra)
library(caret)
library(DescTools)
library(factoextra)
library(clValid)
library(gplots)

```

# Descrizione del dataset

Il **Better Life Index** è un database globale che raccoglie dati provenienti da circa 40 Stati in tutto il mondo. L'obiettivo principale del database è coinvolgere e rendere consapevoli i cittadini in un dibattito significativo sulla valutazione del benessere della società e consentire di partecipare attivamente al processo di formulazione delle politiche che influenzano la qualità della vita di tutti. Questo strumento si propone di rendere le persone più informate e partecipi nell'ambito della governance.

Il Better Life Index è suddiviso in 11 sottotemi o macroaree, ognuna delle quali è supportata da uno a tre indicatori. All'interno di ciascuna delle macroaree, viene calcolata una media degli indicatori, ciascuno dei quali ha lo stesso peso nella valutazione. La scelta degli indicatori si basa su criteri statistici rigorosi, come la pertinenza (ovvero quanto un indicatore rifletta in modo adeguato il concetto che si intende misurare), la profondità (la capacità di catturare aspetti rilevanti del benessere), e la rilevanza politica (cioè quanto l'indicatore è utile per le decisioni politiche). Inoltre, la qualità dei dati è un criterio fondamentale nella selezione degli indicatori. Questo include la validità predittiva (la capacità di un indicatore di prevedere il benessere futuro), la copertura (quanto ampiamente l'indicatore può essere applicato a diverse realtà), la tempestività (la disponibilità dei dati in tempo reale o con aggiornamenti regolari), e la comparabilità tra paesi (la possibilità di confrontare dati tra nazioni diverse).
Tutti questi criteri sono stabiliti in consultazione con l'Organizzazione per la Cooperazione e lo Sviluppo Economico (OCSE) e i paesi membri di questa organizzazione. Gli indicatori selezionati sono quindi considerati buone misure dei concetti di benessere, specialmente quando si tratta di condurre un confronto tra paesi. Il Better Life Index mira quindi a fornire un quadro informativo completo e affidabile per valutare il benessere delle società a livello globale, incoraggiando un coinvolgimento significativo dei cittadini nel processo decisionale.

E' , quindi, un dataset multivariato che contiene più osservazioni, ciascuna con un set completo di valori per le variabili coinvolte. Questo significa che il dataset è costituito da una matrice di dati in cui le righe rappresentano le osservazioni e le colonne rappresentano le variabili. Sono presenti dati prevalentemente di tipo quantitativi.

Il dataset include le seguenti macroaree e relative variabili: 
  
  * **Housing**
    * **Dwellings without basic facilities**: Questo indicatore si riferisce alla percentuale della popolazione che vive in una residenza senza un water destinato esclusivamente all'uso delle loro famiglie. I water situati all'esterno della residenza non sono da considerare in questa categoria. Inoltre, vengono conteggiati anche i water situati in una stanza in cui è presente anche un'unità doccia o una vasca da bagno. Essenzialmente esprime la percentuale di famiglie che vive senza utilità di tipo primarie. 
    * **Housing expenditure**: Questo indicatore considera la spesa delle famiglie per l'abitazione e la manutenzione della casa, come definito nel Sistema delle Nazioni Unite (P31CP040: Alloggio, acqua, elettricità, gas e altri combustibili; P31CP050: Arredi, attrezzature per la casa e manutenzione ordinaria della casa). Essa comprende l'affitto effettivo e imputato per l'alloggio, la spesa per la manutenzione e la riparazione dell'abitazione (compresi servizi vari), l'approvvigionamento idrico, l'energia elettrica, il gas e altri combustibili, beni e servizi per la manutenzione ordinaria della casa come percentuale del reddito lordo disponibile delle famiglie. 
    * **Rooms per person**:  si riferisce al numero di stanze (escludendo cucina, dispensa, bagno, gabinetto, garage, studi medici, ufficio, negozio) in un'abitazione diviso per il numero di persone che vivono nell'abitazione.
  * **Income**
    * **Household net adjusted disposable income**: l'importo massimo che una famiglia può permettersi di consumare senza dover ridurre il proprio patrimonio o aumentare i propri debiti. Si ottiene sommando al reddito lordo delle persone (guadagni, reddito da lavoro autonomo) i trasferimenti sociali in natura che le famiglie ricevono dai governi, e quindi sottraendo le tasse sul reddito e sulla ricchezza. 
    * **Household net financial wealth**: la ricchezza finanziaria netta  composta da: oro monetario, valuta e depositi, titoli diversi dalle azioni, prestiti, azioni e altri strumenti patrimoniali (inclusi i titoli emessi dai fondi d'investimento). 
  * **Jobs**
    * **Employment rate**: Si tratta del numero di persone occupate di età compresa tra 15 e 64 anni rispetto alla popolazione della stessa fascia d'età. Le persone occupate sono coloro che hanno 15 anni o più e che dichiarano di aver lavorato in un'occupazione retribuita.
    * **Job security**: l' indicatore rappresenta il numero di dipendenti occupati con una anzianità lavorativa inferiore a 6 mesi rispetto all'occupazione dipendente totale. L'anzianità lavorativa è misurata in base alla durata del tempo durante il quale i lavoratori hanno svolto il loro attuale o principale lavoro o sono stati impiegati presso il loro attuale datore di lavoro.
    * **Long-term unemployment rate**: questo indicatore si riferisce al numero di persone che sono state disoccupate per un anno o più, espresso come percentuale della forza lavoro (la somma delle persone occupate e delle persone disoccupate).
    * **Personal earnings**: l' indicatore si riferisce alla retribuzione annua media per equivalente a tempo pieno di un dipendente , ottenuta dividendo il totale dei salari basati sui conti nazionali per il numero medio di dipendenti nell'economia complessiva, moltiplicato poi per il rapporto tra le ore medie settimanali solitamente lavorate da un dipendente a tempo pieno e le ore settimanali solitamente lavorate da tutti i dipendenti. 
  * **Community**: 
    * **Quality of support network**: esprime una misura del supporto percepito all'interno della rete sociale. Questo indicatore si basa sulla domanda: "Se avessi dei problemi, hai parenti o amici su cui puoi contare per aiutarti ogni volta che ne hai bisogno o no?" e tiene conto delle risposte positive da parte dei partecipanti. In altre parole, misura la percezione delle persone sulla disponibilità di parenti o amici pronti ad aiutarle in caso di necessità.
  * **Education**
    * **Educational attainment**: si tratta del numero di individui che hanno completato almeno con successo l'istruzione di livello secondario superiore rispetto alla popolazione compresa tra i 25 e i 64 anni.
    * **Student skills**: Il punteggio medio degli studenti nei test di lettura, matematica e scienze, valutato dal Programma per la Valutazione Internazionale degli Studenti (PISA) dell'OCSE. PISA è un programma di valutazione globale che misura le competenze degli studenti in queste tre aree chiave ed è utilizzato per confrontare le performance degli studenti in tutto il mondo. Il punteggio medio riflette le capacità medie degli studenti in queste materie in un determinato paese o regione.
    * **Years in education**: durata media degli studi in anni. 
  * **Environment**
    * **Air pollution**: si tratta di una misura della qualità dell'aria nelle aree urbane, con un'enfasi sulle città di dimensioni maggiori, in cui le concentrazioni di PM10 vengono ponderate in base alla popolazione residente. Questo indicatore fornisce una stima della contaminazione atmosferica e del potenziale impatto sulla salute dei residenti nelle aree urbane.
    * **Water quality**: misura il grado di soddisfazione delle persone riguardo alla qualità dell'acqua nell'area in cui vivono, basandosi sulle loro risposte soggettive.
  * **Civic engagemen**
    * **Consultation on rule-making**: L'indicatore è una media ponderata delle risposte sì/no a varie domande sulla presenza di consultazioni legali da parte dei cittadini e sulla presenza di procedure formali che consentano al pubblico in generale di influenzare la regolamentazione e le azioni governative. L'indicatore descrive l'entità in cui processi formali di consultazione sono integrati in fasi chiave della progettazione di proposte di regolamentazione e quali meccanismi esistono affinché l'esito di tali consultazioni influenzi la preparazione di leggi primarie e regolamenti subordinati. Le domande su cui si basa l'indicatore riguardano l'esistenza di procedure formali che permettono al pubblico in generale, alle imprese e alle organizzazioni della società civile di influenzare la regolamentazione e le azioni governative, nonché se le opinioni dei cittadini su tali procedure di consultazione siano rese pubbliche.
    * **Voter turnout**: la partecipazione elettorale è definita come il rapporto tra il numero di individui che hanno votato durante un'elezione  e la popolazione registrata per votare. Poiché le caratteristiche istituzionali dei sistemi di voto variano notevolmente tra i paesi e tra i tipi di elezioni, l'indicatore si riferisce alle elezioni che hanno attratto il maggior numero di elettori in ciascun paese. 
  * **Health**
    * **Life expectancy**: l'aspettativa di vita misura quanti anni in media le persone possono attendersi di vivere in base ai tassi di mortalità specifici per età. Questa misura si riferisce alle persone nate oggi e viene calcolata come una media ponderata dell'aspettativa di vita per gli uomini e le donne.
    * **Self-reported health**: si riferisce alla percentuale della popolazione di età superiore a 15 anni che dichiara di avere uno stato di salute "buono". L'Organizzazione Mondiale della Sanità (OMS) raccomanda di utilizzare un sondaggio standard di intervista sulla salute per misurare questo indicatore, formulando la domanda come "Come valuti la tua salute in generale?" con una scala di risposta che include "Molto buona/ Buona/ Sufficiente/ Cattiva/ Molto cattiva".
  * **Life Satisfaction**: misura il livello di soddisfazione e benessere generale delle persone in base alla loro percezione della loro situazione di vita rispetto ai loro migliori e peggiori scenari possibili.
  * **Safety**
    * **Assault rate**: la variabile misura la percentuale di persone che ha subito un'aggressione o una rapina entro l'arco dei 12 mesi precedenti all'indagine.
    * **Homicide rate**: numero annuale di omicidi intenzionali registrati dalla polizia.
  * **Work-life balance**
    * **Employees working very long hours**: proporzione dei dipendenti lavoratori il cui contratto di lavoro prevede 50 ore o più. 
    * **Time devoted to leisure and personal care**: quantità di minuti (o ore) al giorno che, in media, le persone impiegate a tempo pieno dedicano al tempo libero e alle attività di cura personale.



# Definizione degli obiettivi

La seguente analisi si pone degli obiettivi tramite l'utilizzo del database OECD, con particolare attenzione su tre aspetti principali. 

  * In primo luogo, nella parte precedente,  è stata condotta un'analisi delle serie storiche basata su osservazioni annuali per comprendere l'evoluzione di specifiche variabili nel tempo. Questo ha consentito di acquisire una prospettiva longitudinale e identificare eventuali tendenze o cambiamenti significativi.
  * In seguito, in questa parte,  ci si concentra su un anno specifico (il 2017), in cui verrà condotta un'analisi esplorativa e di clustering. Quest'ultima  permetterà di ottenere una visione più dettagliata dei pattern e delle relazioni presenti nei dati di quell'anno in particolare.
  * Infine, verrà scelta una variabile aleatoria sulla quale svolgere inferenza. 

L'obiettivo principale è capire quali elementi hanno un impatto significativo sul livello di benessere e qualità della vita.


# DATA WRANGLING

Il "data wrangling," spesso chiamato anche "data munging" rappresenta
un passaggio cruciale nell'analisi dei dati. Molto spesso si hanno a
disposizione un insieme di dati grezzi provenienti da diverse fonti.
Questi dati possono essere disorganizzati, contenere errori, dati
mancanti o informazioni in formati diversi. Senza una preparazione
adeguata, l'analisi e la modellazione dei dati sarebbero difficili, se
non impossibili.

Il data wrangling è il processo di trasformazione dei dati disordinati e sporchi in un formato coerente e adatto all'analisi. Il passaggio
comporta molteplici attività, tra cui la pulizia dei dati per correggere errori e rimuovere duplicati, la standardizzazione delle unità di misura, la trasformazione dei dati categorici in forme numeriche comprensibili, e la creazione di nuove variabili o caratteristiche quando necessario.

L'obiettivo finale del data wrangling è creare un dataset pulito, coerente e pronto per essere analizzato, riducendo così i potenziali errori e garantendo che i risultati dell'analisi siano accurati e significativi.

## Raccolta dei dati e importazione del dataset

Il primo passo è quello di caricare in memoria il dataset per l'analisi.
Poichè è un dataset di tipo excel è necessario installare la libreria apposita contenente funzioni necessarie al caricamento dei dati.

### Import del dataset

Viene quindi caricato il set di dati in memoria. Il dataset ,contenuto nel file csv/excel etc , viene letto in un dataframe. Il dataframe è la struttura dati utilizzata da R per memorizzare una matrice di dati.

```{r}
bl_total <- read_excel("C:/Users/carme/OneDrive/Desktop/UNIVERSITA 2/STATISTICA E ANALISI DEI DATI/Datasets/Better_life_2017_total.xlsx")




bl_men <- read_excel("C:/Users/carme/OneDrive/Desktop/UNIVERSITA 2/STATISTICA E ANALISI DEI DATI/Datasets/Better_life_2017_men.xlsx")
bl_women <- read_excel("C:/Users/carme/OneDrive/Desktop/UNIVERSITA 2/STATISTICA E ANALISI DEI DATI/Datasets/Better_life_2017_women.xlsx")
bl_women$Sex<-(rep('F'))
bl_men$Sex<-rep('M')
bl_merge<- rbind(bl_men, bl_women)
bl_merge<- bl_merge[-36, ]
bl_merge$Sex<-as.factor(bl_merge$Sex)
bl_merge$`Dwellings without basic facilities`<-as.numeric(bl_merge$`Dwellings without basic facilities`)
bl_merge$`Rooms per person`<-as.numeric(bl_merge$`Rooms per person`)
bl_merge$`Household net adjusted disposable income`<-as.numeric(bl_merge$`Household net adjusted disposable income`)
bl_merge$`Housing expenditure`<-as.numeric(bl_merge$`Housing expenditure`)
bl_merge$`Household net adjusted disposable income`<-as.numeric(bl_merge$`Household net adjusted disposable income`)
bl_merge$`Air pollution`<-as.numeric(bl_merge$`Air pollution`)

val_med<-median(bl_merge$`Air pollution`)
var<-(ifelse(bl_merge$`Air pollution`<val_med, 0, 1))
bl_merge<-bl_merge
bl_merge$`Air pollution`<-as.factor(var)


bl_merge$`Household net financial wealth`<-as.numeric(bl_merge$`Household net financial wealth`)

```

Il dataset viene letto in una struttura dati detta *tibble*, che è una forma moderna di dataframe, in cui vengono mantenute le caratteristiche base del dataframe. 
    
La classe del dataframe è appunto tibble. 
```{r}
class(bl_total)
```

### Panoramica dei dati

Si utilizza il comando [ head() ]{style="font-family: 'Courier New';"}
per visualizzare le prime unità statistiche.

```{r}
head(bl_total)
```

Invece, si utilizza il comando [ tail()
]{style="font-family: 'Courier New';"} per visulizzare le ultime
osservazioni del dataset.

```{r}
tail(bl_total)
```


  
Sono quindi presenti 38 osservazioni relative agli stati dell'indagine e 25 variabili di descrizione. 
```{r}
dim(bl_total)
```


## Pulizia dei dati (data cleaning)

I dati grezzi sono spesso [disordinati]{style="font-style: italic;"} e
[formattati male]{style="font-style: italic;"}. Inoltre, potrebbero
mancare definizioni appropriate che tengano conto della scala di
misurazione utilizzata.

Per cui la pulizia dei dati consiste nel procedimento mediante il quale si esaminano e si migliorano i dati contenuti nel dataset, con l'obiettivo di assicurare che siano di alta qualità e validi per l'analisi statistica. Le procedure che caratterizzano questo passaggio sono le seguenti:

-   **Analisi dei missing values.** Si verifica la presenza/assenza dei valori mancanti (NA) che può notevolmente influire sull'analisi. Si procede , quindi, decidendo di eliminarli (*na.omit*) sostituendoli con valori reali (esempio: imputazione di media o mediana).
-   **Individuazione di valori anomali.** Si esamina attentamente il dataset per individuare eventuali valori inesatti o insoliti, e si prendono decisioni su come trattarli. Queste decisioni possono    includere l'eliminazione dei valori problematici o la loro sostituzione con valori appropriati.
-   **Trasformazione delle variabili.** Si verifica che tutte le variabili abbiano la classe appropriata. ([Double o Integer]{style="font-style: italic;"} per i numeri, [factor]{style="font-style: italic;"} per le variabili categoriali, [ordered]{style="font-style: italic;"} per le variabili categoriali ordinate).
-   **Implementazione di nuove variabili.** Sulla base delle variabili già presenti nel dataset si possono creare delle nuove variabili, ad esempio facendo operazioni matematiche tra due variabili o creando una variabile multilivello sulla base di una variabile numerica.

### Analisi dei missing values

Si verifica la presenza degli NA nel dataset. Nel dataset non sono presenti NA per l anno corrente.


```{r}
sum(is.na(bl_total))
```


### Individuazione di valori anomali

Per l'individuazione di valori anomali o errati è possibile utilizzare la funzione [summmary()]{style="font-style: Courier New;"}. La funzione fornisce un resoconto automatico delle statistiche di base per ciascuna variabile nel dataset. Queste statistiche comprendono il valore minimo, il valore massimo, la media, la mediana e la deviazione standard. Se la variabile è numerica, vengono calcolati anche i quartili e il range interquartile. Nel caso in cui la variabile sia di tipo carattere o un factor, la funzione restituirà il conteggio delle osservazioni per ciascun livello o valore univoco presente nella variabile stessa.

```{r}
summary(bl_total[,-1])
```
```{r}
# bl_total[which.max(bl_total$`Employment rate`),]%>%
#   select(Stato, `Employment rate`)
# bl_total[which.min(bl_total$`Employment rate`),]%>%
#   select(Stato, `Employment rate`)
# 
# bl_total[which.max(bl_total$`Life expectancy`),]%>%
#   select(Stato, `Employment rate`)
# bl_total[which.min(bl_total$`Life expectancy`),]%>%
#   select(Stato, `Employment rate`)

```
Nello studio dei dati, vengono quindi esaminati una serie di indicatori che forniscono una visione approfondita della qualità della vita e del benessere. 
Partendo dall'indicatore "Abitazioni senza servizi di base," si osserva che circa il 50% degli stati esprime un valore medio prossimo all'1, il che significa che in media l'un per cento delle famiglie potrebbero ancora affrontare sfide legate all'accesso a servizi essenziali come l'acqua corrente e i servizi igienici.
Le "Spese per l'abitazione" costituiscono una parte significativa della spesa familiare, con una media di circa 20,87 dollari. Media e mediana coincidono esprimendo una possibilità di distribuzione pressocchè simmetrica, la questione verrà approfondita successivamente.
Il numero medio di "Stanze per persona" è di circa 1,65, ma con variazioni significative. 
In termini di reddito, il "Reddito familiare netto disponibile aggiustato" è di circa 25.254 dollari. Tuttavia, essendoci una presenza di stati con ricchezza territoriale e lavorative diverse, questo fa si che ci si confronti con patrimoni diversi fino a un massimo di 44049. Lo stesso problema si riflette in maniera più evidente sul "Patrimonio finanziario netto delle famiglie" con valore medio di circa 50.419 dollari. Per questa variabile la differenza tra il terzo e quarto quartile è di oltre 100000 unità monetario dando evidenza di probabili outlier o valori anomali. 
Il "Tasso di occupazione" medio è del 67,72%, il che rappresenta la percentuale di persone in età lavorativa attualmente impiegate, il minimo è prossimo al 44% per il Sud Africa mentre il massimo all'88% per l'Islanda. 
L'"Aspettativa di vita" media di circa 79,55 anni suggerisce una buona prospettiva di salute e longevità. Il paese con aspettativa di vita più alta è il Giappone con 84 anni mentre il più basso è del Sud Africa con aspettativa di vita prossima ai 57 anni. 

Questi indicatori  forniscono una panoramica completa delle condizioni di vita tenendo conto ,tuttavia, delle differenze che caratterizzano ciascun paese.  L'analisi di questi dati costituisce un passo importante per identificare i fattori positivi e negativi al fine di aumentare il benessere generale. L'analisi dettagliata di ciascuna variabile si terrà in seguito con il relativo approfondimento su valori anomali. 



## Descrizione del dataset

Dalla descrizione delle variabili del dataset "better life index" mostrata in tabella , è possibile comprendere che , ad esempio:
-   al tipo *chr* (*carattere*), ovvero una stringa di testo, appartengono le variabili relative allo stato come unità statistica;
-   al tipo *numeric* (*numerico*), ovvero i numeri con la virgola mobile, fanno parte le variabili che esprimono una percentuale, come: tasso di occupazione, tasso di omicidio, tempo dedicato alla cura personale etc..;
-   al tipo *integer* (*numeri interi*), ovvero i numeri interi senza decimali, appartengono le variabili: qualità dell'aria e dell'acqua, spese per la casa, reddito etc..;

```{r}
str(bl_total)
```



# EDA (Exploratory data analysis)

L'EDA (Analisi Esplorativa dei Dati) è un approccio all'analisi del set di dati per riassumere le loro caratteristiche principali, spesso con metodi di visualizzazione e grafici. Questo passaggio viene svolto preventivamente all'applicazione di modelli statistici poichè serve a capire cosa effettivamente i dati sono in grado di comunicare. Gli obiettivi principali dell'EDA sono:

-   **Massimizzare l'intuizione in un set di dati**. L'EDA aiuta    ottenere una comprensione approfondita dei dati. Consente di esaminare le caratteristiche principali, le distribuzioni delle variabili, le relazioni tra di esse e i possibili valori anomali.
-   **Scoprire la struttura sottostante**. Durante l'EDA, vengono creati grafici e visualizzazioni che consentono di esplorare la distribuzione dei dati. Queste visualizzazioni possono includere istogrammi, grafici a dispersione (scatter plot), diagrammi a barre e etc.. La visualizzazione dei dati fornisce un'immagine visiva della struttura dei dati, evidenziando modelli o tendenze che potrebbero non emergere in modo evidente dai dati grezzi.
-   **Effettuare confronti**. I grafici permettono di confrontare diverse categorie o gruppi di dati, ad esempio analizzando e confrontando le distribuzioni o le frequenze di diverse variabili.
-   **Condividere i risultati**. l'utilizzo di grafici consente di esporre in modo efficace i risultati di un'analisi a un pubblico più vasto, comprese le persone che non hanno una conoscenza approfondita di statistica o analisi dei dati. Ad esempio, è possibile includere un grafico all'interno di un report o di una presentazione per presentare chiaramente e in modo sintetico i risultati dell'analisi.

In letteratura l'analisi dei dati distingue in maniera cruciale tre
sezioni:

-   **Analisi univariata** , i metodi appartenenti a questa sezione
    esaminano una variabile (colonna di dati alla volta);
-   **Analisi bivariata** in cui l'esplorazione viene svolta su coppie
    di variabili (sia dello stesso tipo che di tipo diverso);
-   **Analisi multivariata** in cui vengono coinvolti metodi in cui
    vengono esaminate tre o più variabili alla volta per esplorare le
    relazioni.

Nella strutturazione dell'analisi delle variabili del progetto, si terrà conto della distinzione appena presentata. Questi tre approcci consentono di esplorare le caratteristiche delle variabili da diverse prospettive, permettendo di avere una comprensione più completa dei dati e delle relazioni tra le variabili coinvolte nello studio statistico.

# ANALISI UNIVARIATA

L'analisi univariata permette di esplorare una variabile alla volta.
Le [Statistiche descrittive]{style="font-family: 'Courier New';"} sono
strumenti cruciali per riassumere un gruppo di osservazioni nel modo più semplice possibile.

Per le variabili categoriali:
  1. si calcolano le tabelle di frequenza 
  2. diagramma a barre 
  3. pie chart

Per le variabili quantitative: 
  1. si calcolano le misure di posizione o tendenza centrale come media, mediana e quartili 
  2. misure di dispersione come la deviazione standard, MAD, varianza etc..
  3. misure di forma come asimmtria e curtosi 
  4. boxplots 
  5. stime di densità Kernel
  6. Normal probability plots

Proseguendo con l'analisi delle variabili qualitative:

## Tabelle di frequenza (per le variabili categoriali)

Per esplorare le variabili categoriali le tabelle di frequenza sono uno degli strumenti più efficaci e semplici. Si utilizza il comando
[table(dataset$variabile$)]{style="font-family: 'Times New Roman';"} per ottenere il conteggio delle osservazioni per ogni categoria di una
variabile. Nel caso in cui fossero presenti NA, la funzione è utile perchè questi ultimi vengono conteggiati e segnalati nella tabella di frequenza.

Poichè all'interno del dataset non sono presenti variabili categoriali, è possibile trasformare variabili numeriche in categoriali sotto un criterio specifico. 
In tal caso, si è deciso di distinguere, per il puro scopo esplorativo, due variabili in particolare: **Air pollution** e **Life Satisfaction**. 
Il criterio logico che giustifca la scelta è il seguente: per ciascuna variabile è possibile individuare un valore soglia (media o mediana della variabile numerica) che riesca a distinguere le unità statistiche (o i paesi) in due gruppi, gli stati che hanno valori al di sotto e al di sopra del valore soglia tale da costruire una separazione netta. 

## Air pollution (Variabile 1)

### Tabella di frequenza

```{r}
val_med<-median(bl_total$`Air pollution`)
var<-(ifelse(bl_total$`Air pollution`<val_med, 0, 1))
dat1<-bl_total
dat1$`Air pollution`<-as.factor(var)

val_m<-mean(bl_total$`Life satisfaction`)
var_2<-(ifelse(bl_total$`Life satisfaction`<val_m, 0, 1))
dat1$`Life satisfaction`<-as.factor(var_2)
```

La variabile **AirPollution** rappresenta la contaminazione dell'aria. Questa vale 1 per i paesi il cui valore è maggiore della mediana mentre vale 0 altrimenti. E' una variabile categorica nominale (factor), in quanto i valori possibili sono limitati e non possono essere ordinati in base alla loro scala di valore. 

```{r}
var1 <- data.frame( Frequenza=c(table(dat1$`Air pollution`)), Frequenza_percentuale=c(table(dat1$`Air pollution`)/nrow(dat1)*100))
var1
```

Sono presenti 18 osservazioni con valore di airpollution al di sotto della mediana e 21 con valori maggiori dela mediana. 

Per visualizzare la variabile **AirPollution** si può utilizzare un grafico a barre e un grafico a torta. 

### Grafico a barre e a torta

Nel grafico a barre ogni barra rappresenta il numero di osservazioni per il livello della variabile.


Il grafico a torta è un tipo di grafico utilizzato per visualizzare le frequenze di una variabile di tipo carattere o factor. In particolare, ogni settore della torta rappresenta la percentuale di osservazioni per un determinato livello o valore univoco della variabile.

```{r, warning=FALSE}
theme_1<-theme(panel.background = element_rect(fill = '#83c8ac', color = '#9a8262'),
panel.grid.major = element_line(color = '#ffffff', linetype = 'longdash'),
panel.grid.minor = element_line(color = '#83c8ac', size = 0.7,linetype = "dotdash"))
plot1<-ggplot(data=dat1, mapping= aes(x=`Air pollution`))+geom_bar(color='black', fill='white')+ ggtitle("Grafico a barre")+theme_1
Inquinamento_Aria <- factor(dat1$`Air pollution`,
levels = names(sort(table(dat1$`Air pollution`))))
p2 <- ggplot(dat1, aes(x = "", y = `Air pollution`, fill = Inquinamento_Aria)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y") + theme_void()+  scale_fill_brewer(palette = "Greens")+ggtitle("Pie chart")
 

p2 <- p2 +theme_minimal()

grid.arrange(plot1, p2, ncol = 2)

```



## Life Satisfaction (Variabile 2)

### Tabella di frequenza

La variabile **life satisfaction** rappresenta la soddisfazione media degli individui riguardo la propria vita. La variabile factor è costruita a partire dalla variabile numerica, dopo aver individuato il valore medio, ciascuno stato in corrispondenza della feature assume valore 0 se si trova al di sotto della media di soddisfazione di vita 1 altrimenti. Dato il campione ristretto, il numero di osservazioni si riduce al 43% degli stati con soddisfazione di vita al di sotto della media mentre il restante 57% al di sopra. 

```{r}
var2 <- data.frame( Frequenza=c(table(dat1$`Life satisfaction`)), Frequenza_percentuale=c(table(dat1$`Life satisfaction`)/nrow(dat1)*100))

var2
```

### Grafico a barre

Per la rappresentazione grafica, essendo una variabile factor, è possibile rappresentare la distribuzione tramite il grafico a barre. La disparità tra le due classi è più evidente della variabile precedente. L'asse delle y rappresenta il numero di stati mentre l'asse delle x è espressione delle due entità della feature.  

```{r}
p1 <- ggplot(dat1, aes(x = `Life satisfaction`)) +
geom_bar(color = "black", fill = "white") +
theme(axis.text.x = element_text(angle = 90)) + ylab("Numero di stati")
p1 <- p1 +theme_1
p1
```


### Lollipop Chart

Un metodo alternativo per la visualizzazione di una variabile categoriale è il lollipop chart. Un *Lollipop Chart* è un grafico che presenta punti di dati come cerchi o dischi ("lollipops") posti su un asse orizzontale, che rappresenta una variabile indipendente o categoria. Ogni lollipop rappresenta un singolo punto dati e la sua posizione sull'asse orizzontale indica il valore di quella variabile.
Il "lollipop" è collegato a una linea verticale o "astina" che si estende verso sinistra da ciascun punto dato fino a una seconda scala. La seconda scala rappresenta la variabile dipendente o un valore di riferimento, come una media o una soglia. 

Per cui, 16 stati hanno valore medio della soddisfazione dell'individuo al di sotto della media complessiva, mentre circa 22 stati hanno valore medio della soddisfazione al di sopra della media.  
```{r, warning=FALSE}


data <- data.frame( y=c(table(dat1$`Life satisfaction`)), x=c('Soddisfazione < media', 'Soddisfazione>media'))

# Reorder the data
data <- data %>%
  arrange(y) %>%
  mutate(x=factor(x,x))

# Plot
p <- ggplot(data, aes(x=x, y=y)) +
  geom_segment(
    aes(x=x, xend=x, y=0, yend=y), 
    color=ifelse(data$x %in% c("A","D"), "orange", "#83c8ac"), 
    size=ifelse(data$x %in% c("A","D"), 1.3, 0.7)
  ) +
  geom_point(
    color=ifelse(data$x %in% c("A","D"), "orange", "#83c8ac"), 
    size=ifelse(data$x %in% c("A","D"), 5, 2)
  ) +
  coord_flip() +theme_minimal()+
  theme(
    legend.position="none"
  ) +
  xlab("") +
  ylab("Numeri di stati") +
  ggtitle("Come si distribuisce la soddisfazione di vita negli stati?")

p 
```

### Donut chart
 
Il "Donut Chart" è un grafico circolare diviso in sezioni, o "fette," che rappresentano le diverse categorie di dati. Ogni fetta corrisponde a una categoria specifica e la dimensione di ciascuna fetta è proporzionale alla percentuale che quella categoria rappresenta rispetto al totale. E' un'alternativa al "Pie Chart" distinguendosi per il foro al centro, che crea un anello vuoto. Il "Donut Chart" è utile per visualizzare chiaramente come le diverse categorie contribuiscono a un totale, e la dimensione dell'anello interno rappresenta il totale complessivo. 

Ancora una volta la lettura delle informazioni è in percentuale, il 57% degli stati ha valore di soddisfazione al di sopra della media mentre il 43% al di sotto. 
```{r}
data <- data.frame( count=c(table(dat1$`Life satisfaction`)), category=c('Soddisfazione < media', 'Soddisfazione>media'))

df <- data.frame(value = c(table(dat1$`Life satisfaction`)),
                 Gruppo = c('Soddisfazione < media', 'Soddisfazione>media'))

hsize <- 4


df1 <- df %>% 
  mutate(x = hsize)


plot1<-ggplot(df1, aes(x = hsize, y = value, fill = Gruppo)) +
  geom_col(color = "black") +
  geom_text(aes(label = c('43%','57%')),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +
  scale_fill_brewer(palette=4) +
  xlim(c(0.2, hsize + 0.5)) +  theme(panel.background = element_rect(fill = "white"),
                                     panel.grid = element_blank(),
                                     axis.title = element_blank(),
                                     axis.ticks = element_blank(),
                                     axis.text = element_blank())+ggtitle('Soddisfazione di vita ')

plot1
```



## Indici di sintesi

Gli indici di sentesi, detti anche statistiche, sono utili a descrivere i dati numerici. Si fa riferimento a media, mediana, moda, varianza, deviazione standard. La media, moda e mediana sono misure di centralità, mentre la varianza e deviazione standard misurano la dispersione dei dati.

### Media campionaria

La **media campionaria** è la media aritmetica dei valori in
corrispondenza di ciascuna osservazione. Si consideri ad esempio la variabile della ricchezza finanziara netta , **Household net financial wealth**. Il valore della media campionaria è: 

```{r}
mean(bl_total$`Household net financial wealth`)
```
Nel contesto della ricchezza finanziaria, una media di 49362.79 dollari indica che, se si considerano tutte le famiglie nella popolazione, la quantità media di ricchezza finanziaria posseduta è di circa 49362.79 dollari.


[Definizione. ]{style="font-family: 'Anastasia';"}. Dati i livelli
osservati ${x_1,x_2,...,x_n}$ per una variabile $X$, si definisce la
media come:

$$\overline x = \frac1n \sum^n_{i=1}x_i$$

La media campionaria è importantissima poichè utilizza tutti i dati ed è influenzata in maniera sensibile dai valori eccezionalmente alti o bassi. L'importanza della media è dovuta, tuttavia, alla proprietà che soddisfa: la *somma degli scarti è nulla*, per cui la media costituisce il baricentro di una distribuzione di frequenza.

Definiti gli *scarti della media* come $(x_i - \overline x)$,
$\forall i= 1, 2, ..., n$, si ottiene:

$$\sum^n_{i=1} (x_i-\overline x) = \sum^n_{i=1}(x_i) - \sum^n_{i=1}(\overline x) = \sum^n_{i=1}x_i - n\overline x= \sum^n_{i=1}(x_i) -n (\sum^n_{i=1}(x_i)/n)=\sum^n_{i=1}(x_i)-\sum^n_{i=1}(x_i)=0$$

per cui, implica che la media $\overline x$ , essendo interna ai valori delle modalità di $X$, presenterà alcuni scarti positivi, eventualmente alcuni nulli ed altri negativi. La media $\overline x$ è il valore che bilancia esattamente positivi e negativi in quanto baricentro di una distribuzione di masse.

### Mediana campionaria

La **mediana campionaria** è la modalità dell'unità statistica che
occupa il posto centrale nella distribuzione ordinata delle
osservazioni. La media della ricchezza finanziaria è: 

```{r}
median(bl_total$`Household net financial wealth`)
```
La mediana è significativamente diversa dalla media, per  cui potrebbe indicare la presenza di valori estremi che influenzano la media.

[Definizione. ]{style="font-family: 'Anastasia';"}. Dati i livelli
osservati ${x_1,x_2,...,x_n}$ per una variabile $X$, si definisce la
mediana , indicata con [Med(X) ]{style="font-family: 'Courier New';"},
il quantile a livello $\alpha = 50%$. La mediana campionaria dipende da solo uno o due valori centrali dei dati e non risente dei valori
estremi. La mediana è una posizione sia di posizione , in quanto
individua un punto nel range dei dati, sia di centralità perchè
individua un punto che divide il range in parti contenenti uguale massa di dati.


### Moda campionaria

La **moda** è la modalità a cui corrisponde la massima frequenza,
assoluta o relativa.

[Definizione. ]{style="font-family: 'Anastasia';"}. Dati i livelli
osservati ${x_1,x_2,...,x_n}$ per una variabile $X$, si definisce la
moda , indicata con [Mod(X) ]{style="font-family: 'Courier New';"}: 

  * il livello osservato più frequentemente nei dati *non continui*; 
  * il livello di massima densità nei dati *continui*.

A differenza di *media* e *mediana* può essere calcolata per qualsiasi
tipo di variabile. Non esiste in R una funzione per estrarre la moda o
la classe modale di una distribuzione di dati poiché è facilmente
ricavabile osservando il grafico delle frequenze assolute o l'istogramma delle frequenze relative, ma è possibile dedurlo manualmente. Vale 10000 per la variabile in analisi. 

```{r}
moda<-function(x){
h<-hist(x, plot = FALSE)
kmoda<-which.max(h$density)
mod<-h$mids[kmoda]
mod}
moda(bl_total$`Household net financial wealth`)
```

### Quartili, decili, percentili

Anche i **quantili** possono essere visti come misure di posizione.
Tuttavia, seguono un *principio di localizzazione* diverso.

[Definizione. ]{style="font-family: 'Anastasia';"}. Per serie di
quantili intendiamo i quantili calcolati su una griglia di valori
${\alpha_1,\alpha_2,...,\alpha_n}$ equispaziata.

**I Quantili** si ottengono dividendo l'insieme di dati ordinati in 4
parti uguali. Nel caso studio, questi sono i quantili della ricchezza patrimoniale:

  * **Primo Quantile (25%)**: Il primo quantile rappresenta il 25% inferiore della distribuzione dei dati sulla ricchezza patrimoniale. Questo valore indica che il 25% delle famiglie degli stati presi in considerazione ha una ricchezza patrimoniale inferiore a 19082,5 dollari.

  * **Mediana (50%)**: la mediana della ricchezza patrimoniale è di 43493,0 dollari. Ciò significa che il 50% della popolazione ha una ricchezza patrimoniale inferiore a questo valore e il restante 50% ha una ricchezza patrimoniale superiore a questo valore.

  * **Terzo Quantile (75%)**: il 25% delle famiglie degli stati ha una ricchezza patrimoniale superiore a 73842,0 dollari.

```{r}
quantile(bl_total$`Household net financial wealth`, probs = c(0.25,0.50,0.75))

```

**I Decili** , invece, dividono la distribuzione in 10 parti uguali.

```{r}
quantile(bl_total$`Household net financial wealth`, probs=seq (0, 1, 0.1))

```

**I Percentili** dividono la distribuzione in 100 parti uguali.

```{r}
quantile(bl_total$`Household net financial wealth`, probs=seq (0, 1, 0.01))

```

### Varianza e deviazione standard

L'indice più importante per misurare la variabilità di una distribuzione espresso dalla media degli scarti al quadrato è la **varianza**, dove per variabilità si intende la dispersione rispetto al centro della distribuzione. La **varianza campionaria** è così definita.

[Definizione. ]{style="font-family: 'Anastasia';"}. Sia
${x_1,x_2,...,x_n}$ un campione osservato con media $\overline x$. Si
definisce [ Varianza campionaria]{style="font-family: 'Courier New';"}
la quantità: $$s^2 = \frac {1}{n-1} \sum^n_{i=1}(x_i - \overline x)^2$$

con $$(n=2,3,...)$$


-   $s^2$ sarà tanto più grande se la dispersione rispetto a
    $\overline x$ è grande e sarà tanto più piccola se la dispersione
    rispetto a $\overline x$ è piccola.
-   $s^2$ è tanto più piccola quanto più $\overline x$ è
    rappresentativa/centrale per la distribuzione.

Per la ricchezza patrimoniale la varianza è pari a: 

```{r}
var(bl_total$`Household net financial wealth`)
```
Sulla quale è possibile svolgere delle considerazioni: 

  * 1. **Quantità di Variabilità**: una varianza di 1502434845 implica che i dati nella variabile sono piuttosto dispersi o variabili per cui ci sono differenze significative tra i singoli valori osservati nella variabile. 

  * 2. **Scostamenti Quadrati**: la varianza viene calcolata utilizzando gli scostamenti quadrati tra ciascun dato e la media dei dati. Questo significa che le differenze positive e negative sono elevate al quadrato, il che può amplificare l'effetto delle deviazioni dai valori medi.

  * 3. **Unità di Misura Quadrata**: La varianza ha unità di misura quadrata. Ad esempio, la variabile rappresenta la ricchezza patrimoniale e ha dollari come moneta, la varianza avrà come indicatore dollari al quadrato, il che potrebbe non essere facilmente interpretabile in termini reali. Per ottenere una misura della dispersione nella stessa unità di misura della variabile, si utilizza la radice quadrata della varianza, chiamata deviazione standard.


[Definizione. ]{style="font-family: 'Anastasia';"}. Sia
${x_1,x_2,...,x_n}$ un campione osservato con media $\overline x$ e
varianza $s^2$. Si definisce [ Deviazione standard
campionaria]{style="font-family: 'Courier New';"} la radice quadrata
della varianza:

$s= \surd(s^2)$

```{r}
sd(bl_total$`Household net financial wealth`)
```
I dati nella variabile sono distribuiti in modo tale che, in media, ciascun dato si discosta dalla media della variabile in questione di circa 38708,25 dollari.

**Osservazioni sulla varianza**.

-   sia la varianza che la deviazione standard sono misure non negative;
-   var e sd sono uguali a 0 **se e solo se** tutte le $x_i$ sono uguali alla media $\overline x$;
-   la varianza non ha un massimo quindi non è possibile fare
    valutazioni assolute;
-   è possibile confrontare varianze di una stessa variabile misurata su campioni diversi, posto che siano espresse nella stessa unità di misura.

### Coefficiente di variazione

Poichè varianza e scarto quadratico medio sono indici assoluti è bene
parlare di indici relativi.

[Definizione. ]{style="font-family: 'Anastasia';"}. Si definisce [
Coefficiente di variazione]{style="font-family: 'Courier New';"} come
rapporto della varianza campionaria e il valore assoluto della media
campionaria. E' un coefficiente privo d iunità di misura, ovvero un
numero puro, che esprime la variazione media del fenomeno in rapporto
alla sua media utile per confrontare la variabilità di un fenomeno in
circostanze differenti.

$$CV=\frac {s}{|\overline x|}$$
Per la variabile di benessere economico il coefficiente di variazione vale : 


```{r}
cv <- function(x){
 sd(x)/abs(mean(x))}

cv(bl_total$`Household net financial wealth`)
```
Il risultato indica che la deviazione standard è pari al 76.88% della media dei dati, suggerendo che la variabilità relativa dei dati è abbastanza elevata, poiché la deviazione standard è significativamente più grande della media.
Il risultato è una possibile indicazione di distribuzione dei dati con valori estremi o una variazione significativa tra le osservazioni. (Basti osservare la differenza tra terzo quartile e valore massimo per questa osservazione, si distanziano di circa 100 mila dollari). 


### Coefficiente di simmetria

Nella descrizione di una distribuzione risulta fondamentale la definizione di **asimmetria**. Se la media supera la mediana, significa che la distribuzione si *attarda* verso valori alti e quindi superiori alla mediana, per cui si è in presenza di una distribuzione che presenta una coda più pesante verso il semiasse positivo delle $x$, in tal caso si parla di **asimmetria positiva**. Per contro, se la media è inferiore alla mediana, si è in presenza di una distribuzione che presenta una coda più pesante verso sinistra, e quindi, si parla di **asimmetria negativa**.

$$\gamma=\frac{Q_1+Q_3-2Q_2}{Q_3-Q_1}$$

-   Per $\gamma=0$ la distribuzione di frequenze è simmetrica;
-   Per $\gamma>=0$ la distribuzione di frequenze è asimmetrica positiva (la coda di destra è più lunga)
-   Per $\gamma<0$ la distribuzione di frequenze è asimmetrica negativa (la coda di sinistra è più lunga)


L'indice di simmetria per la variabile del benessere economico è positivo per cui è espressione di asimmetria positiva nella distribuzione, esprimendo code più lunghe verso la fine della distribuzione. 

```{r}
simmetria<-function(x){
Q<-quantile(x, probs=c(0.25, 0.5, 0.75))
a<-{Q[1]+Q[3]-2*Q[2]}/{Q[3]-Q[1]}
a}

simmetria(bl_total$`Household net financial wealth`)
```

### Coefficiente di curtosi

La curtosi è una proprietà relativa alla velocità con cui la densità dei
dati diminuisce man a mano che ci allontaniamo dal centro andando verso
i valori estremi. Si definisce **curtosi campionaria** il valore:

$$\gamma_2=\beta_2 -3$$

dove $\beta_2= frac{m_4}{m_4/3}$ è l'indice di pearson adimensionale.
Gli indici $\beta_2 e \gamma_2$ permettono di confrontare la distribuzione di frequenze dei dati con una densità di probabilità normale standard, caratterizzata da $\beta_2=3$ e indice di curtosi
$\gamma_2=0$. Se risulta:

-   $\beta_2<3$($\gamma_2<0$): la distribuzione di definisce
    **platicurtica**, ossia la distribuzione è più piatta di una normale
    (code meno pesanti della n.);
-   $\beta_2>3$($\gamma_2>0$): la distribuzione di definisce    **leptocurtica**, ossia la distribuzione è più a punta di una
normale (code più pesanti della n.);
-   $\beta_2=3$($\gamma_2=0$): la distribuzione di definisce    **normocurtica**, ossia la distribuzione piatta come una normale (code spesse come quelle della n.);

Il calcolo della curtosi campionaria è significativo soprattutto quando si analizzano distribuzioni di frequenze unimodali, in quanto questo indice viene confrontato con la curtosi di una distribuzione normale standard.

Per la variabile relativa al benessere finanziario l'indice di curtosi è positivo espressione di distribuzione platicurtica. 

```{r}
curtosi<-function(x){
 val<-mean(scale(x)^4)-3
val
}
curtosi(bl_total$`Household net financial wealth`)
```

### Funzione di distribuzione empirica

L'ECDF, che sta per **"Empirical Cumulative Distribution Function"** ( "Funzione di Distribuzione Cumulativa Empirica"), è una funzione statistica utilizzata per rappresentare la distribuzione cumulativa empirica di un insieme di dati,ovvero mostra quanto siano distribuiti i dati rispetto alla loro frequenza cumulativa.

[Definizione. ]{style="font-family: 'Anastasia';"}. Si definisce [Funzione di distribuzione empirica]{style="font-family: 'Courier New';"} nel punto $t$, data una variabile $X$ quantitativa e ${x_1,x_2, ...,x_n}$ un campione osservato:

$$F(t)= (proporzione delle osservazioni<=t) = \frac{1}{n} \sum^n_{i=1}(1(x_i<=t))$$


Funziona in questo modo: 

  1. **Creazione dell'ECDF**: Per costruire l'ECDF, si ordinano i dati in              ordine crescente e si assegna a ciascun dato una probabilità cumulativa             basata sulla sua posizione nell'ordine. Semplicemente si calcola la                 percentuale di dati che sono inferiori ouguali a ciascun valore nei dati.
  2.  **Rappresentazione grafica**: L'ECDF viene solitamente rappresentata graficamente attraverso un diagramma a scala di        probabilità. Sull'asse delle ascisse (orizzontale) sono posizionati i valori dei dati, mentre sull'asse delle ordinate (verticale) si trova la probabilità cumulativa corrispondente. L'ECDF inizia a zero e raggiunge uno quando tutti i dati sono stati considerati.
  3.  **Interpretazione**: Guardando il plot, è possibile determinare facilmente la percentuale di dati al di sotto o al di sopra di        un valore specifico. Ad esempio, se l'ECDF raggiunge il valore 0,75 a un certo punto, significa che il 75% dei dati è inferiore o uguale a quel valore.

```{r}

# 
# Per calcolare le frequenze cumulative e ottenere il grafico della
# funzione di distribuzione empirica continua, si utilizza la
# funzione cut()  per creare classi con intervalli chiusi a sinistra invece che a destra. Successivamente viene calcolata la funzione di somma cumulata. In questo modo si stanno trasformando dati numerici in qualitativi assegnandoli a classi specificate arbitrarie prestabilite. 

#Come primo step creo le classi:
#Frequenza relativa delle osservazioni
freqrel <- table(bl_total$`Household net financial wealth`)/nrow(bl_total)
# Lunghezza del vettore frequenza
m <- length(freqrel)
# Creazione delle classi
classi <-c(40000,60000, 100000)
# Frequenze relative delle classi
freqClassi <- table(cut(bl_total$`Household net financial wealth`, breaks = classi, right = FALSE))/length(bl_total$`Household net financial wealth`)
# Frequenze cumulata
Fcum <- cumsum(freqClassi)
Fcum[3] <- 1

```



Si ottiene in questo modo il grafico della funzione di distribuzione empirica continua introducendo delle classi fittizie: c1=[0;40000], c2=[40000;60000], c3=[60000, 100000] e c4=[100000, 176000] per la variabile di ricchezza finanziara. 

```{r}
ascisse <-c(0,40000,60000, 100000)
ordinate <-c(0,  Fcum [1:3])
plot(ascisse , ordinate , type = "b",
axes = FALSE ,
main = "Funzione di distribuzione empirica continua ",
col =" red ",ylim=c(0 ,1) ,xlab="x",ylab="F(x)")
axis(1, ascisse )
axis(2, format (Fcum , digits = 2))
box()
```



## Servizi sanitari (variabile 1)

### Statistiche

Nell'esaminare la situazione abitativa è necessario prendere in considerazione le condizioni di vita, come il numero medio di vani a persona e la presenza di dotazioni di base.

In media, si è osservato che la percentuale di famiglie che non possiedono servizi sanitari primari a disposizione è circa 3,42. La maggior parte delle famiglie, invece, ha accesso a un ai servizi sanitari primari. La mediana è di 0,6%, per cui la metà degli stati ha in percentuale 0,6% di famiglie senza servizi igienici e l'altra metà ha un numero in percentuale superiore. Si approfondisce quali sono gli stati. Il risultato suggerisce una distribuzione leggermente asimmetrica.

```{r}
bl_total[which(bl_total$`Dwellings without basic facilities`>0.6),]%>%
  select(Stato)
```

La precentuale di 2,5% di famiglie senza sanitari è il numero riportato con maggiore frequenza tra gli stati. Rispetto ai quartili, il primo quartile (Q1) è di 0,15%, il secondo quartile (Q2, che coincide con la mediana) è di 0,6 % e il terzo quartile (Q3) è di 4.25 %. E' presente una chiara variazione significativa tra le abitazioni dei diversi stati. La varianza è di circa 42.96, suggerendo una notevole variabilità. La deviazione standard è di circa 6.55% esprimendo quanto i dati si discostino in media dalla media. 
La simmetria è positiva, con un valore di circa 0.78, per cui la distribuzione tende ad essere leggermente spostata verso destra, indicando una maggiore concentrazione di stati con un numero inferiore di  famiglie con bagni rispetto a stati con famiglie con un numero superiore. La curtosi, con un valore di circa 15.00, indica una distribuzione con code pesanti. Ciò suggerisce che potrebbero essere presenti stati con un numero di percentuali estremamente alto o basso che contribuiscono a una maggiore curtosi.


```{r}

statistiche<-function(x){
  media=mean(x)
  mediana=median(x)
  moda=moda(x)
  quant=quantile(x, probs = c(0.25,0.50,0.75))
  varianza=var(x)
  dev_stan=sd(x)
  simmet=simmetria(x)
  curt=curtosi(x)
  stat=data.frame(Statistiche=c('Media', 'Mediana', 'Moda', 'Q1','Q2', 'Q3', 'Varianza', 'Deviazione standard', 'Simmetria', 'Curtosi'), 
                  Valori=c(media,mediana,moda,quant,varianza,dev_stan,simmet,curt))
  stat
}
statistiche(bl_total$`Dwellings without basic facilities`)

```

### Istogramma

L'istogramma è una rappresentazoine grafica per la visualizzazione della variabile numerica. Dal grafico non c'è evidenza di bimodalità ma forte presenza di asimmetria positiva. In particolar modo la maggior parte delle osservazioni si concentrano tra 0 e 0.6, come evidenziato dalla mediana. 

```{r, warning=FALSE }
ggplot(data = bl_total, mapping = aes(x=`Dwellings without basic facilities`,..density..)) + geom_histogram()

```

### Boxplot

Il boxplot è composto da una scatola che si estende da un quartile all'altro, cioè dal primo quartile (Q1) al terzo quartile (Q3). La lunghezza della scatola rappresenta l'intervallo interquartile (IQR) e indica dove si concentra la maggior parte dei dati. All'interno della scatola c'è una linea che rappresenta la mediana dei dati, che è il valore centrale nella distribuzione. I baffi si estendono dalla scatola verso l'alto e verso il basso. Possono rappresentare la dispersione dei dati e indicare quanto lontano si estendono i dati al di fuori dell'intervallo interquartile. I punti che cadono al di fuori dei baffi sono spesso considerati valori anomali o estremi. Questi punti rappresentano dati che si discostano significativamente dalla maggior parte delle osservazioni.

La mediana è posizionata molto in basso rispetto osservazioni. Data la lunghezza della scatola è evidente che vi è concentrazione dei dati a sinistra della mediana e dispersione sul lato sinistro. Vista la lunghezza del baffo si percepisce asimmetria positiva. In particolare, sono stati individuati circa tre valori anomali, rappresentati dagli stati di Lettonia e Russia, con una frequenza approssimativa intorno al 13-14%. Inoltre, il Sudafrica si distingue con una percentuale massima, pari al 37% di popolazione che non dispone di servizi igienici adeguati. Si parla di valori anomali rispetto alla popolazione di riferimento ma conoscendo il background degli stati le percentuali non sono al di fuori della norma. In genere, i valori anomali potrebbero essere riconosciuti nei casi in cui si aggregano individui o entità pressocchè simili. 

```{r}
ggplot(bl_total, aes(x = `Dwellings without basic facilities`)) +
geom_boxplot() +
coord_flip()+ theme_1
# 
# bl_total[which(bl_total$`Dwellings without basic facilities`>10),]%>%select(Stato, `Dwellings without basic facilities`)
```


## Spese per la casa (variabile 2)

### Statistiche

La spesa abitativa riveste un ruolo centrale nel bilancio familiare e rappresenta la principale voce di spesa per molti individui e famiglie se si prendono in considerazione affitto, gas, elettricità, acqua, mobilio e riparazioni. In media, le famiglie degli stati spendono circa il 20% del reddito disponibile lordo corretto per il mantenimento delle loro case. L'incidenza della spesa abitativa sul bilancio familiare varia da oltre il 26% nella Nuova zelanda a meno del 15% in Corea. La mediana è di 21,00%, suggerisce una distribuzione relativamente bilanciata. La moda è anch'essa di 21,00%. Rispetto ai quartili, il primo quartile (Q1) è di 20,00%, il secondo quartile (Q2, che coincide con la mediana) è di 21,00% e il terzo quartile (Q3) è di 23,00 %. Questi valori quartili indicano che la maggior parte delle famiglie ha spese contenute, mentre alcune famiglie spendono di più (Q3) o di meno (Q1).
In media le spese si discostano di 2,41% dalla media. La simmetria è positiva, con un valore di 0,33 con distribuzione leggermente spostata verso destra. La curtosi è negativa, con un valore di  -0,52. Questo indica una distribuzione leggermente appiattita rispetto a una distribuzione normale, suggerendo che ci siano meno valori estremi o "code" rispetto a una distribuzione più appuntita.

```{r}

statistiche<-function(x){
  media=mean(x)
  mediana=median(x)
  moda=moda(x)
  quant=quantile(x, probs = c(0.25,0.50,0.75))
  varianza=var(x)
  dev_stan=sd(x)
  simmet=simmetria(x)
  curt=curtosi(x)
  stat=data.frame(Statistiche=c('Media', 'Mediana', 'Moda', 'Q1','Q2', 'Q3', 'Varianza', 'Deviazione standard', 'Simmetria', 'Curtosi'), 
                  Valori=c(media,mediana,moda,quant,varianza,dev_stan,simmet,curt))
  stat
}
statistiche(bl_total$`Housing expenditure`)

# bl_total[which.max(bl_total$`Housing expenditure`), ]%>%select(Stato, `Housing expenditure`)
# bl_total[which.min(bl_total$`Housing expenditure`), ]%>%select(Stato, `Housing expenditure`)
```
### Density

Il grafico di densità è un tipo di grafico che  permette di visualizzare la forma della distribuzione di una variabile continua. Questa visualizzazione è particolarmente utile per comprendere la concentrazione e la variabilità dei dati e per individuare eventuali modalità o tendenze all'interno della distribuzione. Nel grafico di densità, sull'asse delle ordinate è rappresentata la densità di probabilità, che rappresenta la probabilità di trovare un'osservazione in una determinata posizione lungo l'asse delle ascisse. Più la curva è alta in un punto, maggiore è la probabilità che le osservazioni cadano in quella posizione.
La distribuzione mostra una curva un pò più appiattita di una normale, il risultato è dovuta a punto con massa di probabilità che potrebbero far pensare a una bimodalità, in tal caso sarebbe meglio utilizzare l'indice della moda come riferimento. L'asimmetria è positiva, anche se in presenza di più punti di maggiore densità non ha senso parlare di asimmetria. 

```{r}
ggplot(data = bl_total, mapping = aes(`Housing expenditure`)) +
geom_density(fill = "white", col = "black")+theme_1

```
 
### Normal qqplot

 Un QQ-plot rappresenta una comparazione tra i quantili di due distribuzioni: la distribuzione dei dati osservati e una distribuzione teorica di riferimento (in questo caso la distribuzione normale). L'asse orizzontale rappresenta i quantili teorici della normale. L'asse verticale rappresenta i quantili osservati delle spese per la casa rispetto alla normale. I punti sul grafico rappresentano le coppie di quantili. Ogni punto corrisponde a un valore nei dati osservati (asse y) e al suo corrispondente quantile teorico (asse x) secondo la normale.
I dati osservati non seguono esattamente la distribuzione della normale infatti pochi punti si allineano sulla retta di riferimento evidenziando discrepanze dalla distribuzione. Poichè, molte osservazioni si trovano al di sotto della retta per cui le code dei dati osservati sono più leggere rispetto alla distribuzione di riferimento.

```{r}

qqnorm(bl_total$`Housing expenditure`, pch = 1, frame = FALSE)
qqline(bl_total$`Housing expenditure`, col = "darkgreen", lwd = 2)
```


## Camere per persona (variabile 3)

Per misurare la condizione di sovraffollamento si divide il numero di locali presenti nell'abitazione per il numero di persone che vi abitano. Un alloggio sovraffollato, infatti, può avere un'incidenza negativa sulla salute fisica e mentale, sui rapporti con gli altri e sullo sviluppo dei bambini. Il sovraffollamento, inoltre, comporta spesso servizi carenti in materia di fornitura idrica e fognature.

### Statistiche

 Nell'area dell'OCSE (degli stati considerati), le abitazioni in media contengono 1,7 vani a persona. Per quanto riguarda le dotazioni di base, il 97% delle abitazioni nei Paesi dispone di un accesso privato ai servizi igienici interni con scarico. La mediana, invece,  è  circa 1,75. Il risultato permette di comprendere che la metà degli stati ha un numero di camere per persona superiore a questo valore e l'altra metà ha un numero inferiore. Il valore più frequentemente presente è 1,9.  
Il primo quartile (Q1) è 1,2 camere, il secondo quartile (Q2, che è anche la mediana) è 1,75 camere e il terzo quartile (Q3) è 1,9 camere per persona. La varianza è di circa 0,22, il che indica che i dati sono relativamente vicini alla media. La deviazione standard è 0,47 indicando che la dispersione dei dati è moderata. Il valore della simmetria  è -0,57 esprimendo una leggera tendenza verso la sinistra nella distribuzione, cioè alcuni stati potrebbero avere un numero inferiore di camere rispetto alla media. La curtosi misura quanto le code della distribuzione differiscono da una distribuzione normale. Il valore di -1,00 indica che la distribuzione ha code meno pesanti di una distribuzione normale.


```{r}

statistiche(bl_total$`Rooms per person`)

```


### Istogramma

Il valore delle camere per persona viene racchiuso nel range [0.7; 2.5]. Come già evidenziato dalla moda la maggior frequenze delle osservazioni si presenta nel valore di 1.9,  questo si riflette nel grafico con presena di barra più alta. Non c'è evidenza di bimodalità ma presenza di leggera asimmetria negativa. 

```{r, warning=FALSE}

ggplot(data = bl_total, mapping = aes(`Rooms per person`)) +
geom_bar(fill = "white", col = "black")+theme_1

```


### Boxplot

Il boxplot evidenza l'asimmetria negativa nei dati. Non sono presenti valori anomali. 

```{r}
ggplot(bl_total, aes(x = `Rooms per person`)) +
geom_boxplot() +
coord_flip()+ theme_1

```




## Tasso di occupazione (variabile 4)

### Statistiche

All'interno dell'area dell'OCSE, circa il 67% della popolazione in età lavorativa, compresa tra 15 e 64 anni, ha un lavoro retribuito. I livelli occupazionali più elevati si registrano in Islanda (86%), Svizzera (80%) e  Svezia (78%); mentre i più bassi si registrano in Sudafrica (43%),Turchia (51%), Grecia (52%). La mediana è del 69%: la metà degli stati ha un tasso di occupazione inferiore al 69% e l'altra metà ha un tasso superiore. Inoltre, il tasso di occupazione di molte aree  è concentrato intorno al 72,5%. Osservando i quartili, si nota che il primo quartile (Q1) è del 65%, il secondo quartile (Q2, equivalente alla mediana) è del 69%, e il terzo quartile (Q3) è del 73,75%.   La dispersione intorno alla media è circa 8,21%. 
La simmetria, con un valore vicino a zero (0,086), suggerisce che la distribuzione dei tassi di occupazione è approssimativamente simmetrica, senza una forte tendenza verso destra o sinistra. La curtosi, con un valore positivo di 1,02, indica una distribuzione con code leggermente più pesanti rispetto a una distribuzione normale. 

```{r}

statistiche(bl_total$`Employment rate`)

#bl_total[which.max(bl_total$`Employment rate`),]%>%select(Stato, `Employment rate`)
# bl_total%>%
#   arrange(`Employment rate` )%>%
#   select(Stato, `Employment rate`)
```


### Stripchart 

Nel grafico a stripchart, i punti dati vengono disposti lungo un'unica linea orizzontale o verticale, in modo che ciascun punto rappresenti un'osservazione o un valore specifico. I punti possono sovrapporsi se ci sono molte osservazioni con lo stesso valore. Questo tipo di grafico è spesso utilizzato per evidenziare la distribuzione dei dati, la concentrazione dei punti in determinate regioni e possibili outliers o valori anomali. 

Per la variabile del tasso di occupazione i dati si concentrano per lo più tra 60 e 77 con 2 valori che cadono fuori l'intervallo dell'80% e 3 valori sotto il 50% (già analizzati precedentemente). In condizioni di osservazioni normali si potrebbe pensare a valori anomali ma in questo caso i valori giustificano l appartenenza dello stato.

```{r}
stripchart(bl_total$`Employment rate`,
main="Percentuale dei tassi di occupazione nei diversi stati",
xlab="Tasso di occupazione",
ylab="Per stato",
method="jitter",
col="darkgreen",
pch=1
)

```



### Normal Qq plot

Per la variabile relativa al tasso di occupazione la similarità della distribuzione con quella della variabile casuale normale è più evidente rispetto alla variabile analizzata precedente. I dati osservati seguono esattamente la distribuzione teorica della normale, i punti ,infatti, si allineano quasi perfettamente alla retta di 45 gradi tranne per i valori che sono stati già ritenuti "outliers" per la distribuzione ma non anomali per gli stati. 

```{r}

qqnorm(bl_total$`Employment rate`, pch = 1, frame = FALSE)
qqline(bl_total$`Employment rate`, col = "lightgreen", lwd = 2)

```


## Reddito personale (Variabile 5)

### Statistiche


Nei Paesi dell'OCSE le persone guadagnano in media 37.436 USD all'anno, ma il reddito medio varia in maniera significativa da un Paese all'altro. Negli Stati Uniti, nel Lussemburgo e in Svizzera il reddito da lavoro medio è più del doppio di quello registrato in Europa orientale, Cile, Grecia, Ungheria, Messico e Portogallo. Tuttavia, è fondamentale notare che la mediana, che è di 38.223, è leggermente superiore alla media. Questo suggerisce che la distribuzione del reddito ha una leggera tendenza verso il lato superiore, con la maggior parte delle persone che guadagnano vicino o sopra la mediana. La moda, che è di 25.000,  indica che ci sono molte persone con un reddito vicino a questa cifra. È interessante notare che la moda è significativamente inferiore alla media, suggerendo la presenza di un gruppo significativo di stati con redditi più bassi. Esaminando i quartili, si può vedere che il primo quartile è di 23.923, il secondo quartile, che coincide con la mediana, è di 38.223, e il terzo quartile è di 49.291. La varianza, che è di 203.261.600.000, suggerisce una notevole variabilità nei redditi, mentre la deviazione standard, di circa 14.256, indica quanto i redditi si discostino dalla media. La simmetria, con un valore leggermente negativo di -0,127, suggerisce una leggera asimmetria verso sinistra nella distribuzione del reddito, cioè alcuni stati potrebbero avere una proporzione di persone con redditi inferiori alla media più elevata. Infine, la curtosi, con un valore di -1,239, indica che la distribuzione ha code leggermente più pesanti rispetto a una distribuzione normale.

```{r}
statistiche(bl_total$`Personal earnings`)
```


### Boxplot

Il boxplot evidenza una leggera asimmetria negativa data la grandezza della scatola. Non sono presenti valori anomali rispetto alla distribuzione. Lo stato il cui reddito medio percepito è più alto è lo stato del lussemburgo, mentre il più basso è il South Africa. 

```{r}
ggplot(bl_total, aes(x = `Personal earnings`)) +
geom_boxplot() +
coord_flip()+ theme_1

```


## Student Skill (Variabile 6)

### Statistiche

La media delle abilità degli studenti negli stati è di circa 486,76. Tuttavia la mediana, che è di 496, è superiore alla media. Ciò suggerisce che la maggior parte degli studenti si colloca al di sopra del valore medio, con alcune prestazioni eccezionali che spingono la mediana verso l'alto. La moda, che è di 490, indica che ci sono molti studenti con abilità vicine a questo valore. La moda è leggermente inferiore alla media ma comunque piuttosto vicina.
Esaminando i quartili, si vede che il primo quartile (Q1) è di 481,5, il secondo quartile (Q2), che coincide con la mediana, è di 496, e il terzo quartile (Q3) è di 506. La varianza è  1122,94 e la deviazione standard è di 33,51.  La simmetria, con un valore leggermente negativo di -0,18, suggerisce una leggera asimmetria verso sinistra nella distribuzione delle abilità. Infine, la curtosi, con un valore di 1,40, indica che la distribuzione ha code più pesanti rispetto a una distribuzione normale. Il giappone è in testa alla classifica, con un punteggio medio PISA di 529 punti. Seguono l'Estonia e la Finlanida con 524 e 523 punti. Il Paese con i risultati più bassi è il South Africa, con un punteggio medio di 391 punti. Ciò significa che il divario tra i Paesi con il più alto e il più basso rendimento è di 138 punti.


```{r}
statistiche(bl_total$`Student skills`)
# 
# bl_total%>%
#   select(Stato,`Student skills` )%>%
#   arrange(`Student skills`)
```


### Box a Intaglio

Si possono utilizzare anche i boxplot ad intaglio i quali sono una rappresentazione grafica dei boxplot ma con l’aggiunta dell’intervallo di confidenza. Con un grado di fiducia del 95%, l’intervallo di confidenza approssimato per la mediana delle skills degli studenti è (489.76; 502.23). Dal grafico vengono evidenziati possibili valori anomali, per il South Africa e il Brasile il punteggio medio è molto al di sotto della mediana, addirittura al di sotto del 400. 

```{r, warning=FALSE}
 ggplot(bl_total, aes(x = `Student skills`)) +
geom_boxplot(notch = TRUE) +
coord_flip()+theme_1

IQR <- quantile(bl_total$`Student skills`,0.75) - quantile(bl_total$`Student skills`, 0.25)
M1 <- quantile(bl_total$`Student skills`,0.5) - 1.57 *IQR/sqrt(length(bl_total$`Student skills`))
M2 <- quantile(bl_total$`Student skills`,0.5) + 1.57 *IQR/sqrt(length(bl_total$`Student skills`))
c(M1 ,M2)
# 
# bl_total%>%
#   filter(`Student skills`<400)
```

### Density 

Dalla visualizzazione della distribuzione è chiaramente possibile assimilare l'asimmetria negativa della distribuzione con code più lunghe a destra che a sinistra. Le code più pesanti fanno si che la distribuzione si mostri leptocurtica, per cui più appuntita di una normale. 
```{r}
ggplot(data = bl_total, mapping = aes(`Student skills`)) +
geom_density(fill = "white", col = "black")+theme_1

```


## Aspettativa di vita (Variabile 7)

### Statistiche

In media, la speranza di vita alla nascita raggiunge 79,54 anni, rappresentando una stima del periodo di vita medio nei paesi. Tuttavia la mediana è di  81,15 anni, supera la media. In molte nazioni  l'aspettativa di vita si avvicina a 82,5.  Esaminando i quartili, si vede che il primo quartile (Q1) è di 78,18 anni, il secondo quartile (Q2), coincidente con la mediana, è di 81,15 anni, e il terzo quartile (Q3) è di 82,25 anni. La deviazione standard, di circa 4,69, misura quanto le aspettative di vita si discostino dalla media, molto poco considerando la differenza interquartile.
La simmetria, con un valore negativo di -0,46, è espressione di  leggera asimmetria verso sinistra nella distribuzione delle aspettative di vita. Infine, la curtosi, con un valore notevolmente alto di 10,49, indica che la distribuzione ha code estremamente pesanti, il che suggerisce la presenza di alcuni paesi con aspettative di vita molto al di fuori della norma. Il Paese in cui la speranza di vita è più elevata è il Giappone, dove la media è di 84 anni; all’altra estremità della scala, la speranza di vita più bassa tra i Paesi si registra in Brasile a 74 anni, a 71 anni nella Federazione Russa e a 57 anni in Sudafrica.

```{r}
statistiche(bl_total$`Life expectancy`)
# bl_total%>%
#   arrange(`Life expectancy`)%>%
#   select(Stato, `Life expectancy`)
```

### Istogramma e Kernel Density 


L'asimmetria negativa e lo spostamento dell'andamento della curva è pressocchè dovuta alla presenza di valori anomali per la distribuzione (faccio riferimento all'Africa che si attesta valore medio di aspettativa per gli abitanti relativamente bassa, oltre che la Russia). Nonostante non sia presente bimodalità, la distribuzione è notevolmente più appuntita di una normale giustificando il risultato della statistica calcolata. 

```{r}
ggplot(data = bl_total, mapping = aes(`Life expectancy`,..density..)) +
geom_histogram(bins = 30, fill = "white", col = "black")+
geom_density()+theme_1
```


## Stato di salute (Variabile 8)

### Statistiche

In tutta l’area ricoperta dallo studio, circa il 68% della popolazione adulta dichiara di essere in "buona" o "ottima” salute. In Canada, Nuova Zelanda e negli Stati Uniti, l'88% degli adulti dichiara di essere in buona salute, mentre in Giappone e Corea, nonostante le aspettative di vita molto alte, meno del 40% delle persone dichiara di essere in "buona" o "ottima" salute.  La mediana, che si colloca a 70, suggerisce che la stragrande maggioranza delle regioni si trova al di sopra della media in termini di benessere salutare. La modalità, ossia il valore più frequente, è 65. Guardando i quartili, si nota che il primo quartile (Q1) è di 62, il secondo quartile (Q2) è di 70, e il terzo quartile (Q3) è di 76. Non intercorrono differenze abissali nella massa di distribuzione. Le valutazioni discostano dalla media di circa 13,98, in termini percentuali. Il valore di simmetria è leggermente negativo ,-0.14, suggerendo che la distribuzione delle valutazioni è leggermente inclinata verso sinistra. Infine, la curtosi ha valore pressocchè nullo. 


```{r}
statistiche(bl_total$`Self-reported health`)
# bl_total%>%
#   arrange(`Self-reported health`)%>%
#   select(Stato,`Self-reported health`)
```

### Boxplot

Il boxplot relativo alla percezione dello stato di salute dei cittadini dei diversi stati rende visibile una leggera asimmetria calcolata dall'indice precedente e una pressocchè nulla curtosi. Vengono individuati due valori anomali al di sotto del valore 40 imputabili a Giappone e Korea. Il 35% dei giapponesi e il 33% dei coreani ha una percezione positiva del proprio stato di salute. 

```{r}
ggplot(bl_total, aes(x = `Self-reported health`)) +
geom_boxplot() +
coord_flip()+ theme_1


#bl_total[which(bl_total$`Self-reported health`<40), ]%>%
# select(`Self-reported health`, Stato)
```



## Tasso di Omicidi (Variabile 9)

### Statistiche

Il tasso di omicidi (numero di omicidi ogni 100 000 abitanti) si riferisce solo alla forma più estrema di violenza sulla persona e, di conseguenza, non fornisce informazioni sulle condizioni di sicurezza più rappresentative. Secondo i dati, il tasso medio di omicidi nell’area OCSE è pari a 2.93 omicidi ogni 100 000 abitanti. Il maggior tasso di omicidi è registrato in Brazile, mentre il tasso minore di omicidi in Gran Bretagna. La moda, ovvero il valore che compare più frequentemente, è 2.5. Il primo quartile (Q1) è 0.6, il secondo quartile (Q2) è 1, e il terzo quartile (Q3) è 1.625. Questi quartili indicano che la maggior parte dei paesi ha un tasso di omicidi relativamente basso, ma ci sono alcune eccezioni con tassi più elevati. La varianza è abbastanza alta, pari a circa 29.9, il che suggerisce una notevole variabilità nei tassi di omicidi tra i paesi. La deviazione standard implica che il valore intorno alla media si discosta in media di 5.47. La simmetria è positiva, con un valore di 0.22, suggerendo che la distribuzione è leggermente spostata verso destra, ma in generale, è approssimativamente simmetrica. La curtosi è piuttosto alta, a 9.62, il che suggerisce che la distribuzione ha code pesanti, cioè ci possono essere paesi con tassi di omicidi molto elevati rispetto alla media.

```{r}
statistiche(bl_total$`Homicide rate`)
#bl_total[which.max(bl_total$`Homicide rate`), ]
#bl_total[which.min(bl_total$`Homicide rate`), ]

```


### Istogramma 

I valori cacolati dalle statistiche per descriverne la distribuzione non hanno effettivamente senso per questa variabile. Il valore del terzo quartile fissato a 1.62, indica che circa il 75% delle osservazioni rientrano prima della soglia fissata mentre il restante 25% è compreso tra la soglia e il valore massimo osservato per il Brasile pari al 27%. Per cui, parlare di curtosi e asimmetria non risulta essere del tutto corretto. In casi generici, si potrebbe pensare che i valori potrebbero essere anomali, ma siccome si sta facendo aggregazione su gruppi di stati che potrebbero avere indici differenti, si comprende la non anomalia dei rispettivi dati.  

```{r}
ggplot(data = bl_total, mapping = aes(`Homicide rate`,..density..)) +
geom_histogram(bins = 30, fill = "white", col = "black")+theme_1
```

## Attenzione sull'italia: 


L'Italia ottiene risultati positivi in diverse dimensioni del benessere rispetto ad altri paesi nel Better Life Index. L'Italia supera la media equilibrio tra lavoro e vita privata e coinvolgimento civico, qualità ambientale e aspettativa di vita. Tuttavia, si colloca al di sotto della media in termini di salute, reddito, occupazione, istruzione, relazioni sociali e soddisfazione nella vita.

```{r}
# mean_benessere<-mean(bl_total$`Self-reported health`)
# mean_vitalavoro<-mean(bl_total$`Time devoted to leisure and personal care`)
# mean_civica<-mean(bl_total$`Voter turnout`)
# mean_reddito<-mean(bl_total$`Personal earnings`)
# mean_occupazione<-mean(bl_total$`Employment rate`)
# mean_istruzione<-mean (bl_total$`Years in education`)
# mean_aria<-mean(bl_total$`Air pollution`)
# mean_soddisfazione<- mean( bl_total$`Life satisfaction`)
# mean_vita<-mean(bl_total$`Life expectancy`)
# mean_retribuito<-mean(bl_total$`Employees working very long hours`)
# mean_ed<-mean(bl_total$`Educational attainment`)
# mean_punteggio<-mean(bl_total$`Student skills`)
# mean_water<-mean(bl_total$`Water quality`)
# italy<-bl_total%>%
#   filter( Stato=='Italy')
# 
# italy$`Self-reported health`>mean_benessere
# italy$`Time devoted to leisure and personal care`>mean_vitalavoro
# italy$`Voter turnout`>mean_civica
# italy$`Personal earnings`>mean_reddito
# italy$`Employment rate`>mean_occupazione
# italy$`Years in education`>mean_istruzione
# italy$`Air pollution`>mean_aria
# italy$`Life satisfaction`>mean_soddisfazione
# italy$`Life expectancy`>mean_vita
# italy$`Educational attainment`
# italy$`Student skills`
# italy$`Water quality`


# italy$`Personal earnings`
# mean_reddito
# bl_men%>%filter(Stato=='Italy')%>%select( `Employment rate`)
# bl_women%>%filter(Stato=='Italy')%>%select( `Employment rate`)
# italy$`Employees working very long hours`
# bl_men%>%filter(Stato=='Italy')%>%select( `Employees working very long hours`)
# bl_women%>%filter(Stato=='Italy')%>%select( `Employees working very long hours`)
# bl_men%>%filter(Stato=='Italy')%>%select( `Educational attainment`)
# bl_women%>%filter(Stato=='Italy')%>%select( `Educational attainment`)
# italy$`Student skills`
# bl_men%>%filter(Stato=='Italy')%>%select( `Student skills`)
# bl_women%>%filter(Stato=='Italy')%>%select( `Student skills`)
# italy$`Life expectancy`
# bl_men%>%filter(Stato=='Italy')%>%select( `Life expectancy`)
# bl_women%>%filter(Stato=='Italy')%>%select( `Life expectancy`)
# italy$`Air pollution`
# italy$`Quality of support network`
# mean(bl_total$`Quality of support network`)
# italy$`Voter turnout`
# mean(bl_total$`Voter turnout`)
```

In Italia, il reddito disponibile netto medio per persona è di 35.397 dollari all'anno, leggermente inferiore alla media dei paesi di 37435 dollari all'anno.

Per quanto riguarda l'occupazione, circa il 57% delle persone tra i 15 e i 64 anni in Italia ha un lavoro retribuito, al di sotto della media totale del 67%. Il 66% degli uomini lavora, rispetto al 48% delle donne. In Italia, il 4% dei dipendenti lavora molte ore in modo retribuito, al di sotto della media totale del 8.72%, con il 5% degli uomini che lavorano molte ore in modo retribuito rispetto al 2% delle donne.

Nell'ambito educativo, il 60% degli adulti tra i 25 e i 64 anni ha completato l'istruzione secondaria superiore, inferiore alla media totale degli stati del 77%. Tuttavia, il completamento varia tra uomini e donne, con il 58% degli uomini che hanno completato con successo il liceo rispetto al 62% delle donne. Per quanto riguarda la qualità del sistema educativo, il punteggio medio degli studenti è di 485 in lettura, matematica e scienze nel Programma per la Valutazione Internazionale degli Studenti (PISA) dell'OCSE. Questo punteggio è leggermente inferiore alla media complessiva di 486. Le ragazze ottengono risultati migliori dei ragazzi di 4 punti, per cui 3 punti al di sopra della media, molto al di sotto del divario medio di 2 punti.

Per quanto riguarda la salute, l'aspettativa di vita alla nascita in Italia è di circa 82 anni, tre anni in più rispetto alla media totale di 79 anni. L'aspettativa di vita per le donne è di 85 anni, rispetto a 80 anni per gli uomini. Il livello di PM2,5 atmosferico, piccole particelle inquinanti dell'aria abbastanza piccole da penetrare e danneggiare i polmoni, è di 18 microgrammi per metro cubo, superiore alla media di 13 microgrammi per metro cubo. In Italia, il 71% delle persone dichiara di essere soddisfatto della qualità dell'acqua, inferiore alla media dell'82%.

Per quanto riguarda la sfera pubblica, in Italia c'è un senso moderato di comunità e un alto livello di partecipazione civica, dove il 90% delle persone crede di poter contare su qualcuno in caso di necessità, inferiore alla media pari a  91%. Il tasso di affluenza alle urne, una misura della partecipazione dei cittadini al processo politico, è stato del 75% nelle elezioni del 2017, superiore alla media registrata come 70%. Lo status sociale ed economico può influenzare i tassi di voto. 

Quando si chiede loro di valutare la loro soddisfazione generale nella vita su una scala da 0 a 10, gli italiani le danno una media di 5.9, inferiore alla media totale di 6.53.


# ANALISI BIVARIATA

L'analisi bivariata permette di lavorare su ogni unità statistica e rilevare *congiuntamente* i due caratteri statistici $X e Y$, generando la rilevazione doppia $(X,Y)$. Si può trattare di due caratteri qualitativi, due caratteri quantitativi o un carattere qualitativo e uno quantitativo.

Prima di analizzare le relazioni fra variabili si rende necessaria
un'analisi preliminare degli indici e misure che caratterizzano tali
rapporti.

## 1) DUE VARIABILI QUANTITATIVE

## COVARIANZA

Si è resa necessaria un'analisi preliminare delle variabili numeriche per comprendere quali fra queste hanno un legame di associazione elevato tale da poter essere considerato *statisticamente significativo*. E' possibile analizzare la matrice di varianza e covarianza per studiarne l'associazione. La **covarianza** permette di misurare la presenza di legame lineare tra due variabili numeriche ma non la forza di tale legame.

```{r}
data_new<-bl_total%>%
  select(where(is.numeric))
abbreviated_variable_names <- c(
  "Dwelling",
  "Housing Exp.", 
   "Rooms per Person",
  "Household  Income",
  "Household  Wealth",
   " Job Security",
   "Empl. Rate",
   "Long-term Un.",
 "Earnings",
  "Support Net.",
  "Education Att.",
 "Student Skills",
  "Years in Education",
  "Air Pollution",
 "Water Quality",
  "Stakeholder Engagement",
  "Voter Turnout",
  "Life Expectancy",
  "Self-Reported Health",
  "Life Satisfaction",
 "Safety at Night",
  "Homicide Rate",
  "Long Working Hours",
 "Leisure Time") 


# Rinomina le colonne con le abbreviazioni
colnames(data_new) <- abbreviated_variable_names
```

Il coefficiente è il seguente:

$$cov(X,Y)= \frac{1}{n} \sum^n_{i=1}((x_i-\overline x)(y_i-\overline y))$$

-   se $cov=0$, $X e Y$ sono incorrelate, non esiste alcun legame
    lineare fra di loro;
-   se $cov>0$, $X e Y$ sono correlate positivamente; a variazioni
    positive (negative) di una variabile corrispondono variazioni
    positive(negative) dell'altra variabile;
-   se $cov<0$, $X e Y$ sono correlate negativamente; a variazioni
    positive di una variabile, corrispondono in media, variazioni
    negative dell'altra variabile e viceversa;

Nonostante la grandezza del dataset, si è cercato di cogliere i tratti essenziali dalla matrice di covarianza:

  1. La variabile "Dwelling" con "Housing Exp.", e "Rooms per Person" mostra coefficiente leggermente negativo o vicino a zero, indicando che non c'è una forte associazione tra queste variabili.
  2. Le variabili legate al reddito e alla ricchezza familiare ("Household Income" e "Household Wealth") hanno covarianze positive molto elevate con altre variabili finanziarie come "Earnings" e "Support Net.". 
  3. La variabile "Empl. Rate" è positivamente correlata con "Long-term Un." e "Homicide Rate", suggerendo che in alcune situazioni, un tasso di occupazione più basso potrebbe essere correlato a tassi più alti di disoccupazione a lungo termine e omicidi.
  4. Alcune variabili, come "Air Pollution" e "Water Quality," sono leggermente negative o vicine a zero con "Stakeholder Engagement" e "Voter Turnout", indicando che non c'è una forte associazione tra i fattori.
  5. Le variabili relative alla salute, come "Life Expectancy" e "Self-Reported Health" mostrano una correlazione positiva tra loro, suggerendo che paesi con un'aspettativa di vita più alta tendono ad avere una migliore autopercezione della salute.
  6. La variabile "Safety at Night" ha una covarianza positiva significativa con "Homicide Rate", indicando che paesi con un tasso di omicidi più elevato potrebbero percepire una minore sicurezza notturna.
  7. "Education Att." e "Student Skills" mostrano una forte correlazione positiva, il che suggerisce che i paesi con un maggior accesso all'istruzione tendono ad avere una migliore preparazione degli studenti.
  8. Le variabili "Long Working Hours" e "Leisure Time" hanno una covarianza negativa, suggerendo che paesi con lunghe ore di lavoro potrebbero avere meno tempo libero.
  
```{r}
cov(data_new)
```

## HEATMAP

L'evidenza dell'associazione fra variabili è possibile misurarla attraverso la **correlazione**. La correlazione è , appunto, una misura della relazione tra due variabili. Questa descrive come le variazioni di una variabile sono associate alle variazioni dell'altra variabile.

$$cor(X,Y)= \frac{S_XY}{S_X S_Y}$$

La correlazione può essere positiva, quando le variazioni delle due variabili vanno nella stessa direzione, o negativa, quando le variazioni delle due variabili vanno in direzioni opposte. L'espressione del coefficiente di correlazione avviene attraverso un valore, che varia da -1 a +1. Un coefficiente di correlazione di 0 indica l'assenza di correlazione, mentre un valore di +1 o -1 indica una correlazione perfetta tra le due variabili positivamente o negativamente. E' possibile quindi procedere alla visualizzazione del suddetto coefficiente attraverso un grafico pheatmap, utilizzato per creare mappe di calore, ovvero grafici in cui le celle di una tabella sono colorate in base al loro valore, al fine di evidenziare modelli o tendenze nei dati.

```{r}
C<- cor(data_new)
pheatmap::pheatmap(C)


```

Le righe e le colonne del grafico rappresentano le variabili numeriche, come prima descritte. La scala di valori rappresentata dalla legenda posizionata a destra è espressione del grado di correlazione fra variabili. Per cui, variabili che presentano un grado di associazione molto elevato , positivo, avranno in corrispondenza del match riga-colonna un colore tendente al rosso/arancione. Una casella colorata di giallo indica un'assenza di correlazione; una casella colorata celeste, tendente al blu scuro, indica una debole o forte associazione negativa. Risulta essenziale denotare che è una matrice simmetrica, la diagonale principale è colorata di rosso scuro poiché riflette un ovvia associazione pari a 1 della variabile con sé stessa, per cui tutto ciò che si ripete nella parte superiore della diagonale si ripete nella parte inferiore della diagonale.

Dalla lettura dell'heatmap della correlazione tra variabili, emergono diverse relazioni tra le variabili:

**Forte correlazione negativa tra **

  1. **Dwelling e Life Expectancy:**  paesi con condizioni abitative di bassa qualità (Dwelling) tendono a avere aspettative di vita più basse (Life Expectancy). Ciò potrebbe riflettere il fatto che le condizioni abitative influenzano la salute e il benessere della popolazione.
  2. **Insecurity e Employment Rate:** La correlazione negativa tra Insecurity e Employment Rate suggerisce che in paesi con alti livelli di insicurezza nel mondo del lavoro, potrebbe esserci una minore occupazione. L'insicurezza del mondo del lavoro potrebbe influire negativamente sull'occupazione e la stabilità economica.
  3.  **Air Pollution e Support Net:**  in aree con alti livelli di inquinamento dell'aria (Air Pollution), i sistemi di supporto sociale (Support Net) possono essere meno sviluppati. L'inquinamento dell'aria potrebbe avere un impatto negativo sulla qualità della vita e sul bisogno di reti di supporto.

**Forte correlazione positiva tra:**

  1.  **Insecurity e Long-term Unemployment:** paesi con alti livelli di insicurezza lavorativa potrebbero avere anche tassi di disoccupazione a lungo termine più elevati. 
  2.  **Household Income e Earnings:** I redditi familiari più elevati (Household Income) sono correlati positivamente ai guadagni (Earnings) a livello individuale. Questo suggerisce che in famiglie con redditi più alti, è probabile che ci siano anche guadagni individuali più alti.
  3.  **Household Wealth e Household Income:** Una correlazione positiva tra ricchezza familiare (Household Wealth) e reddito familiare (Household Income) suggerisce che famiglie più ricche tendono ad avere redditi più elevati.
  4.  **Employment Rate e Water Quality:** L'occupazione (Employment Rate) è correlata positivamente alla qualità dell'acqua (Water Quality), suggerendo che in paesi con alti tassi di occupazione, la qualità dell'acqua potrebbe essere migliore.
  5.  **Life Satisfaction e Earnings:** Una correlazione positiva tra la soddisfazione nella vita (Life Satisfaction) e i guadagni (Earnings) indica che in paesi con redditi più alti, le persone potrebbero essere generalmente più soddisfatte della propria vita.
  6.  **Safety at Night e Life Expectancy:** La sicurezza notturna (Safety at Night) è correlata positivamente all'aspettativa di vita (Life Expectancy), suggerendo che paesi in cui le persone si sentono più sicure durante la notte tendono ad avere aspettative di vita più lunghe.




Si procede all'analisi esplorativa bivariata tenendo conto delle informazioni precedenti. 

## Analisi Dwelling  e Life Expectancy

**Scatter plot**. L'applicativo plotly permette di rendere interattivo il grafico e ottenere informazioni su ciascuno stato (se letto dal file html). 

All'aumentare della qualità delle abitazioni, ci si aspetta che l'aspettativa di vita aumenti, e viceversa. Un miglioramento delle condizioni abitative, ad esempio attraverso una migliore  o istituzione di servizi sanitari, un accesso più agevole all'acqua potabile o un ambiente più sicuro, può influenzare positivamente la salute delle persone, aumentando la loro aspettativa di vita.


```{r}

p <- bl_total %>% 
  mutate(text=paste("Stato: ",bl_total$Stato, "\n Aspettativa di vita:",bl_total$`Life expectancy` )) %>%
  ggplot( aes(x=`Dwellings without basic facilities`, y=`Life expectancy`, text=text)) +
    geom_point(color="#69b3a2", alpha=0.8) +
    ggtitle("Condizioni abitative e aspettative di vita dei diversi stati") +
    theme(
      plot.title = element_text(size=12)
    ) +
    ylab('Aspettativa di vita (anni)') +
    xlab('Percentuale di popolazione con condizioni abitative non decenti')

ggplotly(p, tooltip="text")
```


## Analisi Job Security e Employment Rate

**2D Density plot**. I punti evidenziati con colori più chiari riflettono maggiore densità dei dati. Dalla relazione rafica è chiaro comprendere che è presente una relazione di correlazione negativa.  Una relazione di correlazione negativa tra il tasso di occupazione e la sicurezza lavorativa (misurata dalla percentuale di persone impiegate a tempo determinato per meno di 6 mesi) indica che quando il tasso di occupazione aumenta, la sicurezza lavorativa tende a diminuire, e viceversa. L'interpretazione della relazione potrebbe essere giustificata dal fatto che un aumento del tasso di occupazione potrebbe significare che più persone stanno ottenendo un impiego, ma se una percentuale significativa di queste persone è impiegata a tempo determinato per meno di 6 mesi, potrebbe indicare una mancanza di stabilità lavorativa. Questo può essere dovuto a un mercato del lavoro precario o all'uso diffuso di contratti temporanei.


```{r}
ggplot(bl_total, aes(y=`Employment rate`, x=`Labour market insecurity`) ) +
  stat_density_2d(aes(fill = ..density..), geom = "raster", contour = FALSE) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
      ggtitle("Tasso di occupazione e sicurezza lavorativa dei diversi stati") +
ylab('Tasso di occupazione') +
    xlab('Sicurezza lavorativa')+
  theme(
    legend.position='none'
  )
```


## Analisi Household Income e Household Wealth

**Retta di regressione**. Una relazione positiva tra "Household Income" (reddito familiare) e "Household Wealth" (patrimonio familiare) suggerisce che, in generale, famiglie con redditi più elevati tendono ad avere anche una maggiore ricchezza complessiva. In modo logico,le famiglie con redditi più elevati hanno una maggiore capacità di risparmiare. Possono mettere da parte una parte più consistente dei loro redditi, contribuendo così a incrementare il loro patrimonio, oltre che permettersi di investire in strumenti finanziari o proprietà che generano rendimenti, contribuendo così a far crescere il loro patrimonio. Dal grafico è evidente che le due variabile sono moderatamente legate linearmente, infatti lo scostamento delle osservazioni dalla retta di regressione lineare (retta interpolante ascendente) è discreto. 


```{r}
#cor(bl_total$`Household net adjusted disposable income`, bl_total$`Household net financial wealth`)
plot(bl_total$`Household net financial wealth` ,bl_total$`Household net adjusted disposable income` ,main =" Retta di regressione ", xlab="Income",ylab="Benessere finanziario")
abline (lm(bl_total$`Household net adjusted disposable income`~ bl_total$`Household net financial wealth`), col ="steelblue")
```


## Analisi Life Expectancy e Self-Reported Health


#### Scatter plot 

Tra le due variabili è presente una correlazione prossima allo 0.22. C' e' si un legame positivo ma non perfettamente lineare. In linea di massima, la relazione positiva suggerirebbe che le persone che valutano la propria salute come migliore tendono ad avere aspettative di vita più lunghe.



```{r}
#cor( bl_total$`Life expectancy`, bl_total$`Self-reported health`)
bl_total %>% 
  ggplot( aes(y=`Life expectancy`, x=`Self-reported health`)) +
    geom_point(color="#69b3a2", alpha=0.8) +
    ggtitle("Aspettativa di vita e proiezione salute dei diversi stati") +
    theme(
      plot.title = element_text(size=12)
    ) +
   xlab('Percezione della salute') +
    ylab('Aspettativa di vita ')
```



## Analisi Safety at night e Homicide Rate

#### Scatter plot

Una correlazione di -0.68 tra sicurezza durante la notte e tasso di omicidi indica una correlazione negativa moderatamente forte tra queste due variabili. Il valore negativo della correlazione suggerisce che quando il livello di sicurezza nel camminare di notte di soli aumenta (indicando una maggiore percezione di sicurezza durante la notte), il tasso di omicidi tende a diminuire. Viceversa, se la "Safety at night" diminuisce (indicando una minore percezione di sicurezza durante la notte), il tasso di omicidi tende a aumentare.Chiaramente, il risultato suggerisce che una maggiore sicurezza percepita durante la notte potrebbe essere associata a una minore incidenza di omicidi in una determinata area. E' tuttavia importante notare che "Safety at night" è una misurazione soggettiva basata sulla percezione delle persone riguardo alla propria sicurezza. Questa percezione può essere influenzata da vari fattori, tra cui la presenza di polizia, l'illuminazione pubblica, il livello di criminalità effettiva e l'educazione sulla sicurezza; si aggiunge che il valore presente all'interno del dataset è una media di tutte le osservazioni per ciascuno stato ma non sul singolo individuo. 
È importante tenere presente che la correlazione non implica causalità diretta. Altri fattori possono influenzare sia la percezione della sicurezza durante la notte che il tasso di omicidi. Ad esempio, un tasso di omicidi più elevato può influenzare negativamente la percezione della sicurezza, ma ci possono essere altri fattori, come la povertà, la disoccupazione e la demografia, che possono confondere la relazione.

```{r}
#cor(bl_total$`Feeling safe walking alone at night`, bl_total$`Homicide rate`)
bl_total %>% 
  ggplot( aes(y=`Feeling safe walking alone at night`, x=`Homicide rate`)) +
    geom_point(color="#69b3a2", alpha=0.8) +
    ggtitle("Sicurezza nel camminare di notte e tasso di omicidi dei diversi stati") +
    theme(
      plot.title = element_text(size=12)
    ) +
   xlab('Sicurezza nel camminare di notte') +
    ylab('Tasso di Omicidi')

```



## Analisi Education Att. e Student Skills


#### 2D Density plot
La correlazione tra livello di istruzione conseguito e abilità degli studenti è prossima al 0.73.  Il valore positivo della correlazione suggerisce che quando il livello di "Education Attainment" aumenta (cioè, quando le persone hanno completato livelli di istruzione più elevati), le "Student Skills" tendono ad aumentare. 
Questa correlazione indica che un maggiore livello di istruzione è generalmente associato a un miglioramento delle abilità degli studenti. L'istruzione formale può fornire alle persone le conoscenze e le competenze necessarie per avere successo in vari settori della vita, sia accademici che professionali. L'istruzione non riguarda solo l'acquisizione di conoscenze, ma anche lo sviluppo di abilità cognitive, analitiche e di problem-solving.

```{r}
#cor(bl_total$`Student skills`, bl_total$`Educational attainment`)
ggplot(bl_total, aes(y=`Educational attainment`, x=`Student skills`) ) +
  stat_density_2d(aes(fill = ..density..), geom = "raster", contour = FALSE) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
      ggtitle("Risultati medi degli studenti rispetto all'attainment educazionale dei diversi stati") +
ylab('Educational Attainment') +
    xlab('Student Skills')+
  theme(
    legend.position='none'
  )

```


## 2) DUE VARIABILI QUALITATIVE


## Analisi Air pollution e Life satisfaction

### Distribuzione di frequenza congiunta

Per sintetizzare i dati di una distribuzione doppia si può utilizzare
una tabella di contingenza in cui vengono riportate le **frequenze
congiunte** delle modalità di $X,Y$. 

In tal caso si sta confrontando la distribuzione congiunta di stati rispetto a soddisfazione della vita e induinamento dell'aria. In particolare: 9 osservazioni sono nel gruppo di unità con valore di inquinamento 1 e soddisfazione 1, 5 unità nel gruppo di soddisfazione 0 e inquinamento 0, 13 inquinamento 0 e soddisfazione 1, 11 inquinamento 1 e soddisfazione 0. 

```{r}
tab<-table(dat1$`Air pollution`, dat1$`Life satisfaction`)
tab
```
### Mosaic plot e grouped bar plot

 Il test V di Cramer permette di fornire informazioni circa il grado di associazione tra due variabili qualitative.  Tanto più il valore è prossimo a 1 , tanto più è presente dipendenza tra i caratteri. Il valore di Cramer's V intorno a 0.275 suggerisce un'associazione moderata tra le variabili. Per valutarne la significatività viene analizzato il mosaic plot e i relativi residui di pearson. 
La proporzione maggiore di osservazioni è visualizzata sulla base della grandezza dei rettangoli; in tal caso pollution 0 e soddisfazione 1 ha la priorità. Ci sono effettive differenze tra i livelli di inquinamento dell'aria. La soddisfazione è più alta in condizioni inquinamento dell'aria basso.

```{r, echo=FALSE, include=FALSE}
library(vcd)

```
Un p-value di 0.08 è al di sopra di molti livelli comuni di significatività ( 0.05). Per cui, un p-value superiore a 0.05 potrebbe suggerisce che non vi è evidenza sufficiente per respingere l'ipotesi nulla di assenza di associazione.

```{r}
tbl <- structable(`Air pollution`~`Life satisfaction`, data=dat1)
questionr::cramer.v(tbl)


mosaic(tbl,shade=TRUE, legend=TRUE)


```

### Gruped Bar plot


E' possibile trarre le stesse informazioni osservando anche questo grafico. 

```{r}
ggplot(dat1,aes(x=`Air pollution`,fill=`Life satisfaction`)) + geom_bar()

```



## 3) UNA VARIABILE QUALITATIVA E UNA QUANTITATIVA


Infine, è anche possibile rappresentare relazioni presenti tra una
variabile quantitativa e una qualitativa.

Si utilizza quindi le variabili che sono state costruite nell'analisi della variabile categoriale per svolgere osservazioni su gruppi differenti. 
Si ricorda che: 

  * Air pollution (factor) è stata creata classificando 1 i paesi la cui media di inquinamento dell'aria è maggiore della mediana totale 0 altrimenti; 
  * Life Satisfaction (factor)  è stata creata classificando con 1 i paesi la cui media della soddisfazione personale è maggiore della media totale 0 altrimenti; 


## Analisi Life Satisfaction e Personal Earnings

### Analisi numerica


```{r}
nuovo<-dat1%>%
select(`Life satisfaction`,`Personal earnings`)

summary(nuovo)
```
Svolgendo analisi sulle medie dei gruppi, tenendo conto che: 

- **Life Satisfaction 1**: è il gruppo che include tutti i paesi il cui valore di soddisfazione personale è superiore alla media.
- **Life Satisfaction 0**: è il gruppo che include tutti i paesi il cui valore di soddisfazione personale è al di sotto della media. 

 e la variabile "Media_guadagno" rappresenta il guadagno medio per ciascuno di questi due gruppi.
E' possibile distinguere la popolazione in : 

  1. **Life Satisfaction 1 (Soddisfatti)**:  gruppo con i paesi in cui le persone sono più soddisfatte della loro vita rispetto alla media globale. Il valore medio del guadagno in questi paesi è di 44,411.86 .

  2. **Life Satisfaction 0 (Insoddisfatti)**:  gruppo con i paesi in cui le persone sono meno soddisfatte della loro vita rispetto alla media globale. Il valore medio del guadagno in questi paesi è di 27,844.06.

La differenza tra i due gruppi è notevole. Nei paesi in cui le persone sono più soddisfatte della loro vita (Life Satisfaction 1), il guadagno medio è significativamente superiore rispetto ai paesi in cui le persone sono meno soddisfatte (Life Satisfaction 0). Il risultato è espressione di correlazione positiva tra la soddisfazione nella vita e il guadagno medio, indicando che nei paesi con livelli di soddisfazione personale più elevati, è più probabile che le persone abbiano guadagni medi più alti.

```{r}
m<-nuovo%>%
group_by(`Life satisfaction`)%>%
summarize(media_guadagno=mean(`Personal earnings`))
m
```


Confrontando i gruppi sulle mediana, in definitiva i paesi che si trovano nel sottoinsieme 1 per soddisfazione della vita guadagnano molto di più rispetto a quelli classificati come 0, ma al differenza in termini monetari è maggiore di circa 7000 unità. 


```{r}
m <-nuovo%>%
group_by(`Life satisfaction`)%>%
summarize(mediana_guadagno=median(`Personal earnings`))
m
```


### Boxplot paralleli

I boxplot paralleli, noti anche come boxplot a confronto, sono uno strumento grafico utile per visualizzare e confrontare la distribuzione di più gruppi o categorie in base a una variabile. Nel  caso specifico sono utili per confrontare i guadagni medi (Media_guadagno) in base ai due gruppi di soddisfazione nella vita (Life Satisfaction 0 e Life Satisfaction 1).
 L'asse delle ordinate rappresenta il valore della variabile del guadagno personale. L'asse delle ascisse rappresenta le categorie: Life Satisfaction 0 e Life Satisfaction 1
Per ciascun gruppo è stato costruito il boxplot. Sulla base della rappresentazione grafica, risulta chiaramente evidente la distinzione delle mediane dei due gruppi, più bassa per il gruppo di life satisfaction 0. La grandezza dei box è piuttosto simile, per cui in termini di variabilità si potrebbe aspettare gli stessi termini, tuttavia ciò che le differenza è una asimmetria positiva per il gruppo 0 e negativa per il gruppo 1. 
Sono presenti due valori anomali, per cui l'aspettativa di vita è al di sopra della mediana ma il salario personale è piuttosto basso: Brasile e Messico. 

```{r}

m <- ggplot(nuovo, aes(x=`Life satisfaction`, y = `Personal earnings`))
m + geom_boxplot()
```



### Densità Kernel

Dal plot della densità risulta essere più chiara la distribuzione. Sebbene le mediane dei gruppi sono differenti, entrambi le classi mostrano asimmetrie rispettivamente positiva per il gruppo 0 e negativa per il gruppo 1. 
```{r}
m <- ggplot(nuovo, aes(x=`Personal earnings`))
m + geom_density(aes(colour=`Life satisfaction`,fill=`Life satisfaction`),alpha=0.3)

```

## Analisi Air pollution e Support Network 

### Analisi numerica


```{r}
nuovo_1<-dat1%>%
select(`Air pollution`,`Quality of support network`)

```

Tenendo conto che la variabile pollution assume 1 per tutti gli stati il cui livello di inquinamento dell'aria è superiore alla media, 0 altrimenti, è possibile confrontare le medie dei due gruppi rispetto alla qualità della rete di supporto. E' evidente che il gruppo "Air pollution 0" ha una media della qualità dell'aria più elevata (92.38889) rispetto al gruppo "Air pollution 1" (87.90000).
La differenza nella media della qualità dell'aria tra i due gruppi suggerisce che gli stati con livelli inferiori di inquinamento dell'aria tendono a presentare una qualità dell'aria media più elevata rispetto agli stati con livelli superiori di inquinamento.

```{r}
m_2<-nuovo_1%>%
group_by(`Air pollution`)%>%
summarize(media_qualità_supporto=mean(`Quality of support network`))
m_2
```


### Densità Kernel
```{r}
ggplot(data=nuovo_1,mapping=aes(x= `Quality of support network`, y=`Air pollution`)) +
geom_density_ridges()
```







# ANALISI MULTIVARIATA

Si può infine, esplorare la relazione fra tre e più variabili.



```{r}
bl_men <- read_excel("C:/Users/carme/OneDrive/Desktop/UNIVERSITA 2/STATISTICA E ANALISI DEI DATI/Datasets/Better_life_2017_men.xlsx")
bl_women <- read_excel("C:/Users/carme/OneDrive/Desktop/UNIVERSITA 2/STATISTICA E ANALISI DEI DATI/Datasets/Better_life_2017_women.xlsx")
bl_women$Sex<-(rep('F'))
bl_men$Sex<-rep('M')
bl_merge<- rbind(bl_men, bl_women)
bl_merge<- bl_merge[-36, ]
bl_merge$Sex<-as.factor(bl_merge$Sex)
bl_merge$`Dwellings without basic facilities`<-as.numeric(bl_merge$`Dwellings without basic facilities`)
bl_merge$`Rooms per person`<-as.numeric(bl_merge$`Rooms per person`)
bl_merge$`Household net adjusted disposable income`<-as.numeric(bl_merge$`Household net adjusted disposable income`)
bl_merge$`Housing expenditure`<-as.numeric(bl_merge$`Housing expenditure`)
bl_merge$`Household net adjusted disposable income`<-as.numeric(bl_merge$`Household net adjusted disposable income`)
bl_merge$`Air pollution`<-as.numeric(bl_merge$`Air pollution`)

val_med<-median(bl_merge$`Air pollution`)
var<-(ifelse(bl_merge$`Air pollution`<val_med, 0, 1))
bl_merge<-bl_merge
bl_merge$`Air pollution`<-as.factor(var)


bl_merge$`Household net financial wealth`<-as.numeric(bl_merge$`Household net financial wealth`)

```


## RELAZIONE: Stato, Salario e genere

Il better index dataset permette di splittare il dataset originale in osservazioni in merito al sesso biologico per poter effettuare analisi di discriminazioni. La prima relazione multivariata è tra gli stati (ne ho considerate solo 6 per una migliore visualizzazione visiva), il reddito personale percepito medio e il genere. 
E' chiaro che, in linea generale, in tutti gli stati il salario è più alto per gli uomini che per le donne. La maggiore differenza tra i due sessi in termini monetari viene percepita negli Stati Uniti, che per altro possiede anche i valori più alti. La minore differenza di salario tra i due sessi è registrata in Italia , che per altro possiede i salari minimi più bassi tra i paesi confrontati. 


```{r}

bl_merge%>%
  filter(Stato %in% c('Australia', 'Austria', 'Canada', 'Italy', 'United Kingdom', 'United States'))%>%
  ggplot( aes(x = Stato, y = `Personal earnings`, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Guadagni Medi per Stato Condizionati al Genere", x = "Stato", y = "Guadagni Medi") +
  theme_minimal()
```


## RELAZIONE: Life Satisfaction, Work-life balance e Gender

La relazione tra "Life Satisfaction" e "Work-Life Balance" condizionata al genere viene esaminata tramite lo scatter plot condizionato al fine di ottenere informazioni rilevanti e capire l'interazione. In generale, tutti i punti tendenzialmnete tendono a salire da sinistra a destra, il che significa che le persone con un migliore equilibrio tra lavoro e vita tendono ad essere più soddisfatte nella vita. Le osservazioni per gli uomini sono leggermente spostate verso l'alto rispetto a quelle delle donne, con valori di soddisfazione della vita in media più alti. Inoltre, i punti delle femmine sono più dispersi, il che potrebbe indicare una maggiore variabilità nelle risposte ottenute dai diversi stati. Due valori potrebbero essere considerati pressocchè anomali, per entrambi work-life balance e life satisfaction esprimono quotazioni basi sia nella distribuzione maschile che femminile, per questo sono stati approfonditi: si sta facendo riferimento a Turchia e Messico. 

```{r}
ggplot(bl_merge, aes(x=`Life satisfaction`, y=`Time devoted to leisure and personal care`, colour=Sex)) +
geom_smooth(method="lm",size=1,se=FALSE)+
  facet_wrap(~Sex)+ geom_point()

# bl_merge %>%
#      filter(`Time devoted to leisure and personal care` < 13.1 & 
#                 `Life satisfaction`> 5 & 
#                 `Life satisfaction` < 6.7)
```


## RELAZIONE: Air pollution, gender e Years in education

Si è deciso , in seguito, di studiare la relazione presente tra gli anni di educazione per genere condizionato all'indice relativo l'inquinamento dell'aria dei diversi paesi. Tenendo conto che a seconda dell'indice di inquinamento dell'aria, si sono distinte due classi: gruppo 0 a cui appartengono gli stati che hanno indice di inquinamento minore della mediana , gli altri al gruppo 1. Visualizzando la relazione tramite i boxplot,si osserva che , in generale, le donne sembrano avere più anni di istruzione  in mediana rispetto agli uomini. Tuttavia, è presente una discrepanza interessante: nei paesi con Air Pollution = 1, il numero di anni di istruzione è inferiore rispetto a quelli con Air Pollution = 0. Questo potrebbe essere dovuto a diverse ragioni. Una spiegazione potrebbe essere che l'inquinamento dell'aria è associato a condizioni socioeconomiche o geografiche che influenzano l'accesso all'istruzione. Ad esempio,  persone in aree altamente inquinate potrebbero affrontare sfide economiche o sociali che limitano la loro opportunità di istruzione. Allo stesso tempo, potrebbe esserci una distribuzione geografica non uniforme dei dati, con le regioni altamente inquinate che influenzano i risultati.

```{r}
ggplot(bl_merge,aes(x=`Air pollution`,y=`Years in education`,colour=`Sex`)) +
geom_boxplot()+scale_fill_brewer(palette = "Paired")
```

# Modelli di regressione

Il dataset potrebbe essere adatto per condurre un'analisi di regressione
lineare, a seconda delle questioni di ricerca o delle ipotesi che si
intendono esaminare. La regressione lineare multipla è un modello
statistico che consente di esplorare le relazioni tra più variabili
indipendenti,o variabili di *input*, e una variabile dipendente,
comunemente chiamata *risposta*.

Per implementare un modello di regressione multipla è necessario che siano presenti due o più predittori e che ciascuna osservazione in presenza di queste variabili abbiano un dato registrato. Nel dataset better life index le variabili *Life expectancy e Life satisfaction* potrebbero essere utilizzate come variabile dipendente mentre le altre come covariate.

Poichè lo scopo è **prevedere l'aspettativa di vita o soddisfazione di vita in funzione degli altri indici del dataset** si considera l'utilizzo del modello di regressione. Esistono diversi tipi di modelli di regressione: lineare semplice, lineare multiplo, etc.. . Poichè il dataset permette di lavorare con molte variabili, è possibile confrontare il modello di regressione lineare semplice con quello multiplo.

## Split in train set e test set

Lo split dei dati in un set di addestramento e un set di test si rende necessario per valutare l'accuratezza del modello. Il *train set* è quel set di dati utilizzato per l'addestramento del modello mentre il *test set* viene utilizzato per prevedere la variabile dipendente e tramite metriche statistiche valutare l'accuratezza del modello.

L'obiettivo principale dei modelli è ottenere delle stime significative e valide che contribuiscano alla comprensione delle relazioni causa-effetto specifiche nella popolazione. La perseguibilità dell'obiettivo tiene conto dell'individuazione di risultati non necessariamente generalizzabili ma piuttosto validi per un sottoinsieme ristretto della popolazione. Per tanto, è stata presa la decisione di analizzare tutti i paesi a eccezione di quelli non presenti nell'aria OECD; questi ultimi nelle analisi precedenti hanno riportato problemi di non compatibilità e anomalia con il resto dei paesi dell'area altamente sviluppati, faccio riferimento a: South Africa, Brasile e Russia.

```{r}

# Divisione del dataset in train set(80%) e test set(20%)
set.seed(123)
bl_new <- bl_total %>%
  filter(!Stato %in% c('South Africa', 'Russia', 'Brazil'))
part<-createDataPartition(bl_new$`Life expectancy`, p=0.8, list=FALSE)

# Creazione del training set tramite le partizioni create
dat_train<-bl_new[part,]

#Creazione del test set escludendo le partizioni utilizzate per il training set
dat_test<-bl_new[-part,]

```

## Modello di regressione lineare semplice

Il modello di regressione lineare semplice è specificato dalla
relazione:

$$Y=\beta_o + \beta_1 x_1 +\epsilon $$

Dove $Y$ è la variabile dipendente, $X_1$ la covariata, $\epsilon$
l'errore residuo, $\beta_0 e \beta_1$ sono i parametri di intercetta e
coefficiente angolare della retta di regressione. L obiettivo geometrico
è quello di esplicitare la variabilità delle ordinate tramite quella
delle ascisse, ovvero trovare la retta che passi tra i punti nel modo
migliore e sintetizzando l'andamento complessivo medio che si percepisce
osservando i dati. Poichè si cerca di spiegare $Y$ tramite $X_1$ la
qualità statistica della retta dovrà essere giudicata sulla base della
sua capacità di adattarsi ai valori delle $Y$ osservate. Pertanto, una
buona retta di regressione sarà quella che minimizzerà la distanza
verticale tra i valori osservati di $y$ e quello teorici
$y(\beta_0,beta_1)$. Per cui i coefficienti vengono stimati minimizzando
la somma dei quadrati degli errori residui.



### Implementazione

I modelli di regressione implementati per il caso studio sono stati scelti tenendo conto della rilevanza degli aspetti statistici nel contesto del caso di studio. Come per la serie storica precedente, si ispeziona il variare dell'aspettativa di vita in relazione alla percentuale di famiglie che vivono senza l'accesso ai servizi sanitari primari. 
I risultati sono espressi nella tabella del summary. Per la valutazione dell'importanza e della significatività dei coefficienti stimati del modello viene effettuato il test di Wald sui singoli parametri, confrontando l'ipotesi $H_0$: il coefficiente associato a una variabile sia statisticamente diverso da 0, contro l'alternativa $H_1$: il coefficiente è statisticamente diverso da 0. Il valore del test viene quindi espresso dal p-value, fissata una soglia critica di livello $\alpha=0.05$, risultano essere statisticamente significative sia il valore di intercetta che la variabile relativa a dwelling. 


L’output del modello e i valori dei coefficienti esprimono l’effetto delle variabili sul valore di aspettativa di vita. Per valori positivi dei coefficienti, l'aspettativa di vita aumenta; per valori negativi dei coefficienti l'aspettativa di vita diminuisce. Il valore  dell’intercetta è  uguale a 81.89, indicando che se tutte le covariate fossero  uguali a zero l'aspettativa di vita della popolazione mediamente è 81.89 anni. 
L’interpretazione del coefficienti si sviluppa in questo modo: per ogni incremento unitario di percentuali di famiglie che non hanno a disposizione l'accesso ai servizi sanitari primari, l'aspettativa di vita diminuisce di 0.63 anni. Per quanto riguarda invece il test sui parametri contemporaneamente, su tutti i parametri del modello, si fa affidamento alla statististica F in basso e il corrispondente p-value. Il valore di F è 140.5, il suo p-value è molto  basso, per cui prossimo allo 0, rifiutiamo $H_0$ secondo la quale tutti i parametri sono uguali a 0, quindi accettiamo l'ipotesi $H_1$ che esiste almeno un parametro $b_j$ diverso da 0. 

```{r}
modello_semplice<-lm(`Life expectancy`~`Dwellings without basic facilities`, dat=dat_train)
summary(modello_semplice)
```


### Previsioni

Avendo stimato e addestrato il modello di regressione è possibile quindi
fare previsione sul test set (non utilizzato per l'addestramento).

```{r}
previsioni_semplice <- predict(modello_semplice, dat_test)
```

### R-quadro

L' $R^2$ è un coefficiente di determinazione: misura la bontà di
adattamento del modello ai dati. Se il valore dell' $R^2$ è prossimo
all' 1, significa che i regressori predicono bene il valore della
variabile dipendente nel campione; mentre se è uguale a 0, significa che
non lo fanno.

Ad ogni modo il coefficente non è in grado di stabilire la
significatività delle variabili o se è stato scelto il gruppo di
regressori più appropriato. L'indice dell' $R^2$ corretto è prossimo allo 0.29, per cui il modello così costruito esprime il 29% della variabilità dei dati.

```{r}
summary(modello_semplice)$r.squared

```
### Visualizzazione legame variabili

Tuttavia, confrontando praticamente non sembra che tra le due variabili sia presente un legame lineare. Per cui, il modello di regressione lineare non è in grado di approssimare bene questa relazione. 
```{r}
plot(bl_new$`Dwellings without basic facilities`,bl_new$`Life expectancy`, main="Scatterplot", xlab="Dwellings", ylab="Life Expectancy")

```




## Modello di regressione lineare multiplo

Il modello di regressione lineare multipla è una tecnica statistica utilizzata per prevedere una variabile dipendente, conosciuta anche come variabile risposta o target, sulla base della sua relazione con più variabili indipendenti, chiamate anche variabili esplicative o predictor. Questo modello presuppone che esista una relazione lineare tra la variabile dipendente e le variabili indipendenti.


### Implementazione

La regressione lineare multipla è comunemente impiegata quando ci sono più di una variabile indipendente che potrebbe influenzare la variabile dipendente. Ad esempio, si potrebbe utilizzare il modello di regressione lineare multipla per prevedere l'aspettativa di vita (variabile dipendente) in base a variabili indipendenti come non solo dwellings, numero di vani per persona, reddito netto disponibile, ricchezza finanziaria, qualità del supporto di rete, qualità dell'aria, qualità del'acqua e il tasso di omicidi. Questo modello  consente di comprendere come ciascuna di queste variabili indipendenti contribuisce alla variazione nella variabile dipendente e di stimare il loro impatto combinato sul risultato.

La tabella delle stime mostra come solo la soddisfazione di e il tasso di omicidi ha un p-value statisticamente significativo fissato alpha prossimo alo 0.05. E' tuttavia necessario sottolineare che l'importanza previsiva di una variabile non deve essere necessariamente valutata rispetto alla singola ma anche rispetto alla remota possibilità che da sola può non avere potere previsivo ma questo potrebbe aumentare se congiunta con un'altra variabile. Di solito si procede valutando il p-value e costruendo un modello con le sole variabili significative, ed è quello che viene fatta alla prossima implementazione, ma esistono dei metodi di feature selection che permettono di scegliere le variabili che hanno effettivamente effetto sulla variabile dipendente. Verrà analizzata nella terza implementazione. 

```{r}
variables = names(bl_total)[c(2:25)]
variables = variables[-18]
variables[23]<-"Time devoted to leisure and personal care`"
model1 = paste("`Life expectancy`", str_c(variables, collapse="`+`"), sep="~`")

modello_completo<-lm(model1, data=dat_train)
summary(modello_completo)
```


### Implementazione 2 

Poichè molte delle variabili risultano non statisticamente significative, si è pensato di creare un modello con le sole significative. 

Il modello così implementato mostra valore negativo per il tasso di omicidi e positivo per la soddisfazione di vita. In maniera logica, qualora si vivesse in uno stato in cui il tasso di omicidi è elevato l'aspettativa di vita diminuisce: in particolar modo, per ogni incremento unitario della percentuale di omicidi l'aspettativa di vita diminuisce di di 0.38 anni. La soddisfazione della vita personale , invece, contribuisce in maniera positiva all'aumento di vita: per ogni incremento unitario di soddisfazione l'aspettativa di vita aumenta di 0.13 anni. Il valore della statistica R-quadro è diminuita. 

```{r}
modello <- lm(`Life expectancy` ~  `Life satisfaction` +`Homicide rate`, data = dat_train)
summary(modello)
```
### Implementazione 3 

Si utilizza il metodo della STEPWISE come variable selection. La stepwise è identificata come un metodo per la selezione del modello. Nei casi in cui un dataset contiene un numero elevato di variabili potrebbe essere utile implementare una procedura che permetta di selezionare le variabili rilevanti per il problema oggetto di studio. La stepwise sviluppa una sequenza di modelli di regressione in cui a ogni step viene eliminata o aggiunta una variabile, tra quelle considerate. Il criterio di aggiunta o eliminazione si basa in termini di somma degli errori delle riduzioni al quadrato, coefficiente di correlazione, statistica t, statistica F. Il risultato finale identifica un unico modello di regressione come il “migliore”.
Esistono tre tipi di possibili selection: Forward Stepwise Selection, Backward Elimination e Stepwise selection. La differenza principale tra questi approcci sta nel modo in cui le variabili vengono aggiunte o rimosse dal modello. Forward e backward sono più semplici, poiché il primo inizia la selezione partendo dal modello con la sola intercetta; mentre il secondo inizia la selezione delle variabili partendo dal modello completo e andando a ritroso. Tuttavia, possono produrre modelli subottimali se le variabili significative sono fortemente correlate tra loro. 
La stepwise forward selection fonda la selezione del modello migliore sulla base degli indici per la bontà di adattamento e criteri di informazione. 
1) Individua un modello di regressione semplice con la sola intercetta per ciascuna delle potenziali variabili di $X$, per ciascuna calcola la statistica test per valutare se l’intercetta è statisticamente significativa o meno. La variabile con la statistica t più elevata e il p-value minore rispetto alla soglia stabilità $alpha$  viene aggiunta al modello; 
2) Si assume che la variabile $x_i$ è la variabile scelta allo step 1. La stepwise regression adatta tutti i modelli di regressione con due X, in cui una delle due è $x_i$. Per ogni modello individuato, la variabile $x_k$ con p-value più piccolo viene selezionata e utilizzata per lo step successivo e analogamente si sviluppano i passi successivi esaminando quale variabile $x$ è la migliore candidata valutando se c’è una variabile da dover eliminare.
3) Quando aggiungere o eliminare una variabile non cambia il risultato, la ricerca si conclude. 
Secondo questa logica è stato quindi individuato il modello migliore con le migliori variabili che hanno statisticamente un impatto sulla variabile dipendente. 

Il modello così individuato permette di tener conto di un numero maggiore di variabili determinate come statisticamente significative: guadagno personale, student skills, soddisfazione della vita, lavoro a lungo termin hanno un impatto positivo sulla variabile di aspettativa di vita mentre le variabili del tasso di omicidi, educational attenmant, qualità di supporto di rete sociale, tempo dedicato alla persona hanno un impatto negativo. 

```{r, echo=FALSE, include=FALSE}
library(MASS)
mod.null <- glm(`Life expectancy` ~ 1, data=dat_train)
#MODELLO COMPLETO
variables = names(bl_total)[c(2:25)]
variables = variables[-18]
variables[23]<-"Time devoted to leisure and personal care`"
model1 = paste("`Life expectancy`", str_c(variables, collapse="`+`"), sep="~`")
Step5.reg <- stepAIC(mod.null, direction="both", model1, trace=TRUE)
summary(Step5.reg)


```



```{r}
mod2.final <- lm(Step5.reg$formula, data=dat_train, x=TRUE)
summary(mod2.final)
```


### Previsioni

Dopo aver stimato il modello di regressione si possono prevedere i valori della variabile dipendente su un set di dati che non è stato usato per addestrare il modello.
```{r}
previsioni_1 <- predict(modello_completo, dat_test)
previsioni_2 <- predict(modello, dat_test)
previsioni_3 <- predict(mod2.final, dat_test)
```


### Confronto fra modelli

Per effettuare un confronto accurato, sono stati presi in considerazione diversi criteri, tra  cui l’adeguatezza del modello alle specifiche della popolazione di studio, la precisione  delle stime dei parametri, la bontà di adattamento e la capacità predittiva tramite l’utilizzo  di indici.

Si può tener conto di : 

#### Errore quadratico medio (RMSE)

L' **RMSE** (errore quadratico medio) è definito come :

$RMSE=\sqrt((\frac{1}{n} \sum^N_{i=1}(y_i-\widehat y)^2))$

dove:  $y_i$ è il valore reale di $y$; 
$\widehat y = x_i \widehat \beta$ è il valore previsto dal modello; 
n è il numero di osservazioni del test set.

E' una misura di errore assoluta in cui le deviazioni vengono elevate al
quadrato per evitare che valori positivi e negativi possano annullarsi
l'uno con l'altro. E' chiaramente preferibile il modello che presenta
indice rmse più basso.



#### Errore assoluto medio (MAE)

Il **mae** è invece definio come :

$$MAE=(\frac{1}{n} \sum^N_{i=1}|y_i-\widehat y|)$$

Un valore piccolo del MAE per il modello è sinonimo di previsioni
accurate mentre un valore grande del MAE è espressione di previsioni del
modello meno accurato.

#### AIC E BIC

I due criteri di informazione più comunemente utilizzati per i modelli
di regressione sono AIC e BIC. Sia  L la verosimiglianza del modello;
 k il numero di parametri del modello;  n il numero di osservazioni
nel campione, i criteri si definiscono come: Il criterio di informazione
di **Akaike (AIC)**: tiene conto del grado di adattamento del modello ai
dati e del numero di parametri del modello stesso. L'indice è calcolato
come:

$$AIC = -2log(L) + 2k$$

L'**AIC** assegna un punteggio ai diversi modelli e il modello con il
punteggio più basso è considerato il modello migliore.
Il criterio di **informazione bayesiano (BIC)**: questo criterio è simile all'AIC, ma penalizza in modo più severo i modelli che hanno un numero elevato di parametri. L'indice è calcolato come: BIC= -2LOG(L)+klog(n). 

Il **BIC** assegna un punteggio ai diversi modelli e il modello con il
punteggio più basso è considerato il modello migliore. Per entrambe le
formule, il primo termine $(-2log(L))$ è una misura della devianza del
modello, ovvero una misura della differenza tra i valori osservati e
quelli predetti dal modello. Il secondo termine è una penalizzazione per
il numero di parametri del modello, in modo che modelli più complessi
vengano penalizzati rispetto a quelli più semplici. Entrambi questi
criteri possono essere utilizzati per confrontare diversi modelli di
regressione e selezionare quello migliore. In generale, il modello con
il valore più basso di AIC o BIC è considerato il migliore tra i modelli
candidati.


La valutazione dell'aspettativa di vita rispetto alle singole feature di tassi di omicidi e aspettativa di vita  nel modello di regressione ha portato a una diminuzione del chi-quadrato nel set di dati ma risultati migliori in termini di previsioni, indicando che le variabili hanno un valore predittivo statisticamente significativo. Nel complesso,  queste le prestazioni dei modelli: 

  * Il modello contenente solo la variabili relativa alla percentuale di famiglie degli stati che non hanno accesso ai servizi sanitari primari mostra un livello basso di R-quadro, prossimo al 44% e mostra valori elevati per AIC e BIC, oltre che previsioni piuttosto pessime sul test set (RMSE E MAE); 
  * Il modello completo con tutte le variabili mosta un decremento dell'adattamento ai dati con R-quadro basso oltre che BIC pressocchè identico al modello precedente penalizzando appunto il fatto che siano aumentate il numero di features ma non sono effettivamente in grado di spiegare l'andamento dei dati, infatti l'AIC sensibile a un incremento artificiale al crescere del numero di variabili è minore. Tuttavia, mostra valori di previsione nettamente inferiori rispetto al modello con la sola variabile; 
  * Il modello aggiornato che contiene le sole variabili di homicide rate e life satisfaction (poichè le uniche variabili significative nel modello precedente) registra un adattamento ai dati da parte del modello piuttosto bassa per l'R-quadro (91%) ma AIC e BIC migliori.
  * In termini previsivi  il migliore è quello con le variabili scelte dalla stepwise.  



```{r}
# # modello semplice
# MSE_s <- mean((dat_test$`Life expectancy` - previsioni_semplice)^2)
# MSE_s
# MAE_s <- mean(abs(dat_test$`Life expectancy` - previsioni_semplice))
# MAE_s
# 
# AIC(modello_semplice)
# BIC(modello_semplice)
# 
# # modello completo 
# MSE_m <- mean((dat_test$`Life expectancy` - previsioni_1)^2)
# MSE_m
# MAE_s <- mean(abs(dat_test$`Life expectancy` - previsioni_1))
# MAE_s
# 
# AIC(modello_completo)
# BIC(modello_completo)
# 
# # modello ridotto
# MSE_m <- mean((dat_test$`Life expectancy` - previsioni_2)^2)
# MSE_m
# MAE_s <- mean(abs(dat_test$`Life expectancy` - previsioni_2))
# MAE_s
# AIC(modello)
# BIC(modello)

# # modello con stepwise
# MSE_m <- mean((dat_test$`Life expectancy` - previsioni_3)^2)
# MSE_m
# MAE_s <- mean(abs(dat_test$`Life expectancy` - previsioni_3))
# MAE_s
# AIC(mod2.final)
# BIC(mod2.final)




# modello_test_1 <- lm(`Life expectancy`~`Dwellings without basic facilities`, dat=dat_test)
# summary(modello_test_1)$r.squared
# 
# modello_test_2 <- lm(`Life expectancy`~`Dwellings without basic facilities`+`Housing expenditure`+`Rooms per person`+`Household net adjusted disposable income`+`Household net financial wealth`+`Labour market insecurity`+`Employment rate`+`Long-term unemployment rate`+`Personal earnings`+`Quality of support network`+`Educational attainment`+`Student skills`+`Years in education`+`Air pollution`+`Water quality`+`Stakeholder engagement for developing regulations`+`Voter turnout`+`Self-reported health`+`Life satisfaction`+`Feeling safe walking alone at night`+`Homicide rate`+`Employees working very long hours`+`Time devoted to leisure and personal care`, data = dat_train)
# summary(modello_test_2)$r.squared
# 
# modello_test_3 <- lm(`Life expectancy` ~  `Life satisfaction` +`Homicide rate`, data = dat_test)
# summary(modello_test_3)$r.squared
# 
# modello_test_4 <- lm(Step5.reg$formula, data = dat_test)
# summary(modello_test_4)$r.squared
```


| Modello | R-quadro | MSE | MAE | AIC | BIC|
|------:|:-----|---------|---------|---------|:------:|
| semplice | 44% | 9.656 | 2.015 | 142.86 | 147.26 |
| completo | 97% | 3.68 | 1.699 | 109.73 | 145.58 |
| aggiornato | 91% |  6.21|2.03| 123.07|  128.81 |
| con stepwise| 98% | 4.92 | 1.65 | 101.37 | 117.15|


## Analisi dei residui

Un'ulteriore approfondimento sull'accuratezza del modello può essere svolto attraverso lo scatter plot dei **valori osservati e quelli stimati dal modello**. 

I residui sono definiti come la differenza puntuale tra i veri
valori della y e quelli previsti dal modello.
I residui sono così definiti:

$E_i = y_i - \hat{y}_i = y_i - (\alpha + \alpha x_i)$


L’analisi dei residui consiste nel verificare se i residui, seguono una distribuzione normale e se sono distribuiti in modo casuale. Ciò è importante perché una distribuzione normale e casuale dei residui
indica che il modello è adeguato alla relazione tra le variabili dipendenti e indipendenti. Per eseguire un’analisi dei residui, è possibile utilizzare alcuni strumenti come un grafico di istogramma dei residui, un grafico Q-Q plot e un grafico di dispersione dei residui sui valori previsti. Nella realtà, spesso i dati non seguono perfettamente una distribuzione normale, ma è importante valutare se l’adesione al modello non sia troppo lontana dai valori attesi.
Il grafico Q-Q plot mostra che i residui seguono una distribuzione approssimativamente normale, in caso contrario i punti non si troverebbero sulla linea di regressione (escluse alcune osservazioni che discostano dalla linea, giustificati dal fatto che si sta aggregando per paesi che hanno quadri culturali, economici e sociali diversi). La maggior parte dei punti non sono direttamente sulla retta ma intorno per cui questo indica che il modello può essere sicuramente migliorato. Ad ogni modo sul
training set ha un ottimo fitting.

```{r}
qqnorm(mod2.final$residuals)
qqline(mod2.final$residuals, col = 2)

```
La verifica della Normalità è possibile effettuarla utilizzando alcuni test di Normalità.
Il Test di **Shapiro-Wilk** : Questo test verifica se i dati o i residui seguono una distribuzione normale. L'ipotesi nulla ($H_0$) del test è che i dati seguono una distribuzione normale. Il p-value, prossimo allo 0.85, ottenuto dal test è maggiore del livello di significatività specifico (0,05), allora non si può rifiutare l'ipotesi nulla e si può concludere che i residui possono essere considerati approssimativamente normalmente distribuiti. 

```{r}
shapiro.test(mod2.final$residuals)

```


Test di **Jarque-Bera** : Questo test è specifico per verificare la normalità dei residui. Calcola la statistica di Jarque-Bera, che è basata sulla curtosi (misura della forma della distribuzione) e sull'asimmetria (misura della simmetria della distribuzione) dei residui. L'ipotesi nulla ($H_0$) di questo test è che i residui seguono una distribuzione normale. Il p-value, prossimo allo 0.78,  ottenuto dal test è superiore a un determinato livello di significatività (0.05), l'ipotesi nulla viene mantenuta, indicando che i residui possono essere considerati normalmente distribuiti. 

```{r}
jarque.bera.test(mod2.final$residuals)

```



Infine il grafico di dispersione dei residui sui valori previsti mostra una distribuzione casuale, ovvero senza alcuno schema visibile, per cui espressione di non dipendenza. 

```{r}
plot(mod2.final$fitted.values, mod2.final$residuals)

```

Per la valutazione delle proprietà dei residui: 

1.  sum(e) = 0:
   Questa espressione rappresenta la somma dei residui $e_i$ su tutte le osservazioni i nel modello di regressione. Un requisito importante per un buon modello di regressione è che la somma dei residui sia il più vicina possibile a zero così che il modello dovrebbe essere in grado di prevedere correttamente il valore medio della variabile dipendente. Il risultato di somma dei residui pari a zero indica che, in media, il modello non sovrastima né sottostima le previsioni.

2. sum(x * e) = 0:
   Questa espressione rappresenta la somma del prodotto tra le variabili indipendenti $x_i$ e i residui $e_i$ corrispondenti su tutte le osservazioni i. Questa condizione indica che la covarianza tra le variabili indipendenti e i residui è zero. Ciò implica che le variabili indipendenti stanno spiegando adeguatamente la variazione nella variabile dipendente. Il risultato ottenuto non è quello atteso . 

3. sum(y*e) = 0:
   Questa espressione rappresenta la somma del prodotto tra la variabile dipendente $y_i$ e i residui $e_i$ corrispondenti su tutte le osservazioni i. Questa condizione indica che la covarianza tra la variabile dipendente e i residui è zero. Questo suggerisce che il modello di regressione stia catturando in modo adeguato la relazione tra le variabili indipendenti e la variabile dipendente.  Il risultato ottenuto non è quello atteso. 


```{r}
sum(mod2.final$residuals)
sum(mod2.final$residuals*bl_new$`Personal earnings`)
sum(mod2.final$fitted.values*bl_new$`Life expectancy`)



```



# Clustering

Per clustering si intende un'insieme di tecniche statistiche volte alla
ricera di sottogruppi (*clusters*) omogenei all'interno di una
popolazione di riferimento. Fa parte dei task di learning *unsupervised*
e si caratterizza per la ricerca di pattern nascosti, di struttura
significative all'interno di dati unlabeled, ovvero di dataset per i
quali non si hanno informazioni a disposizione circa la reale
associazione esistente tra le istanze in essi contenuti ed in gruppi.
Nei metodi di clustering l'obiettivo ultimo si configura nell'utilizzo
della distribuzione osservata delle variabili al fine di ricercare
gruppi all'interno del data set in input. Tale processo di
individuazione viene eseguito facendo in modo che le osservazioni
appartenenti allo stesso cluster siano quanto più possibile simili l'una
all'altra (*omogeneità within*), mentre le istanze associate a gruppi
diversi siano abbastanza dissimili tra di loro (*eterogeneità between*).

Nell'analisi di cluster molto spesso ci si pone dinanzi al problema
della *standardizzazione delle variabili*. La standardizzazione delle
variabili è essenziale in quanto permette di eliminare le differenze di
scala, in quanto le variabili in un set di dati possono avere unità di
misura diverse o range di valori molto diversi. Senza standardizzazione,
le differenze di scala possono influire in modo significativo sui
risultati del clustering, poiché le variabili con valori più elevati
avranno un peso maggiore nella distanza tra le osservazioni. La
standardizzazione rende tutte le variabili comparabili, garantendo che
ciascuna abbia la stessa importanza nel processo di clustering. Inoltre
migliora le prestazioni degli algoritmi basati sulla distanza tra le
osservazioni,senza standardizzazione, le variabili con scale diverse
influiranno in modo sbilanciato sulla distanza. La standardizzazione
garantisce che le variabili contribuiscano in modo equo alla misura
della distanza, migliorando le prestazioni degli algoritmi di
clustering. Sui risultati del clustering influisce ,in maniera
significativa, la scelta del numero di variabili da utilizzare oltre che
quali variabili effettivamente sono utili a scindere i diversi gruppi,
per farlo si utilizza la **PCA**.

Il metodi di cluster si distinguono in cluster **gerarchico** e cluster
**non gerarchico**.

#### Clustering Gerarchico

Il clustering gerarchico è un metodo di raggruppamento dei dati che
organizza le osservazioni in una struttura gerarchica a forma di albero,
comunemente rappresentata come un dendrogramma. Questo tipo di
clustering è intrinsecamente gerarchico, il che significa che i cluster
possono essere ulteriormente suddivisi in sotto-cluster, creando una
struttura ad albero. Nel clustering gerarchico, ci sono principalmente
due approcci:

*Agglomerativo*: l'approccio inizia considerando ogni punto dati come un
cluster separato e successivamente unisce iterativamente i cluster più
vicini fino a ottenere un unico cluster contenente tutti i punti. Questo
crea una struttura gerarchica dalla base verso l'alto.

*Divisivo*: Al contrario, l'approccio divisivo inizia con tutti i punti
dati in un unico grande cluster e quindi lo suddivide iterativamente in
cluster più piccoli. È come "dividere" il cluster in modo progressivo.
Questo crea una struttura gerarchica dall'alto verso il basso.

#### Clustering Non Gerarchico (o Partizionamento):

Il **clustering non gerarchico**, non crea una struttura gerarchica a
forma di albero. Invece, assegna direttamente ogni punto dati a uno dei
cluster, senza creare sottoclassi. Questo tipo di clustering è meno
orientato alla gerarchia ed è più adatto quando si desidera suddividere
i dati in gruppi distinti senza ulteriori suddivisioni interne.

Un esempio comune di clustering non gerarchico è il K-Means, in cui si
specifica un numero prefissato di cluster (K) e l'algoritmo assegna ogni
osservazione a uno dei K cluster basandosi sulla loro somiglianza.

Si analizzeranno quindi:

-   Algoritmi di **clustering Gerarchico** ;
-   Algoritmi di **clustering Non-Gerarchici: K-Means**.

## Clustering gerarchico

Il clustering gerarchico produce raggruppamenti di item seguendo un
processo gerarchico: parte da tutti gli oggetti separati in gruppi
individuali e quindi procede iterativamente con l'aggregazione di coppie
di gruppi "che si somigliano di più", arrivando al termine a produrre un
unico gruppo contenente tutti gli item. Il punto di partenza di ciasun
metodo di Clustering Gerarchico (HC) è il calcolo della dissimilarità di
ciascun individuo rispetto a tutti gli altri. I passaggi sono i
seguenti:

1.  **Scelta del criterio di omogeneità**: gli elementi all interno di
    uno stesso gruppo si somigliano;
2.  **Funzione obiettivo**: misura la qualità del clustering in base al
    livello conseguito di omogeneità/eterogeneità.
3.  **Algoritmo**: la procedura numerica per massimizzare la funzione
    obiettivo.

### Similarità e dissimilarità

Si consideri un oggetto *i* come una riga della matrice dei dati
espresso da *p* features rappresentate nel vettore $x_i$. Molto spesso
gli oggetti sono di tipo euclideo mentre altre volte potrebbero non
esserlo (nel caso specifico....).

Le **misure di similarità** permettono di quantificare la somiglianza
tra due oggetti o individui. L'obiettivo è assegnare un valore numerico
che rappresenti quanto due oggetti siano simili tra loro, con 0 che
indica assoluta assenza di somiglianza e 1 che indica massima
somiglianza. Queste misure sono spesso utilizzate in contesti in cui la
somiglianza è un concetto chiave, come il clustering o il riconoscimento
di pattern. Alcuni esempi di misure di similarità includono la
similarità coseno, la similarità di Jaccard, e la similarità di Pearson.

Le **metriche di somiglianza** si basano principalmente sul concetto di
funzioni distanza tra i vettori delle caratteristiche degli oggetti. Una
funzione a valori reali $d(X_i, X_j)$ è considerata una "funzione
distanza" se e solo se soddisfa alcune condizioni specifiche. Queste
condizioni sono solitamente:

a.  **Positività:** La distanza deve essere sempre non negativa, ovvero
    $d(X_i, X_j) >= 0$ per tutti i $X_i e X_j$.
b.  **Identità dei non-simili:** La distanza tra oggetti identici deve
    essere zero, ovvero $d(X_i, X_i) = 0.$
c.  **Simmetria:** La distanza tra $X_i e X_j$ deve essere uguale a
    quella tra $X_j e X_i$, ovvero $d(X_i, X_j) = d(X_j, X_i)$.
d.  **Disuguaglianza del triangolo:** La distanza tra $X_i e X_j$
    attraverso un punto intermedio $X_k$ deve essere inferiore o uguale
    alla somma delle distanze dirette, ovvero
    $d(X_i, X_j) <= d(X_i, X_k) + d(X_k, X_j)$.

Alcune delle funzioni distanza più comuni includono la distanza
euclidea, la distanza di Manhattan, la distanza di Mahalanobis e la
distanza di Hamming.

Il calcolo delle distanze avviene tramite il comando *dist*.
Innanzitutto si crea una partizione selezionando il 70% delle
osservazioni del campione totale:

```{r}
set.seed("10")
p_bl<- createDataPartition(bl_total$`Life satisfaction`, p = 0.7, list = FALSE)
part_bl <- bl_total[p_bl, ]
part_bl
```

Si procede con lo scale e standardizzazione dei dati per far si che si
abbia la possibilità di lavorare con dati omogenei dal punto di vista
della varianza campionaria.

```{r}
etichette_cluster <- part_bl[,1]
bl_std <- scale(part_bl[,-1],center = TRUE,scale = TRUE)
rownames(bl_std) <- as.list(etichette_cluster$Stato)

```

Segue il calcolo delle principali metriche di distanza

**Metriche di distanza**

La distanza **euclidea** è fornita di default per il metodo *dist*.
Questa in genere è calcolata come, presi due punti a e b :

$$d(a,b)=\sqrt{(b_1-a_1)^2+(b_2-a_2)^2+(b_n-a_n)^2}$$

La distanza di **Manhattan**, è calcolata come la somma delle differenze
assolute tra le coppie di valori tra due punti. Questa distanza è utile
quando le dimensioni sono indipendenti e il percorso tra i punti deve
seguire una griglia rettangolare. È chiamata "Manhattan" perché
rappresenta la distanza tra due punti su una griglia stradale di una
città, dove puoi muoverti solo lungo strade parallele o perpendicolari.

Qui la sua formulazione:

$$d_1(X_i,X_j) = \sum_{k=1}^p|x_{ik}-x_{jk}|$$

La distanza di **Chebyshev** è calcolata come la massima differenza tra
i valori corrispondenti delle coppie tra due punti. Questa distanza
coinvolge anche una procedura di ordinamento per calcolare la massima
differenza. È utile quando si desidera misurare la massima differenza
tra le dimensioni dei punti.

Qui la sua formulazione:

$$d_\infty(X_i,X_j) = \max_{ \ k=1,2,...,p} |x_{ik} - x_{jk}|$$

La distanza di **Minkowski** è una metrica più generale che include sia
la distanza di Manhattan (quando il parametro "p" è uguale a 1) che la
distanza euclidea (quando il parametro "p" è uguale a 2) come casi
particolari. Il parametro "p" consente di regolare il comportamento
della distanza in base alle caratteristiche specifiche dei dati. È utile
quando le dimensioni sono importanti e le relazioni tra di esse sono
complesse. Quando "p" è diverso da 1 o 2, la distanza di Minkowski può
essere utilizzata per adattarsi a situazioni diverse.

Qui la sua formulazione:

$$d_r(X_i,X_j) = \Biggl[ {\sum_{k=1}^p}|x_{ik}-x_{jk}|^r\Biggl]^{1/r}$$

```{r}
## Metrica Euclidea
d <- dist(bl_std,diag = TRUE, upper = TRUE)

## Manhattan
dMh <- dist(bl_std,method = "manhattan", diag = TRUE, upper = TRUE)

## Chebycev
dCb <- dist(bl_std,method = "maximum", diag = TRUE, upper = TRUE)

## Minkowski
dMski <- dist(bl_std,method = "minkowski",4, diag = TRUE, upper = TRUE)

```


**Misure di non omogeneità statistica**

Le misure di non omogeneità statistica sono metriche utilizzate nelle applicazione statistiche. Si utilizza di solito la matrice di varianza e covarianza. 
```{r}
#il set di dati bl_std è standardizzato
WI <- cov(bl_std)
#WI
```

Per mezzo della matrice di covarianza è possibile calcolare la SSM, statistical scatter matrix moltiplicata per (n-1). Sommando la diagonale principale della matrice si ottiene la traccia. (non viene stampata perchè è molto grande e occupa spazio)

```{r}
n = nrow(bl_std)
HI <-(n-1)*WI
#HI
#Traccia della matrice
trHI <-sum(diag(HI))
#trHI

```

Questa misura riguarda l'intera popolazione e viene affiancata da due altre misure: una che valuta la differenza all'interno dei gruppi (denominata "within") e un'altra che valuta la differenza tra i gruppi stessi (denominata "between"). L'obiettivo di queste misure è determinare se il metodo utilizzato per raggruppare individui ha effettivamente creato gruppi con individui simili all'interno di ciascun gruppo, ma diversi tra gruppi diversi.

**Metriche di similarità**

Una funzione di similarità, o coefficiente di similarità,è una funzione
che genera un valore numerico compreso tra 0 e 1 che misura la
somiglianza o la differenza tra due punti all'interno di un dataset. Per
essere considerata una funzione di similarità, deve soddisfare tre
importanti proprietà:

**Unitarietà**: La funzione di similarità deve restituire il valore
massimo (1) quando si confrontano due punti che sono identici. In altre
parole, la massima somiglianza deve essere assegnata quando i punti sono
gli stessi.

**range tra 0 e 1**: Il valore restituito dalla funzione di similarità
deve essere compreso tra 0 e 1. Questo implica che la somiglianza tra
due punti non può essere inferiore a 0 (assoluta assenza di somiglianza)
né superiore a 1 (massima somiglianza).

**Simmetria**: La funzione di similarità deve essere simmetrica. Questo
significa che la similarità tra i punti $X_1 e X_2$ deve essere identica
alla similarità tra i punti $X_2 e X_1$.

La funzione di similarità viene spesso rappresentata attraverso una
matrice S, in cui l'elemento $s_ij$ rappresenta la similarità tra il
punto i-esimo e il punto j-esimo all'interno del dataset. Inoltre:

1.  Ogni distanza è una dissimilarità ma non è vero viceversa;
2.  Una dissimilarità non deve necessariamente soddisfare la
    diseguaglianza triangolare;

Le metriche di similarità vengono spesso utilizzate per validare la
partizione. La validazione è una problematica concettuale poichè non c'è
una soluzione oggettiva dei dati. Servono principalmente a stabilire
quanto due partizioni concordano.

Prese due collezzioni $A$ e $B$, si definisce il **coefficiente
Jaccard** (espressione della somiglianza tra due collezioni):

$s(A,B)=|A\cap B| / |A \cup B|$

L'indice assume valore compreso tra 0 e 1, 0 indica assenza di
somiglianza mentre 1 espressione di massima somiglianza.

Per la definizione del miglior numero di gruppi si utilizza SILHOUETTE
WIDTH (spiegato successivamente). 

I metodi gerarchici si dividono in due gruppi di algoritmi clustering:

1.  AGGLOMERATIVI,

-   si parte da una partizione in cui ogni osservazione appartiene a un
    cluster;
-   in ogni step si fondono i 2 cluster più simili in un unico cluster;
-   lo step precedente viene ripetuto sino a ottenere un unico cluster.

2.  DIVISIVI
-   si parte da una partizione contenente tutte le osservazioni; 
-   in ogni step il cluster più grande viene diviso in due cluster             dissimili fra loro; 
-   lo step precedente viene ripetuto sino a ottenere un unico cluster

Il processo di fusione gerarchico viene sintetizzato in un **grafo** chiamato *Dendogramma*. Nel dendogramma ogni nodo rappresenta un gruppo; alla base ci sono i *leaf nodes* ovvero gli *n* gruppi formati dagli *n* oggetti. In testa è presente il *root node*, contenente tutto il dataset. Ogni nodo ha al suo interno due *children nodes*, ovvero i gruppi della fusione dai quali si ottiene il cluster rappresentato dal parent node. 

```{r}

d_2     <- get_dist(bl_std, stand = FALSE , method = "euclidean")
hls <- hclust(d_2, method = "single")
plot(hls, hang = -2,
xlab=" Metodo gerarchico agglomerativo ",
sub ="del legame singolo ",
ylab = "Distanza",
main = "Dendogramma")
```


In r per analizzare i metodi di clustering gerarchici si utilizza il comando *hclust*. I passi sono i seguenti: 

1. Si inzia con un set di dati rappresentati dalla matrice X, e si decide se standardizzare questi dati. Si sceglie il metodo per calcolare le distanze tra gli elementi e si crea una matrice delle distanze D o una matrice di similarità S.

2. Si trova la coppia di elementi con la distanza più breve nella matrice D e si raggruppano in un cluster. Poi, si ricalcola la matrice delle distanze considerando il nuovo cluster.

3. Si crea una nuova matrice delle distanze con una riga e una colonna in meno, escludendo i dati del cluster appena creato.

4. Si ripete il passo 2 sulla nuova matrice finché non si ottiene una matrice 2x2, eseguendo n-1 iterazioni in totale.

5. Si rappresenta l'intero processo mediante il dendrogramma, che mostra come gli elementi sono stati raggruppati in cluster.

### SINGLE LINKAGE

Il termine **"linkage"** si riferisce alla misura di dissimilarità o di similarità tra due gruppi di dati all'interno di un algoritmo di clustering gerarchico. L'obiettivo di utilizzare diverse misure di linkage è di determinare come i dati dovrebbero essere aggregati in cluster in base alle relazioni di dissimilarità o similarità tra di essi.

Esistono diverse misure di linkage, tra cui:

1. **Single Linkage**: Questo metodo calcola la distanza tra i punti più vicini dei due cluster. In altre parole, misura la dissimilarità tra i due punti più vicini, uno da ciascun cluster. Questo può portare a cluster molto allungati e vulnerabili a errori dovuti a punti anomali.

2. **Complete Linkage**: In questo caso, la misura di linkage si basa sulla distanza tra i punti più lontani dei due cluster. Ciò significa che la dissimilarità è calcolata tra i punti più distanti nei due cluster. Questo metodo tende a creare cluster più compatti, ma può anche soffrire di effetto di "crowding."

3. **Average Linkage**: Questo metodo calcola la media delle distanze tra tutti i punti nei due cluster. Questo approccio può essere considerato una via di mezzo tra il single e complete linkage e tende a produrre cluster di dimensioni più uniformi.


Cambiando il tipo di linkage utilizzato, si otterranno diversi risultati nella struttura gerarchica dei cluster. La scelta del linkage dipenderà dal tipo di dati e dall'obiettivo del clustering. Ad esempio, se si desidera identificare cluster compatti e ben separati, si potrebbe optare per il complete linkage, mentre se si desidera sensibilità alle differenze sottili tra i dati, si potrebbe scegliere l'average linkage. 


Ci si concentra in primo luogo sul single linkage. Questp è definito come, dati due gruppi $A e B$, la minima dissimilarità tra due oggetti appartenenti ai due gruppi: 

$$d_SL (A,B)=min{d(a,b) : a \in A, b \in B}$$

Si procede confrontando distanza euclidea e distanza di manhattan e con la visualizzazione del plot. 

Nel primo caso, ho eseguito un'analisi di clustering gerarchico utilizzando la distanza di Manhattan. Questo metodo misura la somma delle differenze assolute tra le variabili tra i punti del dataset. Il risultato è un dendrogramma che mostra come gli stati sono stati raggruppati in base alle loro somiglianze. Nel grafico risultante, si osserva che alcuni stati con valori di indici di vita simili si sono uniti in cluster, mentre altri rimangono isolati. 

Nel secondo caso, ho eseguito un'analisi simile utilizzando la distanza euclidea. Questa misura calcola la distanza geometrica tra i punti del dataset. I cluster sono diversi rispetto al caso della distanza di Manhattan che tende a creare cluster più allungati, a differenza della distanza euclidea che forma cluster più compatti.
Tuttavia, sono presenti delle similarità. Ad esempio, alcuni stati si raggruppano nello stesso modo in entrambi i grafici ( South Africa da solo; Turchia messico e Brasile), suggerendo che la struttura dei dati è stabile rispetto alle due misure di distanza. 

```{r}
library(ggplotify)

d_2     <- get_dist(bl_std, stand = FALSE , method = "euclidean")
d_3     <- get_dist(bl_std, stand = FALSE , method = "manhattan")


single_hls_1 <- hclust(d_3, method = "single")

p2<-plot(single_hls_1,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame singolo ",
ylab = "Distanza Manhattan",
main = "Singolo")
single_hls <- hclust(d_2, method = "single")
p1<-plot(single_hls,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame singolo ",
ylab = "Distanza Euclidea",
main = "Singolo")



```

Per entrambe le distanze viene riportato lo screeplot, seppur considerazioni sulla validazione dei cluster verranno effettuate successivamente. 
```{r}
plot ( c (0 , single_hls_1$height ) , seq (28 ,1) , type = "b" ,
 main = " Screeplot " , xlab =" Distanza di aggregazione Distanza Manhattan " , ylab = " Numero di cluster " , col =" red " )
plot ( c (0 , single_hls$height ) , seq (28 ,1) , type = "b" ,
 main = " Screeplot " , xlab =" Distanza di aggregazione Distanza Euclidea" , ylab = " Numero di cluster " , col =" red " )

```

Sulla base del dendogramma si ritiene che il taglio ad altezza di 3 cluster potebbe essere ottimale. Si visualizzano i gruppi scelti sul dendogramma. 
All'altezza 3 , per entrambe le distanze si ottengono gli stessi sottogroppi , nonostante la riduzione della similarità è differente. 
```{r}
cut_single <- cutree(single_hls, k = 3)

```

```{r}
plot(single_hls,hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame singolo ",
ylab = "Distanza Euclidea", main = "Singolo")
rect.hclust(single_hls , k = 3, border = 2:6)

plot(single_hls_1,hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame singolo ",
ylab = "Distanza Manhattan", main = "Singolo")
rect.hclust(single_hls , k = 3, border = 2:6)
```

```{r}
sclus_1 = data.frame()
sclus_2 = data.frame()
sclus_3 = data.frame()
cut_single <- cutree(single_hls, k = 3)
for (i in 1:nrow(bl_std)) {
    if (cut_single[i] == 1) {
      sclus_1 <- rbind(sclus_1, bl_std[i,])
    }
    if (cut_single[i] == 2) {
      sclus_2 <- rbind(sclus_2, bl_std[i,])
    }
    if (cut_single[i] == 3) {
      sclus_3 <- rbind(sclus_3, bl_std[i,])
    
  }
}
# 
# names(sclus_1) <- c("cty","hwy")
# names(sclus_2) <- c("cty","hwy")
# names(sclus_3) <- c("cty","hwy")

```

Per valutare l'omogeneità o la non omogeneità dei tre cluster, prima si calcola una misura globale della loro omogeneità. Questo permette di ottenere una comprensione generale della similarità o differenza tra i cluster stessi. La misura di non omogeneità totale è 648. 

```{r}
sclust <- bl_std
ns <- nrow(sclust)
trHs <-(n -1) *sum (apply (sclust,2, var ))
trHs

```
Successivamente, si procede al calcolo dell'omogeneità all'interno di ciascun cluster, ossia quanto gli elementi all'interno di ogni cluster siano simili tra loro. Questa misura interna ai cluster è comunemente denominata "within-cluster heterogeneity" o "non omogeneità interna ai cluster".
I risultati sono i seguenti: 
- nel primo cluster la misura di non omogeneità statistica è la più alta poichè è il gruppo che contiene più elementi al suo interno; 
- nel secondo cluster (con presenza di tre stati) il valore è nettamente diminuito; 
- nel terzo cluster il risultato è 0 perchè è presente una sola osservazione (South Africa)
```{r}
#GRUPPO 1
Ws1 <- cov(sclus_1)
ns1 <- nrow(sclus_1)
Hs1 <- (ns1-1)*Ws1
if (ns1 > 1) {
trHs1 <-sum(diag(Hs1))
}else{
trHs1 <- 0
}


#GRUPPO 2
Ws2 <- cov(sclus_2)
ns2 <- nrow(sclus_2)
Hs2 <- (ns2-1)*Ws2
Hs2 <- (ns2-1)*Ws2
if (ns2 > 1) {
trHs2 <-sum(diag(Hs2))
}else{
trHs2 <- 0
}


#GRUPPO 3
Ws3 <- cov(sclus_3)
ns3 <- nrow(sclus_3)
Hs3 <- (ns3-1)*Ws3
if (ns3 > 1) {
trHs3 <-sum(diag(Hs3))
}else{
trHs3 <- 0
}
cbind(trHs1, trHs2, trHs3)
```
Il valore della metrica within è significativamente più grande dell'indice between si potrebbe dedurre che la suddivisione in tre cluster potrebbe non essere soddisfacente. Questo suggerisce che i punti all'interno dei cluster sono molto simili tra loro, ma ci potrebbero essere notevoli differenze tra i cluster stessi.

Una situazione in cui la varianza all'interno dei cluster è molto più grande della varianza tra i cluster potrebbe indicare che i cluster non stanno realmente catturando strutture significative nei dati o che la suddivisione dei dati in cluster non è stata efficace.

Si potrebbero considerare delle alternative come:

- Aumentare il numero di cluster per cercare di catturare strutture più dettagliate nei dati. 
- Utilizzare un'altra tecnica di clustering che potrebbe essere più adatta.


| Within Total | Between Total | 
|------:|:-----|
| 417.123 | 230.877 |
```{r}
# #WITHIN TOTAL
# trWithin <- trHs1 +trHs2 + trHs3
# trWithin
# #BETWEEN TOTAL
# trBetween <- trHs - trWithin
# trBetween
```
Il rapporto tra la misura di non omogeneità tra cluster between e la traccia della matrice di non omogeneità è del 35.63%, dunque per nulla alta. 
```{r}
# s_perc <- as.character(round((trBetween/trHs),4)*100)
# paste(s_perc,"%",sep="")
```
E' possibile in fine visualizzare i risultati in un diagramma di Venn i tre cluster. 

Dal diagramma si nota che è presente un singolo grande gruppo e gli altri 2 invece sono più piccoli, questo potrebbe essere un effetto collaterale del metodo a legame singolo, proprio perché viene a crearsi un effetto a catena che lega elementi dissimili perché si guarda solo alla distanza minima.
Il south Africa costituisce un cluster a sè, oltre che Turchia, Brasile e Messico. 
```{r}
clusplot(bl_std, cut_single, color=TRUE,
shade=TRUE, labels=3,
lines=0, xlab=" Legame singolo",
ylab = "Distanza", main = "Singolo")
```

### COMPLETE LINKAGE 

Il complete linkage tra due gruppi $A e B$ è definito come la massima dissimilarità tra due oggetti appartenenti ai due gruppi: 

$$d_CL (A,B)=max{d(a,b) : a \in A, b \in B}$$


Il dendrogramma ottenuto con il legame completo ha rami più lunghi rispetto al dendrogramma ottenuto con il legame singolo, poiché i gruppi si formano a livelli di distanza maggiori. Infatti la scala delle ordinate va da 2 a 12 per la distanza euclidea e non da 2 a 8 come nel metodo del legame singolo. La differenza nei dendogrammi per le due distanze è evidente con gruppi più compatti per la distanza di Manhattan e meno compatta per quella euclidea, oltre che sottogruppi di Stati diversi. Rispetto al legame singolo non sembra esserci presente la distinzione di Turchia, Messico e Brasile, tuttavia South Africa continua a non essere associato a nessuna osservazione. 

```{r}
complete_hls <- hclust(d_2, method = "complete")
complete_hls_1 <- hclust(d_3, method = "complete")

plot(complete_hls, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame completo ",
ylab = "Distanza Euclidea", main = "Completo")

plot(complete_hls_1, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame completo ",
ylab = "Distanza Manhattan", main = "Completo")
```

In corrispondenza di altezze alte si riduce di molto la dissimilarità. Dalla rappresentazione grafica sono presenti situazioni in cui la dissimilarità sembra ridursi molto a un taglio di cluster pari a 4, in tal caso vengono uniti gruppi piuttosto differenti sulla base della misura. Ora considerare la distanza di manhattan o euclidea rende significativa la diversa associazione. South Africa continua a rimanere in un cluster a parte; E' presente un cluster di 4 che si distingue nei paesi Messico, Brasile, Grecia e Turchia per la distanza euclidea mentre Polonia, Slovacchia, Israele e Korea per la distanza di manhattan. 

```{r}
plot(complete_hls_1, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame completo ",
ylab = "Distanza Manhattan", main = "Completo")
rect.hclust(complete_hls , k = 4, border = 2:6)

plot(complete_hls, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame completo ",
ylab = "Distanza Euclidea", main = "Completo")
rect.hclust(complete_hls , k = 4, border = 2:6)

```

Per entrambe le distanze si calcolano le metriche utili alla descrizione. La misura di non omogeneità è 648. 


```{r}
cut_complete <- cutree(complete_hls, k = 4)
cut_complete_m <- cutree(complete_hls_1, k = 4)

###EUCLIDEA
cclus_1 = data.frame()
cclus_2 = data.frame()
cclus_3 = data.frame()
cclus_4 = data.frame()
for (i in 1:nrow(bl_std)) {
if (cut_complete[i]==1) {
cclus_1 <- rbind(cclus_1, bl_std[i,])
}
if (cut_complete[i]==2) {
cclus_2 <- rbind(cclus_2, bl_std[i,])
}
if (cut_complete[i]==3) {
cclus_3 <- rbind(cclus_3, bl_std[i,])
}
if (cut_complete[i]==4) {
cclus_4 <- rbind(cclus_4, bl_std[i,])
}
}

###MANHATTAN 

###EUCLIDEA
cclus_5 = data.frame()
cclus_6 = data.frame()
cclus_7 = data.frame()
cclus_8 = data.frame()
for (i in 1:nrow(bl_std)) {
if (cut_complete_m[i]==1) {
cclus_5 <- rbind(cclus_5, bl_std[i,])
}
if (cut_complete_m[i]==2) {
cclus_6 <- rbind(cclus_6, bl_std[i,])
}
if (cut_complete_m[i]==3) {
cclus_7 <- rbind(cclus_7, bl_std[i,])
}
if (cut_complete_m[i]==4) {
cclus8 <- rbind(cclus_8, bl_std[i,])
}
}

cclust <- bl_std
nc <- nrow(cclust)
trHc <- (n - 1) * sum (apply (cclust, 2, var))
trHc

```

La tabella presenta quattro gruppi di cluster con misurazioni di eterogeneità basate su distanza euclidea e di Manhattan. Considerando la distanza euclidea, il Gruppo 1 mostra un alto grado di eterogeneità (112.078), seguito da Gruppo 3 (104.69), mentre Gruppo 2 è meno eterogeneo (71.544). Gruppo 4 è l'unico con un'eterogeneità euclidea pari a zero, poichè è presente un unica osservazione. 

Nel caso dell'eterogeneità di Manhattan, i risultati sono simili, ma con valori leggermente più bassi in generale. Gruppo 1 è ancora il più eterogeneo (77.593), seguito da Gruppo 3 (14.322) e Gruppo 2 (50.427). Gruppo 4 ha ancora un'eterogeneità di Manhattan pari a zero, sempre poichè possiede un unica osservazione.

|Gruppo| Within Eterogenity Euclidea | Within Eterogenity Manhattan  | 
|------:|:-----------------|---------------|
| Gruppo 1 | 112.078 |  77.593   |
| Gruppo 2 | 71.544        |  50.427    |
| Gruppo 3| 104.69   |  14.322         |
| Gruppo 4 |    0    |    0    |

```{r}

####EUCLIDEA
#GRUPPO 1
Wc1 <- cov(cclus_1)
nc1 <- nrow(cclus_1)
Hc1 <- (nc1-1)*Wc1
trHc1 <-sum(diag(Hc1))
# trHc1
#GRUPPO 2
Wc2 <- cov(cclus_2)
nc2 <- nrow(cclus_2)
Hc2 <- (nc2-1)*Wc2
trHc2 <-sum(diag(Hc2))
# trHc2
#GRUPPO 3
Wc3 <- cov(cclus_3)
nc3 <- nrow(cclus_3)
Hc3 <- (nc3-1)*Wc3
trHc3 <-sum(diag(Hc3))
# trHc3
#GRUPPO4
Wc4 <- cov(cclus_4)
nc4 <- nrow(cclus_4)
Hc4 <- (nc4-1)*Wc4
trHc4 <-sum(diag(Hc4))
# trHc4


#####MANHATTAN
#GRUPPO 1
Wc5 <- cov(cclus_5)
nc5 <- nrow(cclus_5)
Hc5 <- (nc5-5)*Wc5
trHc5 <-sum(diag(Hc5))
# trHc5
#GRUPPO 2
Wc6 <- cov(cclus_6)
nc6 <- nrow(cclus_6)
Hc6 <- (nc2-1)*Wc6
trHc6 <-sum(diag(Hc6))
# trHc6
#GRUPPO 3
Wc7 <- cov(cclus_7)
nc7 <- nrow(cclus_7)
Hc7 <- (nc7-1)*Wc7
trHc7 <-sum(diag(Hc7))
# trHc7
#GRUPPO4
Wc8 <- cov(cclus_8)
nc8 <- nrow(cclus_8)
Hc8 <- (nc8-1)*Wc8
trHc8 <-sum(diag(Hc8))
# trHc8

```
La distanza euclidea mostra un valore di within maggiore mentre la distanza di manhattan mostra un valore maggiore per la betwee. 
In entrambi i casi, qualunque delle due distanze si consideri, la "Between Total" è maggiore della "Within Total", suggerendo che c'è una maggiore differenza tra i cluster rispetto alla variabilità all'interno dei cluster. Per questo motivo, la suddivisione dei dati in cluster sembra essere in grado di catturare una notevole differenza tra i cluster stessi.

|Distanza | Within Total | Between Total | 
|------:|:-----|--------|
| Euclidea | 288.316 |   359.683 |
|Manhattan |  142.343   | 505.656|

```{r}

###EUCLIDEA
#WITHIN TOTAL
trWithin <- trHc1 + trHc2+ trHc3
#trWithin
#BETWEEN TOTAL 
trBetween <- trHc - trWithin
#trBetween


###MANHATTAN
trWithin <- trHc5+ trHc6+ trHc7
#trWithin
#BETWEEN TOTAL 
trBetween <- trHc - trWithin
#trBetween
```


Per la distanza euclidea, il rapporto tra "Between Total" e "Total" è del **55,55%**, il che significa che circa il 55,55% della varianza totale è dovuta alle differenze tra i cluster (between), mentre il restante 44,45% è dovuto alla variabilità all'interno dei cluster (within). Così, il metodo completo (utilizzato con la distanza euclidea) ha una maggiore capacità di catturare le differenze tra i cluster rispetto al legame singolo con circa il 17% in più.
Nel caso in cui si consideri la distanza di Manhattan, il rapporto tra "Between Total" e "Total" cresce significativamente fino al **78,03%**. Per cui, il metodo completo utilizzato con la distanza di Manhattan è particolarmente efficace nel catturare le differenze tra i cluster, con una percentuale molto maggiore rispetto alla distanza euclidea.

|Euclidea|Manhattan|
|--------|:----------|
|55.55%  | 78.03%    |
```{r}
# c_perc <- as.character(round((trBetween/trHc),4)*100)
# paste(c_perc,"%",sep="")

```
Anche se la distanza di manhattan mostra metriche migliori per i gruppi, la rappresentazione grafica rende evidente come vengono aggregate osservazioni anche molto dissimili fra loro. 

```{r}
clusplot(bl_std, cut_complete, color=TRUE,
shade=TRUE, labels=3, lines=0,
xlab=" Legame completo",
ylab = "Distanza Euclidea", main = "Complete")

clusplot(bl_std, cut_complete_m, color=TRUE,
shade=TRUE, labels=3, lines=0,
xlab=" Legame completo",
ylab = "Distanza Manhattan", main = "Complete")


```


### AVERAGE LINKAGE 

L'average linkage tra i gruppi $A e B$ è definito come la dissimilarità media tra tutte le coppie di punti appartenenti a $A e B$. 


$d_{(AL)}(A,B) = \frac{1}{n_An_B} \sum_{a \in A} \sum_{b \in B} {d(a,b)}$

Il dendrogramma ottenuto utilizzando il legame medio ha rami di lunghezza intermedia rispetto al dendrogramma ottenuto con il legame singolo e a quelli ottenuti con il legame completo. Questo perché i gruppi si formano a livelli di distanza media tra i punti dati, il che significa che i cluster nel dendrogramma medio sono più coesi rispetto a quelli nel dendrogramma completo ma meno coesi rispetto a quelli nel dendrogramma singolo.

```{r}
average_hls <- hclust(d_2, method = "average")
average_hls_1 <- hclust(d_3, method = "average")

plot(average_hls, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame medio ",
ylab = "Distanza Euclidea",
main = "Medio")
plot(average_hls_1, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame medio ",
ylab = "Distanza Manhattan",
main = "Medio")

```
Un taglio ad altezza 4 mi sembra ragionevole in quanto tagliare ad altezza 2 significherebbe scremare troppo poco gli stati. 
Ancora una volta l'utilizzo della metrica individua cluster completamente diversi: sulla base della distanza euclidea, si ottengono metriche pressocchè simili al legame singolo ad eccezione di un cluster unico con la Grecia. 
```{r}
plot(average_hls, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame medio ",
ylab = "Distanza Euclidea", main = "Medio")
rect.hclust(average_hls , k = 4, border = 2:6)
average_hls_2 <- hclust(d_3, method = "average")
plot(average_hls_1, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame medio ",
ylab = "Distanza Manhattan", main = "Medio")
rect.hclust(average_hls_2 , k = 4, border = 2:6)
```



```{r}
cut_average <- cutree(average_hls, k = 4)
cut_average_m <- cutree(average_hls_1, k = 4)


###EUCLIDEA
cclus_1 = data.frame()
cclus_2 = data.frame()
cclus_3 = data.frame()
cclus_4 = data.frame()
for (i in 1:nrow(bl_std)) {
if (cut_average[i]==1) {
cclus_1 <- rbind(cclus_1, bl_std[i,])
}
if (cut_average[i]==2) {
cclus_2 <- rbind(cclus_2, bl_std[i,])
}
if (cut_average[i]==3) {
cclus_3 <- rbind(cclus_3, bl_std[i,])
}
if (cut_average[i]==4) {
cclus_4 <- rbind(cclus_4, bl_std[i,])
}
}

###MANHATTAN 

cclus_5 = data.frame()
cclus_6 = data.frame()
cclus_7 = data.frame()
cclus_8 = data.frame()
for (i in 1:nrow(bl_std)) {
if (cut_average_m[i]==1) {
cclus_5 <- rbind(cclus_5, bl_std[i,])
}
if (cut_average_m[i]==2) {
cclus_6 <- rbind(cclus_6, bl_std[i,])
}
if (cut_average_m[i]==3) {
cclus_7 <- rbind(cclus_7, bl_std[i,])
}
if (cut_average_m[i]==4) {
cclus_8 <- rbind(cclus_8, bl_std[i,])
}
}



aclust <- bl_std
na <- nrow(aclust)
trHa <- (n - 1) * sum (apply (aclust, 2, var))
trHa
```
Si confrontano i 4 cluster ottenuti dall'average linkage sulla base delle distanze euclidee e di Manhattan. 

|Gruppo| Within Eterogenity Euclidea | Within Eterogenity Manhattan  | 
|------:|:-----------------|---------------|
| Gruppo 1 | 339.050|  77.593  |
| Gruppo 2 | 0        |  0    |
| Gruppo 3| 37.001  |  37.001        |
| Gruppo 4 |    0    |    0    |
```{r}

####EUCLIDEA
#GRUPPO 1
Wc1 <- cov(cclus_1)
nc1 <- nrow(cclus_1)
Hc1 <- (nc1-1)*Wc1
trHc1 <-sum(diag(Hc1))
# trHc1
#GRUPPO 2
Wc2 <- cov(cclus_2)
nc2 <- nrow(cclus_2)
Hc2 <- (nc2-1)*Wc2
trHc2 <-sum(diag(Hc2))
# trHc2
#GRUPPO 3
Wc3 <- cov(cclus_3)
nc3 <- nrow(cclus_3)
Hc3 <- (nc3-1)*Wc3
trHc3 <-sum(diag(Hc3))
# trHc3
#GRUPPO4
Wc4 <- cov(cclus_4)
nc4 <- nrow(cclus_4)
Hc4 <- (nc4-1)*Wc4
trHc4 <-sum(diag(Hc4))
# trHc4


#####MANHATTAN
#GRUPPO 1
Wc5 <- cov(cclus_5)
nc5 <- nrow(cclus_5)
Hc5 <- (nc5-5)*Wc5
trHc5 <-sum(diag(Hc5))
# trHc5
#GRUPPO 2
Wc6 <- cov(cclus_6)
Hc6 <- (nc2-1)*Wc6
trHc6 <-sum(diag(Hc6))
nc6 <- nrow(cclus_6)
# trHc6
#GRUPPO 3
Wc7 <- cov(cclus_7)
nc7 <- nrow(cclus_7)
Hc7 <- (nc7-1)*Wc7
trHc7 <-sum(diag(Hc7))
# trHc7
#GRUPPO4
Wc8 <- cov(cclus_8)
nc8 <- nrow(cclus_8)
Hc8 <- (nc8-1)*Wc8
trHc8 <-sum(diag(Hc8))
# trHc8

```

La distanza Euclidea è sensibile a dispersioni su tutte le dimensioni, mentre la distanza di Manhattan è più robusta contro dispersioni su una singola dimensione. 


|Distanza | Within Total | Between Total | 
|------:|:-----|--------|
| Euclidea | 376.052 |   271.94 |
|Manhattan |  114.595   | 533.405|
```{r}

###EUCLIDEA
#WITHIN TOTAL
trWithin <- trHc1 + 0+ trHc3
#trWithin
#BETWEEN TOTAL 
trBetween <- trHc - trWithin
#trBetween


###MANHATTAN
trWithin <- trHc5+ 0+ trHc7
#trWithin
#BETWEEN TOTAL 
trBetween <- trHc - trWithin
#trBetween
```
Per la distanza euclidea, il rapporto tra "Between" e "Total" è del **41.97%**, il che significa che circa il 41.97% della varianza totale è dovuta alle differenze tra i cluster (between), mentre il restante è dovuto alla variabilità all'interno dei cluster (within). Così, il metodo dell0average (utilizzato con la distanza euclidea) ha una capacità maggiore di catturare le differenze tra i cluster rispetto al legame singolo ma inferiore rispetto al legame completo..
Nel caso in cui si consideri la distanza di Manhattan, il rapporto tra "Between " e "Total" cresce significativamente fino al **82.32%**. Il legame dell'average sulla distanza di Manhattan mostra risultati migliori della distanza euclidea e di tutti i linkage in generale. 

|Euclidea|Manhattan|
|--------|:----------|
|41.97%  | 82.32%    |


```{r}
a_perc <- as.character(round((trBetween/trHc),4)*100)
paste(a_perc,"%",sep="")

```
Anche graficamente i cluster basati sulla distanza di Manhattan , sul legame medio, sono più comprensibili e compatti. 
```{r}
clusplot(bl_std, cut_average, color=TRUE,
shade=TRUE, labels=3, lines=0,
xlab=" Legame medio",
ylab = "Distanza Euclidea", main = "Average")
clusplot(bl_std, cut_average_m, color=TRUE,
shade=TRUE, labels=3, lines=0,
xlab=" Legame medio",
ylab = "Distanza Manhattan", main = "Average")
```

Il grafico che sembra più chiaro è quello basato sul linkage average, si riesce a visualizzare meglio e a comprendere a quali altezza viene effettutata la fusione. Questo perchè l avarage linkage permette di non avere problemi ne di crowding che di chaining, ovvero fondere rispetto alla massima o alla minima distanza fra coppie evitando tutte le altre.

### Metodo del centroide

Nel contesto del metodo del centroide e del metodo della mediana, è necessario adoperare con la distanza euclidea. Il metodo del centroide, un algoritmo di clustering gerarchico, determina la distanza tra due cluster valutando la distanza tra i rispettivi centroidi, che rappresentano le medie campionarie dei dati nei due cluster.

$$d_{((i,j),k} = \frac{1}{2}(d_{(i,k)}^2 + d_{(j,k)}^2) - \frac{1}{4}d_{i,j}^2$$

```{r}
d_quadro <- d_2^2
centroide_hls <- hclust(d_quadro, method = "centroid")
plot(centroide_hls, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del centroide ", ylab = "Distanza", main = "Centroide")
rect.hclust(centroide_hls , k = 3, border = 2:6)
```
La partizione creata è pressocchè la stessa del legame singolo e medio. 

La traccia ha sempre lo stesso valore, poichè si considerano lo stesso numero di unità statistiche. 

```{r}
cut_centroide <- cutree(centroide_hls, k = 3)
clus_1 = data.frame()
clus_2 = data.frame()
clus_3 = data.frame()
for (i in 1:nrow(bl_std)) {
if (cut_centroide[i]==1) {
clus_1 <- rbind(clus_1, bl_std[i,])
}
if (cut_centroide[i]==2) {
clus_2 <- rbind(clus_2, bl_std[i,])
}
if (cut_centroide[i]==3) {
clus_3 <- rbind(clus_3, bl_std[i,])
}
}

clust <- bl_std
n <- nrow(clust)
tr_H <- (n - 1) * sum (apply (clust, 2, var))
tr_H
```

Anche i valori di eterogeneità interna, within totale e between totale sono gli stessi del metodo gerarchico con il linkage medio. 

|Gruppo| Within Eterogenity Euclidea | 
|------:|:-----------------|
| Gruppo 1 | 380.050|
| Gruppo 2 | 0        |  
| Gruppo 3| 37.001  |  


|Distanza | Within Total | Between Total | 
|------:|:-----|--------|
| Euclidea | 417.123|   230.87 |


Con questo grafico riusciamo a vedere come si distribuiscono i punti dei vari gruppi, e possiamo vedere che la partizione a tre va bene in quanto si nota il distacco dai gruppi.

```{r fig.align = 'center'}
cut_centroide_list <- list(cut_centroide)
agmean <- aggregate (bl_std, cut_centroide_list , mean )[,-1]
plot(bl_std, col = cut_centroide , 
     main = " Metodo gerarchico del centroide ", xlim = c(-4,17), 
     ylim = c(-4,26))
points (agmean ,col = 1:2, pch =8, cex =1)

```
Proprio come il metodo del legame singolo e del legame medio si è formato un fenomeno gravitazionale che ha unito degli elementi dissimili tra loro in un unico cluster e ha creato cluster con un'unica informazione. 



```{r}
#GRUPPO 1
Wc1 <- cov(clus_1)
nc1 <- nrow(clus_1)
Hc1 <- (nc1-1)*Wc1
trHc1 <-sum(diag(Hc1))
# trHc1
#GRUPPO 2
Wc2 <- cov(clus_2)
nc2 <- nrow(clus_2)
Hc2 <- (nc2-1)*Wc2
trHc2 <-sum(diag(Hc2))
# trHc2
#GRUPPO 3
Wc3 <- cov(clus_3)
nc3 <- nrow(clus_3)
Hc3 <- (nc3-1)*Wc3
trHc3 <-sum(diag(Hc3))


#WITHIN TOTAL
trWithin <- trHc1 +  trHc2
#trWithin
#BETWEEN TOTAL 
trBetween <- tr_H - trWithin
#trBetween



clusplot(bl_std, cut_centroide, color=TRUE,
shade=TRUE, labels=3, lines=0,
xlab=" Centroide", ylab = "Distanza", main = "Centroide")

```


### Metodo della mediana

Il procedimento della mediana presenta somiglianze con quello del centroide, ma si distingue per il fatto che la sua esecuzione è indipendente dal numero di cluster. Quando due gruppi si fondono, il nuovo centroide viene calcolato come la media dei due centroidi precedenti.

Dal grafico, a un plot di taglio pari a k=3 cluster si generano situazioni ancora peggiori di quelle precedenti: sono presenti 2 cluster con un'unica osservazione e un terzo cluster che possiede il resto degli stati. 

```{r}
Median_hls <- hclust(d_quadro, method = "median")
plot(Median_hls, hang = -2, xlab=" Metodo gerarchico agglomerativo",
sub ="della mediana ", ylab = "Distanza", main = "Mediana")
rect.hclust(Median_hls , k = 3, border = 2:6)

```


Le metriche di rappresentazione sono piuttosto pessime. Il gruppo 1 omogeneizza troppo contenendo tutte le osservazioni meno 2 (Grecia e South Africa) con valori chiaramenti elevati per la eterogenità interna. 

|Gruppo| Within Eterogenity Euclidea | 
|------:|:-----------------|
| Gruppo 1 | 497.160|
| Gruppo 2 | 0        |  
| Gruppo 3| 0  |  


|Distanza | Within Total | Between Total | 
|------:|:-----|--------|
| Euclidea | 497.16|   150.83 |

```{r}
cut_mediana <- cutree(Median_hls, k = 3)
mclus_1 = data.frame()
mclus_2 = data.frame()
mclus_3 = data.frame()
for (i in 1:nrow(bl_std)) {
if (cut_mediana[i]==1) {
mclus_1 <- rbind(mclus_1, bl_std[i,])
}
if (cut_mediana[i]==2) {
mclus_2 <- rbind(mclus_2, bl_std[i,])
}
if (cut_mediana[i]==3) {
mclus_3 <- rbind(mclus_3, bl_std[i,])
}
}

mclust <- bl_std
nm <- nrow(mclust)
trmH <- (nm - 1) * sum (apply (mclust, 2, var))


#GRUPPO 1
Wc1 <- cov(mclus_1)
nc1 <- nrow(mclus_1)
Hc1 <- (nc1-1)*Wc1
trHc1 <-sum(diag(Hc1))
# trHc1
#GRUPPO 2
Wc2 <- cov(mclus_2)
nc2 <- nrow(mclus_2)
Hc2 <- (nc2-1)*Wc2
trHc2 <-sum(diag(Hc2))
# trHc2
#GRUPPO 3
Wc3 <- cov(mclus_3)
nc3 <- nrow(mclus_3)
Hc3 <- (nc3-1)*Wc3
trHc3 <-sum(diag(Hc3))


#WITHIN TOTAL
trWithin <- trHc1 
#trWithin
#BETWEEN TOTAL 
trBetween <- trmH - trWithin
#trBetween

clusplot(bl_std, cut_mediana, color=TRUE,
shade=TRUE, labels=3, lines=0,
xlab="Mediana", ylab = "Distanza", main = "Mediana")
```

## Validazione e scelta di K: 

Il clustering è un task unsupervised. Ex-post non si possono confrontare i
risultati con il **ground-truth**. Tuttavia, si ha bisogno di strumenti che in qualche modo  danno una misura della qualità del clustering. 

**Scelta del numero di gruppi K**

In alcuni metodi viene visto come un problema di stima, questo presuppone l’esistenza di un modello che definisce un “vero” K. In molte applicazioni i diversi valori di K potrebbero dare una “buona” rappresentazione della popolazione, per cui la scelta di K è un problema di validazione piuttosto che di stima. 

I metodi più utilizzati per misurare qualità e accuratezza si basano su una statistica. 

**Silhouette Width**

Il metodo prende in input un vattore con i cluster label e la matrice di dissimilarità. L'ida di base è che in un buon clustering ogni punto è ben connesso al suo cluster, mentre è scarsamente connesso agli altri clusters. 

La dissimilarità media tra l'oggeto *i* del cluster *C* e tutti i punti del suo cluster è data da, misurando la connesione di *i* al suo cluster: 

$$a(i) = \frac{1}{|C_i| - 1} \sum_{j \in C_i, i \neq j} d(i, j) $$

dove: 
$C_i$ è il cluster al quale appartiene il punto 
$d(i,j)$ è la distanza tra il punto i e il punto j.

La dissimilarità media tra *i* e il suo cluster più prossimo è il minimo di, misurando la connessione tra i e gli altri cluster a cui i non appartiene: 

$$b(i) = min_{k \neq i} \frac{1}{|C_k|} \sum_{j \in C_k} d(i, j) $$

Il **silhouette width di i** è espresso come: 

$$S(i) = \frac{b(i) - a(i)}{max {a(i), b(i)}} $$

Questa metrica esprime quanto bene un punto è ancorato al suo cluster e quanto meno ancorato al cluster simile. Se il valore è prossimo a 1,allora il punto è ben accomodato nel suo cluster; se il valore è prossimo a -1 allora starebbe meglio nel clsuter simile; se il valore è prossimo allo 0 allora il punto si trova in una regione di transizione tra i due clusters. 

Infine, l'**average Silhouette Width** 

$$ ASW = \frac{1}{N} \sum_{i=1}^{N} S(i) $$

La situazione ottimale è volere un clustering con il più alto ASW possibile. 

**Criterio di Calinski-Harabasz**

Il metodo prende in input i labels del clustering e la matrice di dissimilarità. L'idea di base è che in un buon clustering si ha un alto rapporto tra dissimilarità between e dissimilarità within. 

Nella dissimilarità within-cluster si valuta la media delle distanze (o dissimilarità) tra tutti i punti all'interno di uno stesso cluster, misurando quanto i membri di un cluster sono simili tra loro. 
Nella dissimilarità between-clusters si calcola la media delle distanze tra i centroidi (o altri rappresentanti) dei diversi cluster, fornendo un'indicazione di quanto i cluster siano separati tra loro.

L'indice del criterio di Calinski è rappresentato da: 
$$CHC = \frac{Varianza tra-cluster}{Varianza all'interno del cluster} \frac{(Numero di osservazioni) - (Numero di cluster)}{(Numero di cluster) - 1}$$

Aumentando il numero di cluster generalmente W diminuisce e B aumenta, tuttavia l'**effetto sul fattore di correzione** è inverso, e per alti valori di K questo produce una forte deflazione del rapporto correggendo l'effetto di overfitting. 


**Dunn Index**

L’indice Dunn è comunemente utilizzato per identificare cluster compatti e ben separati tra di loro, con una bassa variabilità all’interno di ciascun gruppo. Tale concetto `e formalizzato dalla seguente espressione:


$$D = \frac{\min_{i \neq j} {d}(C_i, C_j)}{\max_{i} \max_{a, b \in C_i} {d}(a, b)} $$

o meglio: 

$$D = \frac{(Minima distanza tra centroidi)}{(Massima dimensione interna a un cluster)}$$

dove: 
$C_i$ rappresenta la distanza tra i centroidi dei cluster ; 
$d(C_i, C_j)$ rappresenta la distanza tra i centroidi dei cluster i e j; 
$d(a, b) $ rappresenta la distanza tra gli oggetti a e b nello stesso cluster. 



### TWSS vs k: scelta del numero di gruppi

In base ai dati e agli obiettivi dell'analisi, la combinazione della distanza di Manhattan e il linkage "average" ha prodotto cluster che erano più omogenei tra i loro membri rispetto ad altre opzioni. Questa configurazione ha mostrato una maggiore coesione all'interno dei cluster, che è l obiettivo desiderato nell'analisi di clustering, soprattutto se si cercano gruppi con pattern simili o comportamenti analoghi. La TWSS resta costante qualunque sia il taglio di cluster. 

```{r}


d_3 <- get_dist(bl_std, stand = FALSE, method = "manhattan")
hc <- hclust(d_3, method = "average")

# Crea un vettore per memorizzare i valori TWSS
twss_values <- numeric(length = 7)  # da 2 a 8 tagli

# Calcola TWSS per tagli da 2 a 8
for (k in 2:8) {
  clusters <- cutree(hc, k)
  cluster_centers <- aggregate(bl_std, list(clusters), mean)
  twss <- sum(apply(bl_std, 1, function(x) sum((x - cluster_centers$mean[clusters])^2)))
  twss_values[k - 2] <- twss
}



# Crea un grafico per visualizzare come cambia TWSS per i diversi tagli
plot(2:8, twss_values, type = "b", xlab = "Numero di Cluster", ylab = "TWSS")

```


### ASW vs K: scelta del numero di gruppi 

Il plot mostra come varia il valore dell'ASW in corrispondenza di gruppi che vanno da k=2 a k=8. L'ASW diminuisce drasticamente, indicando che aggiungere ulteriori cluster non migliora significativamente la coerenza dei gruppi. Si osserva un repentino cambiamento nella pendenza dell'ASW da k=7 in poi, k=7 rappresenta il punto in cui l'aggiunta di cluster non migliora la coerenza e potrebbe addirittura peggiorare la qualità del clustering (portando l'ASW prossimo allo 0). 
Il numero ottimale di cluster è rappresentato dal picco massimo di ASW in k=2,  indicando che due cluster potrebbero essere l'opzione ottimale. Questo punto riflette una buona coerenza all'interno dei cluster, mentre aggiungere ulteriori cluster sembra non portare a miglioramenti significativi. 

```{r}
d_3 <- get_dist(bl_std, stand = FALSE, method = "manhattan")
hc <- hclust(d_3, method = "average")

# CalcolO ASW per tagli da 2 a 8
asw_values <- numeric(length = 7)  # da 2 a 8 tagli
for (k in 2:8) {
  clusters <- cutree(hc, k)
  asw_1 <- silhouette(clusters, dist = d_3)[,3]
  asw_values[k - 2] <- mean(asw_1) 

}

# Creazione di un grafico per l'ASW
plot(2:8, asw_values, type = "b", xlab = "Numero di Cluster", ylab = "ASW")

# Aggiunta di una linea verticale per il valore massimo di ASW
max_asw <- max(asw_values)
abline( h= max_asw, col = "red", lty = 2, )

legend("topright", legend = paste("Max ASW =", round(max_asw, 2)), col = "red", lty = 2)

```

**Analisi dell'ASW Migliore**

Il numero di gruppi migliori per l'ASW è 2, tuttavia, si confrontano graficamente k da 2 a 4. In dettaglio, si analizzano i silhouette plot delle partizioni più utili per effettuare valutazioni ulteriori circa la qualità del partizionamento ottenuto. A ciascuna osservazione presente nel campione è associata una barra orizzontale, di lunghezza pari al suo silhouette. Sarebbe auspicabile che, per ciascun gruppo, il maggior numero possibile di silhouette superasse la linea verticale posta in corrispondenza dell’ASW ; tuttavia non è esattamente questo il caso specifico. 

Per **k=2**,24 osservazioni si trovano nel primo cluster e 4 nel restante.Il primo gruppo è abbastanza compatto: ad un buon numero di istanze è associato un silhouette maggiore della media, ed essi decrescono seguendo un andamento smooth e regolare, il primo cluster mostra ASW discreto (0.42). Il secondo cluster mostra valore più basso prossimo allo 0.26. Nonostante ciò il valore medio complessivo è il migliore 0.39.  

Per un numero di gruppi pari a 3, la situazione è evidentemente peggiore. Per quanto concerne il primo gruppo, non solo la decrescita dei silhouette - da quelli delle unità più centrali al cluster a quelle meno ancorato ad esso è meno lenta e più frastagliata, ma sono anche presenti delle unità per cui sw < 0. Ciò implica che tali osservazioni sono state con ogni probabilità mis-classificate, in quanto risultano in media più dissimili dalle istanze presenti all’interno del proprio gruppo che da quelle appartenenti al cluster ad esse pù prossimo. Queste, così come le numerose osservazioni per cui sw prossimo allo 0 che si trovano lungo la regione di transizione tra due gruppi - risultando in una scarsa connessione ad entrambi - portano ad un abbassamento dell’ASW totale misurato. Questa partizione individua anche un cluster con un'unica osservazione. L'asw totale diminuisce sino a 0.30 rispetto alla partizione precedente. 

Per *k=4*, si creano cluster sempre più piccoli e più omogenei. Oltre che, al crescere di k insorgono sempre un numero maggiore di punti di frontiera. 

```{r}
cl_k2 <- cutree(hc, k=2)
si_km2  <- silhouette(x = cl_k2 , dist = d_3)
plot(si_km2, main = "K=2" , col = 1:2)
asw2 <- mean(si_km2[,3])
abline(v = asw2)



# K=3
cl_k3 <- cutree(hc, k=3)
si_km3  <- silhouette(x = cl_k3 , dist = d_3)
plot(si_km3, main = "K=3" , col = 1:3)
asw3 <- mean(si_km3[,3])
abline(v = asw3)


#K=4
cl_k4 <- cutree(hc, k=4)
si_km4  <- silhouette(x = cl_k4 , dist = d_3)
plot(si_km4, main = "K=4" , col = 1:4)
asw4 <- mean(si_km4[,3])
abline(v = asw4)
```

### CHC vs K: scelta del numero di gruppi


Come l'ASW il numero di gruppi che massimizza il CHC sono 2. L'aumentare del numero di gruppi non assicura in alcun modo un incremento dell'indice, piuttosto corrisponde una ripida discesa. 

```{r}
Kmax <- 10  
CHC  <- rep(0, times = Kmax-1)
for(k in 2:Kmax){
    a   <- pam(x = d_3, k = k)
    ci  <- cluster.stats(d = d_3, clustering = a$clustering)
    CHC[k-1] <- ci$ch
}
plot(2:Kmax, CHC, t="b", lwd = 3, xlab = "K", ylab = "CHC")
```

## APPRONDIMENTO CON CLUSTER SENZA VALORI ANOMALI 

Si decide, visti i risultati precedenti, di lavorare con le osservazioni selezionate appartenenti ai paesi aderenti all' OECD, così che i paesi estranei a quest'area non influiscano in maniera notevole per via delle differenze registrate piuttosto sensibili. 
Nonostante ciò, la differenza dovuta ad aggregazioni tra nazioni con background diversi permane facendo sì che continuino a essere presenti cluster con 1 e valori per l'ASW ancora più bassi del caso precedente. 
```{r}
set.seed("10")
p_bl<- createDataPartition(bl_total$`Life satisfaction`, p = 0.7, list = FALSE)
part_bl <- bl_total[p_bl, ]
part_bl<-part_bl%>%
  filter(!Stato %in% c('South Africa', 'Russia', 'Brazil', 'Mexico', 'Türkiye'))
etichette_cluster <- part_bl[,1]
bl_2 <- scale(part_bl[,-1],center = TRUE,scale = TRUE)
rownames(bl_2) <- as.list(etichette_cluster$Stato)
d_3 <- get_dist(bl_2, stand = FALSE, method = "manhattan")
hc <- hclust(d_3, method = "average")

cut_average_m <- cutree(hc, k = 4)
plot(hc, hang = -2,
xlab=" Metodo gerarchico agglomerativo",
sub ="del legame medio ",
ylab = "Distanza", main = "Medio")
rect.hclust(hc , k = 3, border = 2:6)

# CalcolO ASW per tagli da 2 a 8
asw_values <- numeric(length = 7)  # da 2 a 8 tagli
for (k in 2:8) {
  clusters <- cutree(hc, k)
  asw_1 <- silhouette(clusters, dist = d_3)[,3]
  asw_values[k - 2] <- mean(asw_1)  

}

# Creazione di un grafico per l'ASW
plot(2:8, asw_values, type = "b", xlab = "Numero di Cluster", ylab = "ASW")

# Aggiunta di una linea verticale per il valore massimo di ASW
max_asw <- max(asw_values)
abline( h= max_asw, col = "red", lty = 2, )

legend("topright", legend = paste("Max ASW =", round(max_asw, 2)), col = "red", lty = 2)


```


## Clustering non gerarchico 

Dato un numero preassegnato  $K$ di gruppi, i metodi di clustering non gerarchico (NHC) cercano la paritizione dei dati (“righe” o item) in  $K$ cluster in maniera tale da ottenere un buon clustering, espresso come partizione dove gli item entro ciascun cluster o gruppo siano quanto possibile simili tra loro, mentre gli item appartenenti a cluster diversi siano quanto possibile diversi.Tra i molti algoritmi di clustering non gerarchici sviluppati finora, il più popolare è il **K-means**. Per questo algoritmo la disomogeneità tra due oggetti è determinata sulla base della distanza Euclidea.  Un possibile approccio per ottenere questo risultato potrebbe passare attraverso l’elencazione di tutti i possibili raggruppamenti in $K$ gruppi costruibili con gli item e quindi scegliere come migliore soluzione il raggruppamento che ottimizza un qualche criterio predefinito. Sfortunatamente, un tale approccio diventerebbe rapidamente inapplicabile, specialmente per grandi dataset, poiché richiederebbe una quantità enorme di tempo macchina e di spazio di memoria. Infatti, il problema del K-means è **NP-hard**: il calcolo alla soluzione del problema della funzione obiettivo è computazionalmente intrattabile, pochè bisognerebbe verificare questa condizione per tutte le possibili assegnazioni di $n$ oggetti a $K$ liste. Di conseguenza tutte le tecniche di clustering disponibili sono iterative e operano solo su un numero molto ristretto di ripetizioni.
Nella sua implementazione fondamentale, l’algoritmo K-means inizia assegnando gli item a uno dei $K$ cluster predeterminati e quindi calcolando i  $K$ centroidi di gruppo , oppure pre-specificando i  $K$ centroidi di gruppo. I centroidi pre-specificati possono essere item selezionati casualmente oppure possono essere ottenuti “tagliando” un dendrogramma ad una altezza appropriata.
In seguito, tramite una *procedura iterativa*, l’algoritmo cerca di minimizzare la somma dei quadrati entro gruppi (**WGSS**) su tutte le variabili, riassegnando (“spostando”) gli item sui diversi cluster. Si riallocano i punti per i quali i centroidi sono più vicini e si aggiornano i centroidi e i gruppi fin quando  non si ottengono miglioramenti di TWSS con ulteriori riassegnamenti (per cui le osservazioni non hanno necessità di cambiare gruppo). 

  * E' dimostrato che alla fine di ogni step di ottiene un decremento delle somme dei quadrati delle distanza dei punti osservati dai prototipi di clusters. 
Il K-means presenta alcuni vantaggi, come ad esempio la sua semplicità di implementazione e il suo tempo di esecuzione relativamente breve. Tuttavia, ha anche alcuni svantaggi, come la dipendenza dalla scelta dei centroidi iniziali e la difficoltà nel gestire cluster di forma irregolare o di densità variabile. Inoltre, K-means è sensibile alle outlier (punti anomali) e non è adatto a dati non linearmente separabili. Si visualizza la partizione ottenuta utilizzando il k-means con la scelta casuale di due centroidi. 
Il metodo quindi individua due partizioni dello spazio: un cluster con 8 elementi e un secondo cluster con 14 elementi. La misura di non omogeneità statistica within è circa 185, mentre quella tra cluster, between è 165. 

```{r}
km_1 <- kmeans (bl_2, center = 2, iter.max = 10, nstart = 1)
table(km_1$cluster)
km_1

####Centri 
# km_1$centers

####WITHIN
# km_1$withinss

####BETWEEN 
# km_1$betweenss

```

Il grafico mostra dove sono posti i centroidi, e la distribuzione dei cluster dei due gruppi rispetto alle prime due features.  


```{r}
plot(bl_std, col = km_1$cluster , main = " Metodo non gerarchico del k-means con 2 centroidi")
points (km_1$center , col = 1:2, pch = 8, cex =1)

```

Si vede adesso il k-means con 3 centroidi.
Oltre a cambiare il numero dei centroidi è stato cambiato anche nstart, ossia si richiede che l’algoritmo di agglomerazione venga ripetuta 10 volte, assicurandoci di minimizzare la misura within e massimizzare la between.
Anche in questo caso la misura within vale circa 112.07891, 132.03 e 91.55 per ciascun cluster, quindi diminuita e la between invece è cresciuta sino a 312.32. Dunque la partizione in 3 gruppi restituisce delle misure di non omogeneità statistica migliori, infatti il rapporto between e total è prossimo al 48.2 % (risultato migliore del metodo precedente). 
```{r}
km_2 <- kmeans (bl_std, center = 3, iter.max = 10, nstart = 10)
table(km_2$cluster)
km_2
# km_2$centers
# km_2$withinss
# km_2$betweenss

```


Sempre rispetto alle prime due variabili, si ottiene il plot rappresentativo. 

```{r}
plot(bl_std, col = km_2$cluster , main = " Metodo non gerarchico del k-means con 3 centroidi")
points (km_2$center , col = 1:2, pch = 8, cex =1)

```



Si procede all'esplorazione del k-means utilizzando le misure gerarchiche. 
I tre cluster così individuati tenendo conto della distanza euclidea contengono ciascuno 15, 12 e 1 Paesi. La within è aumentata per il secondo cluster poichè contiene un numero di elementi maggiori rispetto al caso precedente mentre è uguale a 0 per il terzo cluster poichè è presente una sola osservazione. 

```{r}
d_c <-dist(bl_std, method ="euclidean", diag=TRUE, upper = TRUE)
d_c <- d_c^2
tree <- hclust(d_c, method = "centroid")
taglio <- cutree(tree, k = 3, h =NULL )
tagliolist <-list(taglio)
centroidiIniziali <- aggregate(bl_std, tagliolist, mean)[,-1]
km_c <- kmeans (bl_std, centers = centroidiIniziali, iter.max = 10)
km_c
km_c$centers
km_c$withinss
km_c$betweenss
plot(bl_std, col = km_c$cluster , main = " Metodo non gerarchico del k-means con 3 centroidi")
points (km_c$center , col = 1:2, pch = 8, cex =1)
```

## Validazione dei cluster

### WGSS vs K: scelto del numero di cluster

Dapprima tracciamo i valori di WGSS per soluzioni di raggruppamento con un numero di cluster che varia tra 1 e 8 per vedere se possiamo ottenere indicazioni sul numero di gruppi (che usualmente non è noto a priori). Valori di K > 8 non vengono considerati in quanto, oltre che comportare una forte instabilità di convergenza, si ritiene che conducano ad un partizionamento eccessivamente granulare dei dati considerata la natura del problema: i cluster derivanti risulterebbero infatti di complessa interpretazione. Il grafico può essere ottenuto come segue: Mano a mano che il numero di gruppi aumenta, la somma dei quadrati necessariamente si riduce; Secondo il criterio dell’elbow, il numero di gruppi per cui optare è quello in corrispondenza del quale la curva osservata cambia pendenza: un ulteriore incremento di K renderebbe sempre più complessa la struttura con la quale i dati vengono descritti, senza tuttavia condurre ad un significativo miglioramento della qualità del clustering. Seppure non in maniera marcata, il plot mostra un elbow in corrispondenza di K = 3; per valori maggiori, la decrescita della WGSS è più smooth e meno ripida. 

```{r}

k_max <- 8
wss <- sapply(1:k_max,
              function(k,data) kmeans(data, centers = k)$tot.withinss,
              data=bl_std)
ggp <- ggplot(data = data.frame(x=1:k_max, y=wss), mapping = aes(x=x,y=y)) +
  geom_point(colour = "red") +
  geom_line(colour = "blue") +
  xlab("Numero di gruppi") +
  ylab("Somma dei quadrati entro gruppi (WGSS)")
print(ggp)
```



### ASW vs k: scelta del numero di gruppi

In Figura è possibile visualizzare l’andamento dell’average silhouette width al variare di K; un picco è chiaramente individuabile in corrispondenza di K = 3, per cui in media l’ASW calcolato è di circa 0.27; lo standard error misurato è inoltre alquanto ridotto, per cui è plausibile attendersi un discreto ASW in corrispondenza di tale numero di cluster.
All’aumentare di K non solo in media il valore dei silhouette tende a decrescere drasticamente, ma aumenta altresì, in maniera generale, lo standard error; ne consegue che i
risultati ottenuti sono pi`u instabili e meno affidabili.


```{r}

d_3 <- get_dist(bl_std, stand = FALSE, method = "euclidean")

# CalcolO ASW per tagli da 2 a 8
asw_values <- numeric(length = 7)  # da 2 a 8 cluster
asw_intervals <- matrix(NA, nrow = 7, ncol = 2)  # Matrice per memorizzare gli intervalli

for (k in 2:8) {
  km <- kmeans(bl_std, centers = k, nstart = 30)
  asw_1 <- silhouette(km$cluster, dist = d_3)[,3]
  asw_values[k - 2] <- mean(asw_1) 
  
  # Calcolo dell'intervallo di confidenza al 95%
  n <- length(asw_1)
  conf_interval <- qt(0.975, df = n - 1) * sd(asw_1) / sqrt(n)
  asw_intervals[k - 2, ] <- c(mean(asw_1) - conf_interval, mean(asw_1) + conf_interval)
}

# Creazione del grafico ASW con bande di confidenza
plot(2:8, asw_values, type = "b", xlab = "Numero di Cluster", ylab = "ASW", main = "ASW per K-Means")

# Aggiunta delle bande di confidenza al grafico
arrows(2:8, asw_intervals[, 1], 2:8, asw_intervals[, 2], angle = 90, code = 3, length = 0.1, col = "blue")
max_asw <- max(asw_values)
abline( h= max_asw, col = "red", lty = 2, )

legend("topright", legend = paste("Max ASW =", round(max_asw, 2)), col = "red", lty = 2)


```
### Dunn Index vs K: scelta del numero di gruppi

Il Dunn index si presta ad un’interpretazione poco netta e immediata; si evidenzia l’ampiezza delle bande di confidenza rappresentate, per cui si osservano valori calcolati del DI piuttosto variabili sulle diverse partizioni Ck. Ad ogni modo, lo standrad error misurato non rimane inalterato al variare di K, al crescere del numero di gruppi questo aumenta, motivo per cui si pone quale elemento di giustificazione nella selezione di un valore anzichè di un altro. Il DI assume valori maggiori in corrispondenza di K = 3: per tale scelta è ragionevole attendersi cluster compatti e ben separati, in cui in media la distanza minima tra osservazioni non all’interno dello stesso gruppo è maggiore della massima differenza intra-cluster. Al contrario delle metriche precedentemente consultate, tuttavia, il Dunn Index suggerisce un numero di gruppi K = 3 in maniera meno decisa, l’instabilità dei risultati generati implica che, su taluni campioni
casuali, anche per K > 3 sia possibile ottenere valori del DI migliori rispetto
a quelli ottenuti in corrispondenza del K ottimale.

```{r}
dunn_values <- numeric(length = 7)  # da 2 a 8 cluster
ci_lower <- numeric(length = 7)
ci_upper <- numeric(length = 7)

for (k in 2:8) {
  km <- kmeans(bl_std, centers = k, nstart = 30)
  dunn_values[k - 1] <- dunn(d_2, km$cluster)
  # Calcolo dell'intervallo di confidenza al 95%
  n <- length(km$cluster)
  conf_interval <- qt(0.975, df = n - 1) * sd(km$cluster) / sqrt(n)
  ci_lower[k - 1] <- dunn_values[k - 1] - conf_interval
  ci_upper[k - 1] <- dunn_values[k - 1] + conf_interval
}

data <- data.frame(
  num_clusters = 2:8,
  dunn_values = dunn_values,
  ci_lower = ci_lower,
  ci_upper = ci_upper
)

plotCI(data$num_clusters, data$dunn_values, ui = data$ci_upper, li = data$ci_lower,
       col = "blue", lty = 1, pch = 16, main = "Dunn Index K-Means",
       xlab = "Numero di Cluster", ylab = "Dunn Index")

arrows(data$num_clusters, data$ci_lower, data$num_clusters, data$ci_upper, angle = 90, code = 3, length = 0.05, col = "blue")
cat("Dunn Index per diversi numeri di cluster:", dunn_values, "\n")




```

## Conclusioni clustering e Interpretazione dei risultati 

L'analisi di clustering ha reso evidente come clustering non gerarchico con linkage average e distanza di manhattan con 2 cluster si presta meglio a spiegare il problema in analisi. 


**Gruppo 1**. Il primo gruppo è quello più numeroso, comprendendo l'85%
del campione preso in esame. Si tratta di paesi che mostrano una situazione abitativa con accessi a servizi sanitari piuttosto buona (il 2% della popolazione in media non possiede l'accesso), una buona densità di stanze per persona e un reddito disponibile medio-alto. La ricchezza finanziaria delle famiglie è elevata, così come il tasso di occupazione e il livello di istruzione. Nonostante la qualità della vita apparentemente buona, l'inquinamento dell'aria è significativo. La durata della vita è relativamente alta, e c'è un alto grado di soddisfazione nella vita.


**Gruppo 2**. Il secondo gruppo è quello che contiene un numero ridotto di osservazioni (solo 4) facente parte del restante 15% del dataset. I paesi mostrano una situazione abitativa con un elevato numero di strutture di base mancanti, una bassa densità di stanze per persona e un reddito disponibile basso. La ricchezza finanziaria delle famiglie è inferiore rispetto al primo gruppo, così come il tasso di occupazione e il livello di istruzione. L'inquinamento dell'aria è più elevato, e la durata della vita e la soddisfazione nella vita sono leggermente inferiori rispetto al primo gruppo.



```{r}

d_3 <- get_dist(bl_std, stand = FALSE, method = "manhattan")
hc <- hclust(d_3, method = "average")
cut_average_m <- cutree(hc, k = 2)


dat_gruppo2<-part_bl%>%
  dplyr::filter(Stato %in% c('Mexico', 'Türkiye', 'Brazil', 'South Africa'))
dat_gruppo1<-part_bl%>%
  dplyr::filter(!Stato %in% c('Mexico', 'Türkiye', 'Brazil', 'South Africa' ))




variabili_interesse <- c(
  "Dwellings without basic facilities",
  "Rooms per person",
  "Household net adjusted disposable income",
  "Household net financial wealth",
  "Employment rate", 
  "Educational attainment", 
  "Student skills", 
  "Air pollution", 
  "Life expectancy", 
  "Life satisfaction"
)

medie_variabili1 <- colMeans(dat_gruppo1[, variabili_interesse], na.rm = TRUE)


medie_variabili2 <- colMeans(dat_gruppo2[, variabili_interesse], na.rm = TRUE)

```

```{r, echo=FALSE, include=FALSE}
library(maps)
library(sf)
library(rnaturalearth)
library(ggplot2)
library(rnaturalearthdata)
```


| Variabili                                   | Gruppo 1       |  Gruppo 2      |
|---------------------------------------------|--------------|------------------|
| Dwellings without basic facilities          | 2.17     | 13.600|
| Rooms per person                            | 1.72     | 0.875 |
| Household net adjusted disposable income    | 26524.041 | 13514.250|
| Household net financial wealth              | 53362.00 | 8330.750|
| Employment rate                             | 69.00    | 54.750|
| Educational attainment                      | 83.04    | 42.000|
| Student skills                              | 497.12 | 406.750|
| Air pollution                               | 13.16    | 17.000|
| Life expectancy                             | 80.21    | 71.275|
| Life satisfaction                           | 6.59     | 5.875|


Infine, nella mappa geografica si evidenziano i due cluster analizzati. 
```{r}
world <- ne_countries(scale = "medium", returnclass = "sf")

# Escludo l'Antartide
world <- world[world$continent != "Antarctica", ]

# Specifico i paesi da colorare di rosa chiaro e blu scuro
paesi_rosa_chiaro <- c("Australia", "Austria", "Belgium", "Canada", "Finland", "France", "Germany", "Greece", 
                       "Hungary", "Ireland", "Israel", "Korea", "Latvia", "New Zealand", "Norway", "Poland", 
                       "Portugal", "Slovak Republic", "Slovenia", "Sweden", "Switzerland", "United Kingdom", "Italy",
                       "United States", "Russia")

paesi_blu_scuro <- c("Mexico", "Türkiye", "Brazil", "South Africa")

paesi_rosa_chiaro_sf <- world[world$name %in% paesi_rosa_chiaro, ]
paesi_blu_scuro_sf <- world[world$name %in% paesi_blu_scuro, ]

res <- 500  

par(mar = c(0, 0, 0, 0))  
plot(world["geometry"], col = ifelse(world$name %in% paesi_rosa_chiaro, "lightpink", 
                                     ifelse(world$name %in% paesi_blu_scuro, "darkblue", "lightgrey")), 
     border = "white", resolution = res)

plot(paesi_rosa_chiaro_sf["geometry"], col = "lightpink", add = TRUE)

plot(paesi_blu_scuro_sf["geometry"], col = "darkblue", add = TRUE)


```

# Conclusioni e limiti nelle analisi

La vita si mostra finanziariamente precaria in molte famiglie dei paesi.  Mentre il 12% della popolazione vive in povertà relativa al reddito, la percentuale di coloro che segnalano difficoltà a far fronte alle spese nelle nazioni europee dell'OCSE è quasi il doppio, arrivando al 21%. La ricchezza media delle famiglie è però aumentata, in media, nei paesi in cui esistono dati. Una famiglia su cinque a reddito spende una parte considerevole del proprio reddito disponibile (in media il 20%) per le spese abitative, lasciando poco per le esigenze essenziali della vita. Molte delle famiglie in alcuni stati mostrano difficoltà nell'accesso ai servizi sanitari primari e vivono in condizioni pietose (alcuni stati registrano il 37% della popolazione). 
La qualità della vita riguarda anche le relazioni. Nei paesi, le persone trascorrono circa 14 ore a settimana interagendo con amici e familiari e alla cura della propria persona. Inoltre, una persona su 10 afferma di non avere parenti o amici su cui contare in caso di bisogno (10% vs 90%). 
Inoltre,  sebbene la soddisfazione nella vita sembra essere migliorata in media dal 2013, una considerevole parte della popolazione  nei paesi riporta livelli molto bassi di soddisfazione nella vita. 
L'analisi migliore di cluster ha evidenziato come il linkage average con la distanza di manhattan si presta meglio a gestire la divisione. Messico, Turchia, South Africa e Brasile rappresentano un gruppo a parte. 

Tuttavia, è importante considerare i seguenti limiti nella valutazione dei risultati e delle conclusioni di questo progetto: 
 
  1. *Limitazioni dei dati*: È possibile che i dati utilizzati per l'analisi siano limitati in termini di dimensione del campione, copertura temporale o completezza delle informazioni. Queste limitazioni possono influire sulla generalizzabilità dei risultati e sulla precisione delle stime ottenute.
  
  2. *Mancanza di variabili rilevanti*: È possibile che alcune variabili potenzialmente influenti sul problema non siano state incluse nell'analisi a causa di limitazioni dei dati o di altre ragioni. La mancanza di queste variabili potrebbe limitare la capacità dei modelli di spiegare completamente i fattori che contribuiscono a una vita migliore. 

  3. *Potenziale confondimento*: Nonostante gli sforzi per controllare le variabili confondenti, potrebbe essere presente un potenziale confondimento non misurato o non considerato. Ciò potrebbe influire sugli effetti stimati delle variabili di interesse e sulla validità delle conclusioni. 
  
  4. *Limitazioni dell'interpretazione causale*: Nonostante gli sforzi per controllare le variabili confondenti, gli studi osservazionali come questo possono presentare limitazioni nella determinazione di relazioni causali tra le variabili di interesse. La natura osservazionale dello studio potrebbe rendere difficile stabilire relazioni di causa-effetto definitive tra gli indici di vita e il benessere generale. 

  [Fine seconda parte ]{style="font-family: 'Anastasia';"}

                    




